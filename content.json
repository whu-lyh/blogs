{"pages":[],"posts":[{"title":"B-Spline探秘","text":"B-Spline（=Basic Spline） 需求 需要利用样条函数拟合时相连续的数据，e.g. IMU data。 利用样条函数拟合散点，做表面拟合，e.g. 构建mesh或者其他光滑的表面。 路径规划中使用样条线对A*算法进行优化，得到更加平滑的路径。 多传感器融合任务中，e.g.多传感器标定时，为了内插任意时刻的状态，实现多传感器的时间对齐，使用B-spline做内插。 相关术语123 ​ 大白话来说，B样条曲线其实就是分段多项式，每个分段内的函数又由每个分段内多个子函数（基函数）叠加而成，不同基函数之间有不同的占比。处于高阶的基函数又由相邻分段节点处的低阶基函数得到，由此形成一个不断传递（递归）的过程，直到全部的都计算完毕。B-spline曲线就是每个控制点乘以自己对应的权重系数函数（基函数），然后再求和，控制点是后期指定的，权重函数是预先定义好的，只跟阶数有关，与控制点无关。 Terminologies Notation Explanation Independent Variable \\(t\\) In state estimation, the independent variable is time \\(t\\). \\(t\\) 应该包含\\(k\\)的范围的实数，而\\(k\\)一定是正整数 Order（阶） \\(n\\) Same as the order of final polynomial, the highest exponent. For instance, \\(f(x) = 3x^3\\) has an order of 4. 样条曲线的阶是样条曲线的次数加一。样条曲线的阶越高，控制点越多。二次样条的阶数是三，样条曲线段与三个控制点决定；三次样条的阶数是四，样条曲线段与四个控制点决定。 Degree（次） \\(p\\) Same as the degree of final polynomial, the highest exponent. For instance, \\(f(x) = 3x^3\\) has an degree of 3. 所构成样条曲线的一段光滑参数曲线段，由控制多边形的相邻连续的几段折线段决定，就是几次样条，最常用的就是二次和三次样条。二次样条的某一曲线段只与相应的两段折线段，三个控制多边形顶点有关，改变其中一个顶点，将影响三段样条曲线段。同样的，对三次样条，某一曲线段由相应的三段折线段，四个控制点决定。 Segment Index \\(i\\) A B-Spline is combined with piecewise polynomial, each piece is a segment. 样条曲线是由一组逼近控制多边形的光滑参数曲线段构成，这些曲线段就是样条曲线段。 Knot Vector \\(\\mathbf{k}\\) \\(k_0 \\leq k_1 \\leq ... \\leq k_{m-1}\\), The connect knot, or joint, between every piece of polynomial segment. ==Knot vector lies in the axis of independent variable \\(t\\)==. knot是被提前设计好的，一般被设计成为一组非递减的正整数。 Basis Function \\(B_{i,p}(t)\\) In the expression, \\(i\\) is the index of polynomial segment, \\(p\\) is the degree of the basis function. Control Points（数值） \\(C_i\\) Also named as ==coefficients==. Control points are used to describe the weight of each piece of polynomial segment. 构成特征多边形的各段折线的端点，就是特征多边形的顶点，也叫做控制多边形的控制点。只有在特殊情况下，样条曲线才能通过控制点（如果从白赛尔曲线那边一直研究过来，这句话会好理解一些）。不同的控制点的值*各自定义域内的Basis Function的值就=不同的B-Spline曲线。控制点的\\(i\\)是和分段对\\(i\\)应的，也就是不同的分段会对应不同的控制值，一旦定义好bspline的初始函数之后，其实在不同定义域内初始函数的响应值是一样的，但是被不同的控制值作用之后就不一样了。 直观图例 ​ 下图很直观的表达了B样条曲线的形成过程。注意这里的示意图都是按照Cox-de Boor recursion formula来实现的，因此零次样条线表现出一个反脉冲的形式。 ​ 以一般的基函数如\\(B_{1,0}(t)\\)所示(蓝色)为例，为0次1阶基函数在第一段（属于[0,1)区间）的表达，基函数只有在\\(K_0,K_1\\)处的相应为0.0，其他均为1.0。 Figure.1 Iterative composition of basis functions. Each segment of basis function \\(B_{i,p}(t)\\) is composed by its adjacent basis functions in lower degree, which are \\(B_{i,p-1}(t)\\) and \\(B_{i + 1,p-1}(t)\\). While basis functions in degree 0 are ==unit square wave signals==. py_code Figure.2 The point \\(P_{0,2}\\) of basis function \\(B_{0,2}(t)\\) (order3, degree 2 and segment 0), is evaluated by the weighted combination of \\(B_{0,1}(t)\\) and \\(B_{1,1}(t)\\). The weight of each component is defined by the distance between \\(P_{0,2}\\) and its correspondent knot points (or equivalently linear interpolation). As shown in the figure, the knot vector is \\([0, 3, 6, 9]^T\\). py_code Figure.3 A B-Spline with degree 2, named \\(S_2(t)\\) is generated by weighted combinations of all its basis functions. The weight comes from control points, which are \\([1.2, 0.8, 1.1, 1.2, 1.1]\\) in the figure. The brown dash lines show how control point affect the weight of basis function, these lines finally compose the brown spline. The knot vector is \\([0, 1, 2, 3, 4, 5, 6, 7]^T\\). B-Spline 严格数学定义Cox-de Boor recursion formula 中文表达 TODO 英文表达 ​ Let \\(\\mathbf{K}\\) be a set of \\(m\\) non-decreasing numbers, \\(k_0 \\leq k_1 \\leq ... \\leq k_{m-1}\\). The \\(k_i\\)s are called knot vector, and the ==half-open interval== [\\(k_i,k_{i+1}\\)) the \\(i\\)-th knot span. Note that since some \\(k_i\\)s may be equal, some knot spans (knot span=\\(k_i \\sim k_{i+1}\\)) may not exist. If the knots are ==equally spaced== (i.e. \\(k_{i+1}-k_i\\) is a constant for \\((0\\leq i \\leq m-1)\\)), the knot vector or the knot sequence is said ==uniform==; otherwise, it is non-uniform. The \\(i\\)-th B-spline basis function of degree \\(p\\), written as \\(B_{i,p}(t)\\), is defined recursively as follows: \\[ \\begin{align} \\label{Cox-de Boor Recursion Formula} B_{i,0}(t)&amp;= \\left\\{ \\begin{array}{cc} 1 &amp; if \\quad t_i \\leq t \\leq t_{i+1} \\\\\\\\ 0 &amp; otherwise \\end{array} \\right. \\\\ B_{i,p}(t)&amp;=\\frac{t-t_i}{t_{i+p}-t_i}B_{i,p-1}(t)+\\frac{t_{i+p+1}-t}{t_{i+p+1}-t_{i+1}}B_{i+1,p-1}(t) \\end{align} \\] where If the degree is zero (i.e., \\(p\\) = 0), these basis functions are all step functions \\(\\ref{Cox-de Boor Recursion Formula}\\). Basis function \\(B_{i,0}(t)\\) is 1 if \\(t\\) in the \\(i\\)-th knot span [\\(k_i,k_{i+1}\\)). With control points: \\[ \\begin{align} \\label{Cox-de Boor Recursion Formula w gcp} N(t) = \\Sigma_{i=0}^{n} P_{i}*B_{i,p}(t) \\end{align} \\] 推导 ​ 推导过程详见3，通过三角形法则可以不断计算出更高次的基函数的值。虽然比较麻烦，但是思路挺简单的。 广义矩阵表示 ​ 文章4使用Toeplitz 矩阵将B-spline和Bezier曲线表示为广义矩阵形式。这种表示形式的好处除了更加高效之外，还方便计算导数，方便次数增加和减少任务。 ​ JingeTU对这个文章做了进一步的介绍。但我依然看不懂... 特性（注意点） 样条曲线是连续的，而且曲率变化均匀，B-spline在节点处一阶、二阶导数连续，Cubic Spline在三阶处的导数也连续 the domain is subdivided by knots. 整个分布空间定义域所处的domain被knot分割开 basis functions are not non-zero on the entire interval. In fact, each B-spline basis function is non-zero on a few adjacent subintervals and, as a result, B-spline basis functions are quite \"local\" (local support). B-spline的基函数在局部subintervals是非零的，并不是一直有值，也就是k的定义域在1阶0次基函数中是在局部定义域内响应的 \\(u_i\\) is a multiple knot of multiplicity k, written as \\(u_i(k)\\). knot 是可以重复存在的，knot vector是全部knot组成的，knot其实是预先设定好的，在既定位置上存在的点。 Basic function \\(B_{i,p}(t)\\) is non-zero on [\\(k_i,k_{i+p+1}\\)). Or, equivalently, \\(B_{i,p}(t)\\) is non-zero on \\(p+1\\) knot spans. 想要找到高次基函数所对应的非零区间，可以用三角形法则反向查找，所对应的区间加起来就是其所对应的非零区间3，随着阶数的升高，k对应的定义域是在不断变化的，\\(k \\in \\left[ k_i, k_{i+p+1} \\right)\\). On any knot span [\\(k_i,k_{i+1}\\)), at most \\(p+1\\) degree \\(p\\) basis functions are non-zero. 可以根据subinterval区间找到哪些高次基函数是非零的 给定knot vector \\(\\mathbf{K}\\)和阶数\\(n\\)，每段函数在knot节点处的连续性等于\\(C^{n-2}\\) 生成B-Spline时，所需knots的数量m和阶数n,以及控制点的数量有关。即m=n+1+控制点数量 B-Spline 分为opened 和clamped两种，区别在于是否是B-Spline通过起始点和终止点。前者否，后者是 可视化 一个直观的基于Web的Spline可视化界面。手动选择knot可直接显示Spline，可以移动knot。 C++版基于OpenGL实现的Spline可视化代码，但是没测试过。 医学图像领域基于TPS实现图片编辑的vs工程。 A tool for interactive interpolation of splines. Select any points and visualize how different splines are modelled. 对比不同曲线之间的差异。带界面，推荐。 MATLAB版本的绘制B-spline曲线和表面的。对于MATLAB用户来说非常好用。下面是两个实例结果，非常直观形象。就是拟合大数据的时候会比较慢。不过作为示意图够使用了。 使用不同次数的基函数对数据进行最小二乘拟合的结果 knot非均匀分布下分段多边形函数以及对应的B-Spline函数 基于VTK实现的Spline可视化，包含TPS等样条曲线。 pySpline produces B-spline curves, surfaces, and volumes一个基于python的，但是目前没有环境，没有测试。 References https://xiaoxingchen.github.io/2020/03/02/bspline_in_so3/ ↩︎ 样条曲线的次数和阶数分别是什么意思，能举例说明一下吗？ - potato的回答 - 知乎 https://www.zhihu.com/question/43028324/answer/399976433 ↩︎ https://pages.mtu.edu/~shene/COURSES/cs3621/NOTES/spline/B-spline/bspline-basis.html ↩︎ Qin K. General matrix representations for B-splines[C]//Proceedings Pacific Graphics' 98. Sixth Pacific Conference on Computer Graphics and Applications (Cat. No. 98EX208). IEEE, 1998: 37-43. ↩︎","link":"/blogs/2025/02/08/B-Spline/"},{"title":"B-spline Interpolation","text":"Kalibr Kalibr中使用了B-spline实现位姿的内插，进而完成相机和IMU之间的时间同步标定。 PoseSpline","link":"/blogs/2023/02/09/B-spline-Interpolation/"},{"title":"CloudCompare源代码学习","text":"目的 想使用一下CloudCompare自带的八叉树，替换掉nanoflann。nanoflann在某些特殊场景下返回的结果是有问题的，导致程序出现异常。 nanoflann返回值出现异常 ​ 用于最邻近搜索，在radiussearch下，如果能找到最近点，那么确实找到的是最近点，如果找不到最近点，那么就会出现问题，如下： 123456789101112131415nanoflann::KdTreeFLANN&lt;PB::pmPointXYZ&gt;::Ptr kdtree = std::make_shared&lt;nanoflann::KdTreeFLANN&lt;PB::pmPointXYZ&gt;&gt;();if (!kdtree) { std::cerr &lt;&lt; \"KD tree build failed!\" &lt;&lt; std::endl; return;}kdtree-&gt;setInputCloud(cloud);for (int i = 0; i &lt; checkcorrs.size(); ++i) { std::vector&lt;int&gt; searchIndexes; std::vector&lt;SCALAR_TYPE&gt; distances; SCALAR_TYPE *search_pt = new SCALAR_TYPE[3]; search_pt[0] = checkcorrs[i].x; search_pt[1] = checkcorrs[i].y; search_pt[2] = checkcorrs[i].z; kdtree-&gt;radiusSearch(search_pt, 2.0, searchIndexes, distances);} ​ 在for循环中，每次更新query的点坐标，然后试图从点云中返回其最近的2.0m范围内的点，如果query点周围没有符合条件的点，那么就会返回上一次for循环的值。详见issue。 使用CloudCompare自带的Octree 核心为直接接入cc内部的octree实现最近点的索引，位于#include &lt;DgmOctree.h&gt;，这样检索速度大大加快。过程如下： 首先找到当前选中哪些entity，此时需要引用主窗口的头文件并获取全局静态变量#include &lt;mainwindow.h&gt;； 1const ccHObject::Container &amp;selectedEntities = MainWindow::TheInstance()-&gt;getSelectedEntities(); 遍历每个选中的entity，并将其转换为点云类型，需要#include &lt;ccHObjectCaster.h&gt;头文件； 1234for (ccHObject* ent : selectedEntities){ ccPointCloud* pc = ccHObjectCaster::ToPointCloud(ent);} 获取ccPointCloud点云类中的八叉树索引，如果未构建，则重新构建； 12345678910ccOctree::Shared octree = pc-&gt;getOctree();if (!octree){ octree = pc-&gt;computeOctree(); if (!octree) { ccLog::LogMessage(QString::fromLocal8Bit(\"索引构建失败，\") + ent-&gt;getName(), ccLog::LOG_ERROR); continue; }} 开始索引，测试了有两种方式，一种是使用DgmOctree的findNeighborsInASphereStartingFromCell，另一种是使用DgmOctree的getPointsInSphericalNeighbourhood。这里的PointCoordinateType是cc内部定义的数值变量的类型，默认为float型。检索出来的邻域点存放在CCLib::DgmOctree::NeighboursSet中，通过源码可以看出就是描述点信息的vector向量。需要注意的是，这两个方式都需要提前知道八叉树的层级，通过octree-&gt;findBestLevelForAGivenNeighbourhoodSizeExtraction得到当前半径下需要在哪一层level做检索。NearestNeighboursSphericalSearchStruct中的参数设置没搞明白，就先不用了。 1234567891011PointCoordinateType search_radius = 1.0;// @1//CCLib::DgmOctree::NearestNeighboursSphericalSearchStruct nnsss;//nnsss.queryPoint = search_pt;//CCLib::DgmOctree::NeighboursSet neighbour_pts = nnsss.pointsInNeighbourhood;//int ret_pt_num = octree-&gt;findNeighborsInASphereStartingFromCell(nnsss, search_radius, true);// @2unsigned char level = octree-&gt;findBestLevelForAGivenNeighbourhoodSizeExtraction(search_radius);CCVector3 search_pt = CCVector3(checkcorrs[i].ctrl_pt.x + global_offset.x,checkcorrs[i].ctrl_pt.y + global_offset.y, checkcorrs[i].ctrl_pt.z + global_offset.z);CCLib::DgmOctree::NeighboursSet neighbour_pts; int ret_pt_num = octree-&gt;getPointsInSphericalNeighbourhood(search_pt, search_radius, neighbour_pts, level); ​ 使用cc自带的八叉树之后，发现检索速度非常快（由于八叉树cell分区的原因，虽然返回的值可能不准确，但足够用了）。部分核心代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166// qCC_db#include &lt;ccHObjectCaster.h&gt;#include &lt;ccPointCloud.h&gt;#include &lt;DgmOctree.h&gt;#include &lt;mainwindow.h&gt;// 控制点类struct ControlPoint : public CCVector3d{ std::string gcp_name; // gcp name int id; // gcp index // operator &lt;&lt; overwrite inline friend std::ostream&amp; operator&lt;&lt;(std::ostream &amp;os, const ControlPoint &amp;pt) { os &lt;&lt; std::setprecision(10) &lt;&lt; \"gcp_name: \" &lt;&lt; pt.gcp_name &lt;&lt; \", x = \" &lt;&lt; pt.x &lt;&lt; \" , y = \" &lt;&lt; pt.y &lt;&lt; \" , z = \" &lt;&lt; pt.z; return os; }};typedef std::vector&lt;ControlPoint&gt; ControlPointVec;// 同名点类struct HomonymPoint : public CCVector3d{ double gps_time; // gpstime from origin las point cloud file HomonymPoint() :CCVector3d(0.0, 0.0, 0.0), gps_time(0.0) {} // container stores the nearest points located inside a certain radius for coordinate interpolation std::vector&lt;P2M::BaseType::Point3D&gt; nearest_pts; HomonymPoint(const double x_, const double y_, const double z_) :CCVector3d(x_, y_, z_), gps_time(0.0) {} // operator &lt;&lt; overwrite inline friend std::ostream&amp; operator&lt;&lt;(std::ostream &amp;os, const HomonymPoint &amp;pt) { os &lt;&lt; std::setprecision(10) &lt;&lt; \"Correspondence point gps time stamp: \" &lt;&lt; pt.gps_time &lt;&lt; \", x = \" &lt;&lt; pt.x &lt;&lt; \" , y = \" &lt;&lt; pt.y &lt;&lt; \" , z = \" &lt;&lt; pt.z; return os; }};typedef std::vector&lt;HomonymPoint&gt; HomonymPointVec;// 对应关系类struct checkCorrespondence{ int id; ControlPoint ctrl_pt; HomonymPoint corr_pt; bool isChecked; // for point cloud surface fitting, Coordinates of data points. std::vector&lt;mba::point&lt;2&gt;&gt; coo; // Data values. std::vector&lt;double&gt; val; // statistic info float dist; float dist_x; float dist_y; float dist_z;};typedef std::vector&lt;checkCorrespondence&gt; checkCorrespondences;// get local part of ALS point cloudbool getCorrespondPoints(checkCorrespondences &amp;checkcorrs, CCVector3d &amp;global_offset){ const ccHObject::Container &amp;selectedEntities = MainWindow::TheInstance()-&gt;getSelectedEntities(); if (selectedEntities.empty()) return false; // global shift check, note that offset may be incorrected const ccShiftedObject* shifted = ccHObjectCaster::ToShifted(selectedEntities[0]); if (shifted) { global_offset = shifted-&gt;getGlobalShift(); } for (ccHObject* ent : selectedEntities) { ccPointCloud* pc = ccHObjectCaster::ToPointCloud(ent); if (!pc) { ccLog::LogMessage(QString::fromLocal8Bit(\"未选中有效点云，\") + ent-&gt;getName(), ccLog::LOG_ERROR); continue; } ccOctree::Shared octree = pc-&gt;getOctree(); if (!octree) { octree = pc-&gt;computeOctree(); if (!octree) { ccLog::LogMessage(QString::fromLocal8Bit(\"索引构建失败，\") + ent-&gt;getName(), ccLog::LOG_ERROR); continue; } } Q_ASSERT(octree != nullptr); //CCLib::DgmOctree::NearestNeighboursSphericalSearchStruct nnsss; PointCoordinateType search_radius = 1.0; unsigned char level = octree-&gt;findBestLevelForAGivenNeighbourhoodSizeExtraction(search_radius); // find correspondence and calculate for (int i = 0; i &lt; checkcorrs.size(); ++i) { CCVector3 search_pt = CCVector3(checkcorrs[i].ctrl_pt.x + global_offset.x, checkcorrs[i].ctrl_pt.y + global_offset.y, checkcorrs[i].ctrl_pt.z + global_offset.z); //nnsss.queryPoint = search_pt; //int ret_pt_num = octree-&gt;findNeighborsInASphereStartingFromCell(nnsss, search_radius, true); //CCLib::DgmOctree::NeighboursSet neighbour_pts = nnsss.pointsInNeighbourhood; CCLib::DgmOctree::NeighboursSet neighbour_pts; int ret_pt_num = octree-&gt;getPointsInSphericalNeighbourhood(search_pt, search_radius, neighbour_pts, level); if (ret_pt_num &lt; 1) continue; // get the nearest point if (neighbour_pts[0].squareDistd &lt; checkcorrs[i].dist) { const CCVector3 *ret_pt0 = neighbour_pts[0].point; checkcorrs[i].corr_pt = HomonymPoint(ret_pt0-&gt;x - global_offset.x, ret_pt0-&gt;y - global_offset.y, ret_pt0-&gt;z - global_offset.z); } // get the set of neighbour pts for (auto pt: neighbour_pts) { checkcorrs[i].isChecked = true; const CCVector3 *ret_pt = pt.point; // copy to fitting data container checkcorrs[i].coo.push_back(mba::point&lt;2&gt;{ret_pt-&gt;x, ret_pt-&gt;y}); checkcorrs[i].val.emplace_back(ret_pt-&gt;z); } } } return true;}// interpolate the height value based on nearest pointsvoid interpolateCoordinate(checkCorrespondence &amp;corr, const CCVector3d &amp;global_offset){ // get coarse boundary double minx = 0.0, maxx = 0.0, miny = 0.0, maxy = 0.0; for (auto pt : corr.coo) { minx = (std::min)(minx, pt[0]); maxx = (std::max)(maxx, pt[0]); miny = (std::min)(miny, pt[1]); maxy = (std::max)(maxy, pt[1]); } mba::point&lt;2&gt; lo = { minx - 3.0, miny - 3.0 }; mba::point&lt;2&gt; hi = { maxx + 3.0, maxy + 3.0 }; // Initial grid size. mba::index&lt;2&gt; grid = { 5, 5 }; mba::MBA&lt;2&gt; interp(lo, hi, grid, corr.coo, corr.val); // residual between gt and measurement corr.corr_pt.z = interp(mba::point&lt;2&gt;{corr.ctrl_pt.x + global_offset.x, corr.ctrl_pt.y + global_offset.y}); corr.dist_z = corr.ctrl_pt.z - corr.corr_pt.z;}// for interpolating the position of target gcp pointsbool qualityCheck(const std::string &amp;gcp_path, const std::string &amp;output_path){ namespace PB = P2M::BaseType; // load gcps if (!P2M::Util::FileUtility::FileExist(output_path)) { std::cerr &lt;&lt; \"Output Path: \" &lt;&lt; output_path &lt;&lt; \" doesn't exist!\" &lt;&lt; std::endl; return false; } checkCorrespondences checkcorrs; CCVector3d global_offset(0.0,0.0,0.0); // load check gcp points loadGcpFile(gcp_path, checkcorrs, global_offset); // get loca part of ALS point clouds getCorrespondPoints(checkcorrs, global_offset); // get height difference based on surface fitting for (auto &amp;checkcorr : checkcorrs) { if (checkcorr.isChecked) { interpolateCoordinate(checkcorr, global_offset); } } return true;}","link":"/blogs/2023/03/13/CloudCompare%E6%BA%90%E4%BB%A3%E7%A0%81%E5%AD%A6%E4%B9%A0/"},{"title":"Docker深度学习","text":"感谢卢指导！ 安装出现错误GPG Err解决方案为： 12345rm /etc/apt/sources.list.d/cuda.listrm /etc/apt/sources.list.d/nvidia-ml.listapt-key del 7fa2af80apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/3bf863cc.pubapt-key adv --fetch-keys https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64/7fa2af80.pub Docker 安装 1. Docker 安装 1.1 卸载旧版本 1sudo apt-get remove docker docker-engine docker.io 1.2 安装依赖项 由于 apt 源使用 HTTPS 以确保软件下载过程中不被篡改。因此，我们首先需要添加使用 HTTPS 传输的软件包以及 CA 证书。 12sudo apt-get updatesudo apt-get install apt-transport-https ca-certificates curl gnupg-agent software-properties-common 1.3 添加源和密钥 为了确认所下载软件包的合法性，需要添加软件源的 GPG 密钥。 设备未设置代理：使用 aliyun 镜像 1curl -fsSL https://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg | sudo apt-key add - 向 sources.list 添加 Docker 软件源 1sudo add-apt-repository \"deb [arch=amd64] https://mirrors.aliyun.com/docker-ce/linux/ubuntu $(lsb_release -cs) stable\" 设置了代理：使用官方源 1curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - 向 sources.list 添加 Docker 软件源 1sudo add-apt-repository \"deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable\" 1.4 安装 Docker 更新apt并安装 12sudo apt-get updatesudo apt-get install docker-ce docker-ce-cli containerd.io 1.5 启动 docker 12sudo systemctl enable dockersudo systemctl start docke 1.6 设置 docker 用户组 默认情况下，docker 命令会使用 Unix socket 与 Docker 引擎通讯。而只有 root 用户和 docker 组的用户才可以访问 Docker 引擎的 Unix socket。出于安全考虑，一般 Linux 系统上不会直接使用 root 用户。因此，更好地做法是将需要使用 docker 的用户加入 docker 用户组。 建立 docker 组： 1sudo groupadd docker 将当前用户加入 docker 组： 1$ sudo usermod -aG docker $USER 退出当前终端并重新登录，进行如下测试。 1.7 测试是否安装正确 1docker run hello-world 输出成功信息即可 1.8 修改 docker images 存储路径 1sudo vim /etc/docker/daemon.json 添加 1\"data-root\": \"/data/docker/images\" 重启生效 2. 安装 nvidia-docker 要求已经按照 nvidia 驱动 设置了代理，通过 apt 安装 2.1 配置 nvidia docker 源 123curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add -distribution=$(. /etc/os-release;echo $ID$VERSION_ID)curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.listsudo apt-get update 1curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add - 2.2 安装 nvidia-docker2 12sudo apt-get install nvidia-docker2sudo pkill -SIGHUP dockerd 未设置代理，离线安装 在官网下载，ubuntu 20.04 使用 18.04 的文件，下载下列文件： - libnvidia-container1 - libnvidia-container-tools - nvidia-container-toolkit-base - nvidia-container-toolkit - nvidia-container-runtime - nvidia-docker2 文件名会根据版本有所改变，但前部一致： 严格按照以下顺序，因存在依赖关系 依次输入 123456dpkg -i libnvidia-container1 dpkg -i libnvidia-container-toolsdpkg -i nvidia-container-toolkit-basedpkg -i nvidia-container-toolkit dpkg -i nvidia-container-runtime dpkg -i nvidia-docker2 若无报错 ❌，则安装成功 ✅ 重启 docker 1systemctl restart docker 使用需要gpu的测试 安装完成后，会覆盖 daemon.json，如果需要更改 image 的存储位置，需要重新设置","link":"/blogs/2023/04/17/Docker%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"title":"Docker用法进阶","text":"泡泡机器人SLAM与你一同成长❤ 使用之前先看看本地都有哪些镜像和容器。 1sudo docker ps -a 查看现有容器以及状态。 1234CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES0ac8c062fa10 pointclouddl:segmentation \"/bin/sh -c 'service…\" 8 minutes ago Up 8 minutes 6006/tcp, 50051/tcp, 0.0.0.0:2224-&gt;22/tcp brave_kilbycd8b9c9c5b07 stereolabs/zed:3.0-gl-devel-cuda10.0-ubuntu18.04 \"/bin/bash\" 4 weeks ago Exited (0) 5 hours ago jolly_feynmanaf07110a5157 stereolabs/kalibr \"/ros_entrypoint.sh …\" 4 weeks ago Exited (0) 4 weeks ago modest_leakey e.g.现有用于laser slam的镜像, 设置了界面，ssh，基于amazinghao/ubuntu:graph_slam_clean镜像。 12CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESfe7323d95d8f amazinghao/ubuntu:graph_slam_clean \"./startup.sh\" 9 seconds ago Up 7 seconds 22/tcp, 0.0.0.0:5900-&gt;5900/tcp laser_slam_env 一些容器内部设置必须在创建的时候就设置好，不然就只能重新创建。比如端口映射，文件夹挂载，设置别名，虚拟内存设置，时区设置等。 使用进阶 端口映射 列举几个需要用到网络端口的情况： 使用Docker环境进行深度学习网络训练时，需要将对应的Pytorch日志通过浏览器的方式打开查看，但是Docker是没有图形化界面的，因此需要通过端口映射的方式将Docker环境中的端口映射到本地。在本地打开浏览器查看。 使用Docker环境使用ROS运行程序，需要RVIZ进行可视化。 使用Marsim等仿真环境，需要一个可视化界面进行渲染。 1sudo docker run -it -p 5900:5900 paopaorobot/ubuntu-xfce-vnc -p，容器内部的 5900 端口映射到本地主机的 5900 端口上。访问本地的 可以同时开启多个端口映射。 容器内的网络是隔离的，其中的127.0.0.1指向容器本身。也可以通过指定--network-host共用宿主机网络。 查看端口映射 查看一个容器中已经映射的端口 1docker port containerId 即可查看容器端口映射情况。 文件夹挂载 Docker中是固定了环境的，其中不包含数据和代码，避免容器关闭时代码和数据丢失。容器中修改相关的代码，在本地同时会被更新。 1sudo docker run -i -t -v /Data:/data amazinghao/ubuntu -v，将本地的Data路径挂载到容器中的/data路径下。 同样可以同时挂载多个路径。 拷贝文件 这里不建议拷贝数据或者代码到容器中，Docker设计时是环境和代码分离的，代码和数据可以放在本地。容器只负责环境管理。 1sudo docker cp host_path containerID:container_path 从主机复制到容器 1sudo docker cp containerID:container_path host_path 从容器复制到主机 容器打包成镜像 将现有容器环境打包成镜像，方便后续使用或跨平台使用 Note that the code file and data file should not be packaged into the image and only environment should be in there 1sudo docker commit -a \"amazinghao\" -m \"for point cloud deep learning environment\" dc1e2f6fcf8d pointclouddl:segmentation -a, author info -m, commit message dc1e2f6fcf8d, container id, which is unique the last parameter is the new image name and its tag. The new image name should be lowercase 在推送到云端时，需要和云端仓库中的镜像名字保持一致。那么可能就会用到tag命令。 例如:将462f5c932e5c重命名为amazinghao/ubuntu:dev 1docker tag 462f5c932e5c amazinghao/ubuntu:dev dev即为新的标签，这样做将会创建一个新的镜像。 也可以将hdl_graph_slam:graph_slam_updated重命名为amazinghao/ubuntu:graph_slam_updated 1docker tag hdl_graph_slam:graph_slam_updated amazinghao/ubuntu:graph_slam_updated 再开始推送即可。 设置别名 设置容器的别名 1docker run -itd --name=laser_slam_env 注意别名的设置尽量放置在命令行中靠前的位置。 环境变量设置 1sudo docker run -i -t -e TZ=\"Asia/Shanghai\" -e SSHPW=xxx amazinghao/ubuntu bin/bash -e TZ=\"Asia/Shanghai\"，设置时区，使得容器内部的时间和宿主机时间保持一致，提升日志的可读性。 -e SSHPW=xxx，设置密码。 bin/bash，这个表示容器启动时执行的命令，必须有-it才能生效。 这样容器在退出时容器转为后台运行。 虚拟内存设置 常见的情况是，在深度学习环境Pytorch的Dataloader中num_works设置较大时，太多数据加载到内存中时就会报错。e.g. RuntimeError: DataLoader worker (pid 43257) is killed by signal: Bus error. It is possible that dataloader's workers are out of shared memory. Please try to raise your shared memory limit. 1sudo docker run -i -t -shm_size=32g amazinghao/ubuntu -shm_size=32g 检查镜像 检查镜像中的现有环境，包括镜像生成时的一些设置等 1sudo docker image inspect pointclouddl:segmentaton 检查容器 同理检查容器的内部细节 1docker inspect containerID 它会返回一个 JSON 文件记录着 Docker 容器的配置和状态信息。 导出镜像 export &amp; import 1234# export current imagedocker export image_id &gt; current.tar# import current imagedocker import image_name &lt; current.tar save &amp; load 123docker save 0fdf2b4c26d3 &gt; hangge_server.tardocker save -o images.tar postgres:9.6 mongo:3.4docker load &lt; hangge_server.tar ​ Differences from image sizes, image rename, multiple-containers into one single image, application scenarios, more detail could be seen at here 使用Dockerfile构建进行 可以先参考这里，我一般都用官方镜像，然后手动创建。主要涉及到Dockerfile内部的一些命令的使用，可以配合xfce的相关内容构建，又可可视化又可深度学习的环境。 使用实例 New a container for SLAM The images for SLAM are mostly built from the paopaorobot/ros-vnc, so the visualization module is embedded into the image. Any thing related to the visualization could be set as you wish. 123456789# open a new container using the xfce&amp;vnc for visualization, host port is 5900, host mount dir is /Data, extra setting is the resolution which is 1080Psudo docker run -i -t -p 5900:5900 -v /Data:/data -e RESOLUTION=1920x1080 paopaorobot/ubuntu-xfce-vnc# similar to the upper one, amazinghao/ubuntu is build based on the ros-vnc imagesudo docker run -i -t -p 5900:5900 -v /Data:/data -e RESOLUTION=1920x1080 amazinghao/ubuntu# similar to the upper twosudo docker run -i -t -p 5900:5900 -v /Data:/data -e RESOLUTION=1920x1080 paopaorobot/ros-vnc:latest# windows docker container creation commond# Note that the alias name should be placed frontier and the dir mount should be carefully setdocker run -itd --name=laser_slam_env -p 5900:5900 -e SSHPW=usmn9a -v /D/data/Publicdatasets/:/data -v /E/Vs15WorkSpace/catkin_ws_lidar:/workspsace_slam -e RESOLUTION=1920x1080 amazinghao/ubuntu:graph_slam_clean New a container for Deep learning with CUDA 1sudo docker run -itd --gpus all --privileged=true -v /home/amazinghao/Data:/data-lyh -v /home/amazinghao/PointSeg:/pointcloud_seg_code -p 2224:22 -e SSHPW=xxx pointclouddl:segmentation --gpus all , only this the Nvidia driver could be accessed, check this --privileged=true , to obtain the 'real' permission to mount file or others. This one is very important -v , mount the host dir or file to the container. The dir should begin with '/' and connected by ':' -e SSHPW , set the ssh connect password -p , two ports are opened for both ssh or visualize. Only if the visualization module is activated, the VNC-Viewer is available. -d , the container should be closed manually, and the local command will not convert to the container. After using run to new container Using \"run\" to new a new container and once you quit the container, the container will immediately be closed. The container that you new right now will stay started and STATUS will be like: Up 8 minutes. Only thing you should do, if you are using VNC-Viewer for visualization, is as followings: 1sudo docker start 0ac8c062fa10 1234567891011121314151617181920212223242526amazinghao@xixi-ubuntu:~$ sudo docker attach 0ac8c062fa10root@0ac8c062fa10:~# nvidia-smiMon Jan 18 04:55:55 2021 +-----------------------------------------------------------------------------+| NVIDIA-SMI 450.80.02 Driver Version: 450.80.02 CUDA Version: 11.0 ||-------------------------------+----------------------+----------------------+| GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC || Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. || | | MIG M. ||===============================+======================+======================|| 0 GeForce GTX 108... Off | 00000000:01:00.0 On | N/A || 24% 46C P5 18W / 250W | 271MiB / 11175MiB | 0% Default || | | N/A |+-------------------------------+----------------------+----------------------+ +-----------------------------------------------------------------------------+| Processes: || GPU GI CI PID Type Process name GPU Memory || ID ID Usage ||=============================================================================|+-----------------------------------------------------------------------------+root@0ac8c062fa10:~# nvcc -Vnvcc: NVIDIA (R) Cuda compiler driverCopyright (c) 2005-2019 NVIDIA CorporationBuilt on Sun_Jul_28_19:07:16_PDT_2019Cuda compilation tools, release 10.1, V10.1.243 When you exit the container, the correspond container's STATUS will be some thing like: Exited (0) 4 seconds ago. But if you only close vscode (connnet by Remote Container), the container will not be closed. Also you can using exec to new a container The container will not be stopped, while exec command. 12docker exec -it af07110a5157 /bin/bashdocker attach previous_container_id New a container for zed sdk 12# Open a container for zed stereo camera. The image contains a visualization module using \"X11\"sudo docker run --gpus all -it --privileged --network=host stereolabs/zed:3.0-runtime-cuda10.0-ubuntu18.04 ZED docker display support 1xhost +si:localuser:root 12sudo docker run --gpus all -it --privileged -e DISPLAY=$DISPLAY -v /tmp/.X11-unix:/tmp/.X11-unix stereolabs/zed:3.0-gl-devel-cuda10.0-ubuntu18.04sudo docker attach containerID The camera connection can be verified using lsusb: 1lsusb -d 2b03: -vvv in case of replug/hotplug, mount all the dev folder 1docker run --gpus all -it -v /dev:/dev --privileged stereolabs/zed:3.0-runtime-cuda10.0-ubuntu18.04 problem the ZED_Depth_Viewer didn't work somehow. zed_ros_wapper &amp; cuda for a ros bag add a ros melodic to zed-sdk and build the zed_ros_wapper in it ID:cd8b9c9c5b07 stereolabs/zed:3.0-gl-devel-cuda10.0-ubuntu18.04 New a container for kalibr container ID:af07110a5157 is the one which rebuild the ros_kalibr_system ubuntu version:16.04 ros version:kinetic --show-extraction","link":"/blogs/2021/01/18/Docker%E7%94%A8%E6%B3%95%E8%BF%9B%E9%98%B6/"},{"title":"Docker初体验","text":"泡泡机器人SLAM与你一同成长❤ Docker简介 Docker 是一个开源的应用容器引擎，基于Go语言 并遵从Apache2.0协议开源。 Docker 可以让开发者打包他们的应用以及依赖包到一个轻量级、可移植的容器中，然后发布到任何流行的 Linux 机器上，也可以实现虚拟化。 容器可以认为是一种虚拟环境，它完全使用沙箱机制，相互之间不会有任何接口（类似iPhone的app）,更重要的是容器性能开销极低。 (我认为是一种管理虚拟环境的引擎，方便快速构建任何虚拟环境，而各个环境之间不会相互影响，并且支持快速移植和部署。) 和其他虚拟机软件之间的不同 Docker 是一个用于开发，交付和运行应用程序的开放平台。Docker 能够将应用程序与基础架构分开，从而可以快速交付软件。借助 Docker，可以与管理应用程序相同的方式来管理基础架构。通过利用Docker 的方法来快速交付，测试和部署代码，可以大大减少编写代码和在生产环境中运行代码之间的延迟。 与VirtualBox相比，VirtualBox虚拟化硬件，Docker虚拟化操作系统。 两者比较： VirtualBox，是创建硬件虚拟化的软件。 通常情况下，一个操作系统运行在硬件上，其中硬件和操作系统之间的通信是通过移动数据到内存地址，然后发出指令来通知可使用该数据的硬件（或者是数据在被读取时）。 在VirtualBox（或其它虚拟机）设置的环境中，那些内存地址实际上是虚拟机软件自身的内存区域，并且那些指令是由虚拟机而不是直接由底层的CPU解释的。 实际结果是，你在VirtualBox中运行一个操作系统，对于这个操作系统来说，VirtualBox程序看起来像一台完整计算机，硬件以及所有配件都有。实际上它不知道自己是在另一个程序中运行的。 Docker，则是不进行硬件的虚拟化。 Docker 的作用是创建一个文件系统，使其看起来像一个普通的Linux文件系统，并且运行应用程序在一个所有文件和资源都在文件系统内的锁定环境中。 事实上，该应用程序的容器并不模仿任何硬件，应用程序仍然在硬件上运行，它只是隔离了应用程序并允许开发人员可以运行该应用程序跟特定的并且完全不是主机操作系统的软件和第三方库合作。 这意味着，在启动或停止Docker应用程序时几乎没有开销，因为它们不需要预先分配的内存和磁盘空间等等。因此Docker容器很容易设置或者拆除。 此外，容器在加装需要系统中各种硬件组件上运行软件的时候并不浪费任何开销，因为它是基于系统内核，直接使用硬件的， 不需要独立分配物理资源。多个容器共享内存，CPU等物理资源。 Docker的一些优点 1、快速，一致地交付应用程序 Docker 允许开发人员使用提供的应用程序或服务的本地容器在标准化环境中工作，从而简化了开发的生命周期。容器非常适合持续集成和持续交付（CI / CD）工作流程，请考虑以下示例方案： 开发人员在本地编写代码，并使用 Docker 容器与同事共享他们的工作。 他们使用 Docker 将其应用程序推送到测试环境中，并执行自动或手动测试。 当开发人员发现错误时，他们可以在开发环境中对其进行修复，然后将其重新部署到测试环境中，以进行测试和验证。 测试完成后，将修补程序推送给生产环境，就像将更新的镜像推送到生产环境一样简单。 2、响应式部署和扩展 Docker 是基于容器的平台，允许高度可移植的工作负载。Docker 容器可以在开发人员的本机上，数据中心的物理或虚拟机上，云服务上或混合环境中运行。 Docker 的可移植性和轻量级的特性，还可以使开发人员轻松地完成动态管理的工作负担，并根据业务需求指示，实时扩展或拆除应用程序和服务。 3、在同一硬件上运行更多工作负载 Docker 轻巧快速。它为基于虚拟机管理程序的虚拟机提供了可行、经济、高效的替代方案，因此可以利用更多的计算能力来实现业务目标。 Docker 非常适合于高密度环境以及中小型部署，而开发人员可以用更少的资源做更多的事情。 Docker的基本概念 核心概念：镜像，容器 Docker_images_container Docker安装/(以Win10安装为例，Linux详见另一个博客) Docker 官网，Github Docker 源码 1. Docker-Desktop下载 打开 DockerHub 直接下载 docker-desktop 安装包即可。下载完成会得到\"Docker Desktop Installer.exe\"软件，选个合适的路径，一路Next安装即可。 Win7 或Win8 需要借助 docker toolbox 完成安装。 Win10需要开启Hyper-V功能，开启位置位于：Win10左下角第一个图标右键单击-&gt;应用和功能-&gt;启用或关闭Windows功能，从中找到Hyper-V选中即可。 安装完成之后会在Windows的图标中出现一个小鲸鱼的图标。 2. 安装测试 可以右键单击Docker图标进行一些个性化调整。为了加速软件和镜像的下载速度，最好将Docker镜像源为阿里云或中科大源，不然下载速度会很慢。如下： Docker基础命令 安装完之后，在系统任何位置打开控制台或bash命令行（终端均可运行docker命令） docker --version 查看docker的版本。 docker 即可列出Docker客户端的所有命令行选项，当想要查找某一命令时非常方便。 docker search 如：docker search ubuntu 在Docker Hub中搜索名为ubuntu的镜像。 docker pull DockerHubID/imageName 如：docker pull ubuntu 。若当前Docker Hub账户中没有该名称的镜像，则会自动从Docker Hub公共仓库中下载并拉取到本地。因此这个名字需要注意，不然很容易就下载错了或下载成别人的开源镜像了。另外还可以指定不同标签版本的镜像：docker pull ubuntu:18.04，即可拉取18.04的ubuntu。 docker images 列出本地主机的全部镜像。 docker ps 将全部的容器列出来， 添加-a命令可以显示全部容器，不加-a仅列正在运行的容器，未运行或退出的容器将不会被列出来。ps=process status。 docker run imageName 运行imageName这个镜像，得到一个容器。如：docker run -it ubuntu /bin/bash，-i表示交互式操作，-t表示终端，ubuntu为镜像名称，放在镜像名后的是命令，这里我们希望有个交互式 Shell，因此用的是 /bin/bash。若想在后台运行Docker服务，则需要通过-d指定容器的运行方式。 如：docker run -itd --name ubuntu-test ubuntu /bin/bash，另外可以通过：docker run -t -i ubuntu:18.04 /bin/bash ，可以运行不同tag标签的镜像。 docker exec containerId 进入Docker容器，这里指进入后台运行的容器，如果从这个容器退出，不会导致容器的停止。如：docker exec -it id /bin/bash docker attach containerId 同为进入已经开启的容器中，如果从这个容器退出，会导致容器的停止。 exit 接在控制台输入exit即可退出当前镜像。 docker stop containerId 停止容器。 docker start/restart containerId 通过容器id开启或重启容器。 docker rm containerId 删除容器，这个操作需要十分小心，因为是不可逆的操作，比如你在容器中写的代码，文档将会全部丢失。 docker rmi imageName 删除镜像，需要注意的是再删除镜像的时候需要将正在运行的容器先删除掉。 docker container prune 清理掉所有处于终止状态的容器。 docker top containerId 使用docker top来查看容器内部运行的进程。一般用不到。 docker login/logout 登入登出Docker Hub账号，这样就可以下载自己仓库中的镜像了。 注意事项 安装软件时最好提前将ubuntu的软件源换为国内镜像，不然速度慢到你难以想象，这里在安装好后已经及时对软件源进行了更新。 参考教程 菜鸟教程","link":"/blogs/2020/02/28/Docker%E5%88%9D%E4%BD%93%E9%AA%8C/"},{"title":"Docker可视化界面","text":"泡泡机器人SLAM与你一同成长❤ 可视化 其实关键就是添加一个可视化的应用，如X11 apps (and GL), is the key for display inside the docker，e.g. 12345678#!/bin/bash# This file is covered by the LICENSE file in the root of this project.docker build -t api --build-arg uid=$(id -g) --build-arg gid=$(id -g) .docker run --privileged \\ -ti --rm -e DISPLAY=$DISPLAY \\ -v /tmp/.X11-unix:/tmp/.X11-unix \\ -v $1:/home/data/ \\ api 1docker run --privileged -ti --rm -e DISPLAY=$DISPLAY -v /tmp/.X11-unix:/tmp/.X11-unix -v /home/amazinghao/Data:/home/data/ api -e DISPLAY=$DISPLAY，after this the gui inside the docker will show in the host machine --privileged，will make all extend equippment available for the docker 打开界面 有几种方式可以在Docker中设置界面，openbox，vnc等。这里选择的是ros-vnc来进行可视化界面的，vnc其实是一个功能， ubuntu自带的某些软件也有这个功能,VNC-Viewer免费版即可。 比如直接启动如下容器： 1docker run -it -p 5900:5900 paopaorobot/ros-vnc 调整分辨率 1docker run -it -p 5900:5900 -e RESOLUTION=1980x1200 paopaorobot/ros-vnc 通过ssh连接 打开本机控制台，输入： 1docker run -it -p 2222:22 paopaorobot/ros-vnc ssh -o 'UserKnownHostsFile=/dev/null' root@localhost -p [port] port表示端口号，保持和开启镜像时映射的端口一致。在控制台使用下述ssh链接打开的容器：ssh root@localhost -p 2222 也可以设置自定义的ssh密码,如asc123 1docker run -it -p 2222:22 -e SSHPW=asc123 paopaorobot/ros-vnc 也可以随机选择端口号，P会系统自动给一个端口，可以避免端口冲突 1docker run -it -P paopaorobot/ros-vnc 通过docker port查看当前开了哪些端口，然后找到想要的端口 同时使用ssh和可视化界面 12docker run -it -p 5900:5900 -p 2222:22 paopaorobot/ros-vncdocker run -itd -p 5900:5900 -e SSHPW=usmn9a -e RESOLUTION=1920x1280 -v /d/data:/data -p 2222:22 amazinghao/ubuntu:graph_slam_updated -p 将本地5900端口映射到容器，服务于vnc进行可视化 -e SSHPW= 设置ssh连接的密码为xxx -p 将本地2222端口映射到容器，服务于ssh进行连接 -e RESOLUTION=1920x1280 设置分辨率为1080p -v 表示将本地D:/data路径挂在到容器对应的/data下，amazinghao/ubuntu:graph_slam_updated 为镜像名。 退出之后再打开 按照前述方法用vnc或者ssh打开Docker的一个镜像并生成容器之后，通过exit退出当前容器，若是后续还想再进去，此时如果通过run命令就会再次产生一个容器，而你在之前的容器中所做的操作就不会保留。 因此这时需要通过start，打开之前操作过现在状态是exit的容器，用attach建立连接，此时如果通过docker ps -a可以发现之前的容器又可以打开了,并且端口号是可用的。 另外如果想要在exit容器时，容器不退出，应该使用exec命令打开镜像docker exec -it 24d1106f11b8 /bin/bash,此时也会发现容器时可用的了。 深度学习环境的界面可视化 在使用3D Gaussian Splatting进行场景重建时，有一个可视化界面需要使用，因此需要直接能够从Docker容器中打开，在容器初始化时需要做一些额外的配置， 1docker run -itd --name=3dgs -e TZ=\"Asia/Shanghai\"--shm-size=32g --gpus 'all,\"capabilities=compute,utility,graphics\"' --privileged=true -v /tmp/.X11-unix:/tmp/.X11-unix -e DISPLAY=unix$DISPLAY -v /home/amazinghao/Data:/public -v /home/amazinghao:/workspace pytorch/pytorch:2.1.2-cuda12.1-cudnn8-devel /bin/bash 既有了cuda支持，又有了可视化界面。 Docker远程Debug 首先代码是在本地，以文件夹挂载的方式挂载到容器中。 Python文件的Debug 这里借助的是vscode来实现代码Debug。首先通过Remote-Container/Remote-SSH插件连接到容器中，点击运行-&gt;打开配置，即如下类似的文件settings.json（位于本地.vscode路径下）： 123456789101112131415161718192021222324{ // 使用 IntelliSense 了解相关属性。 // 悬停以查看现有属性的描述。 // 欲了解更多信息，请访问: https://go.microsoft.com/fwlink/?linkid=830387 \"version\": \"0.2.0\", \"configurations\": [ { \"name\": \"Python: 当前文件\", \"type\": \"python\", \"request\": \"launch\", \"program\": \"main.py\", # 主函数入口 \"console\": \"integratedTerminal\", \"justMyCode\": true, \"args\": [ //在这里写命令行的参数，如下 \"--dataset\", \"ETH\", \"--estimator\", \"4DOF\", \"--topk\", \"6\", \"--inlierd\", \"0.2\", \"--tau_2\", \"0.5\", \"--rr\" ] } ]} 设置好之后可以F5开启调试了，打断点和单步调试都可以用。 C++的Debug TODO 其他问题 vnc首次可以连接成功，但是再次连接时失败，打开vnc5900时提示，connected closed unxepectedly。 解决方案： 这是需要使用start将上次的docker容器打开就可以了，连接失败的原因可能是因为端口被占用了。","link":"/blogs/2020/07/11/Docker%E5%8F%AF%E8%A7%86%E5%8C%96%E7%95%8C%E9%9D%A2/"},{"title":"Hdl_graph_slam论文及代码解析_回环检测","text":"回环检测 ​ 闭环的作用就不多说了，koide采用的闭环检测方法其实挺简单的，就是一般闭环检测的基础准则。 候选准则 候选帧不能离当前帧太近，场景变化不大的话，会引入过多的冗余匹配，对实时应用不合适； 候选帧和当前帧的位姿之间的距离要足够小，这个是前提，如果都不小，那说明大概率不是闭环了，但是也不排除前端飘得确实很厉害的情况；小范围内，这个条件还是可以满足的，室外更大的场景，这种就不行了，可能飘得很厉害，只能上特征了。 候选帧确认 ​ 前面只是拿到了一堆可能是候选帧的集合（这里回环候选帧是从历史帧中拿到的），还需要进一步判断到底能不能作为闭环帧，这里判断的依据就是对候选帧\\(lp_{candidate}\\)和当前新来的关键帧\\(kf_{current}\\)做一次点云匹配，采用的就是他们组之前的工作Fast GICP、NDT_OMP做两帧点云的匹配。计算一个sum of squared error 得分score，如果这个score小于阈值，则说明可以接受其作为回环帧。具体点，利用从前端得到的两帧点云的位姿g2o::VertexSE3* node计算一个初始的相对位姿\\(T_{candidate}^{current} = T_{candidate}^{-1}·T_{current}\\)，作为配准初始位姿开始配准，这么做是为了提升配准方法收敛的可能性。匹配完之后返回一个度量，依据这个度量做最终的判断。 回环检测流程 ​ 前端开始工作，得到序列化的关键帧\\(kfs\\)，整个SLAM系统开启的同时回环检测线程就开始工作了，一直在不断的积累关键帧，一定程度（这里可能是延时开启，或者给定关键帧数量阈值）之后，开始做候选回环帧的检测。做回环检测是在新来一帧关键帧\\(kf_{current}\\)之后就开始的（因为要同时进行局部位姿优化得到更加准确的当前帧的位姿），通过上述候选准则，与历史帧中的关键帧进行比较，从中删选出满足条件的关键帧作为当前关键帧\\(kf_{current}\\)的回环候选帧\\(lp_{candidate}\\)，因为候选回环帧可能不是一个，而是一系列组成集合\\(LP_{candidate}\\)（场景变化不大时，都很像），从\\(LP_{candidate}\\)中找到得分最高的候选帧作为最终的回环帧\\(kf_{loop}\\)。 注： 回环检测结果一定要鲁棒且正确，因为如果一旦引入一个错误的闭环，整个后端就崩掉了。当然现在大部分工作都是引入特征描述子了，不仅几何空间，在特征空间也同样进行检测，极大提升回环的召回率。这里就先不介绍了。 如果候选帧的筛查是在特征空间完成的（相对位姿可直接根据匹配对SVD分解得到），后面通常会跟一个几何验证模块，即又是一个点云匹配过程，类似于ICP或者NDT得到从几何角度拿到的相对位姿，与特征匹配得到的相对位姿进行对比，完成进一步确认。 闭环优化 误差来源 ​ 每一个激光帧的位姿都是通过匹配（无论是scan2scan or scan2map）得到的，每一次匹配求位姿都存在偏差，因此检测到回环的时候肯定就互相对不上了，就存在观测值（匹配的T）与估计值（一步步叠加得到的T）之间的偏差。 \\[ e=(\\check{T}_i^j)^{-1}T_{jw}^{-1}T_{iw} \\] ​ 这里的误差表示和视觉SLAM14讲中的PGO优化时采用的表达方式是一样的。\\(T_{iw},T_{jw}\\)分别表示世界坐标系下两个激光关键帧的位姿，\\(\\check{T}_i^j\\)表示的是从i到j的相对位姿（也就是闭环检测估计出来的相对位姿，可以视为观测值）。\\(T_{jw}^{-1}T_{iw}\\)表示的就是用这两个激光关键帧通过前端不断积累之后的位姿所表示的两帧之间的相对位姿。 e对两个节点位姿的jacobian公式推导1 TODO... 回环边的构建 ​ 得到当前激光关键帧\\(kf_{current}\\)的回环帧\\(kf_{loop}\\)之后，就可以构建回环边了，引入回环约束，开始后端优化。 ​ 检测出来的回环存储于Loop结构体中，其实光看Loop的定义，无法确定relative_pose描述的是谁到谁的变换，还需要实际看使用的时候的传入参数。hdl_graph_slam中采用的是\\(T_{loop}^{current}\\)，检测到的回环帧\\(kf_{loop}\\)到当前关键帧\\(kf_{current}\\)的变换，也就是key2\\(\\Rightarrow\\)key1。 1234567891011struct Loop {public: EIGEN_MAKE_ALIGNED_OPERATOR_NEW using Ptr = std::shared_ptr&lt;Loop&gt;; Loop(const KeyFrame::Ptr&amp; key1, const KeyFrame::Ptr&amp; key2, const Eigen::Matrix4f&amp; relpose) : key1(key1), key2(key2), relative_pose(relpose) {}public: KeyFrame::Ptr key1; KeyFrame::Ptr key2; Eigen::Matrix4f relative_pose;}; ​ 回环边的构建如下： 123456789g2o::EdgeSE3* GraphSLAM::add_se3_edge(g2o::VertexSE3* v1, g2o::VertexSE3* v2, const Eigen::Isometry3d&amp; relative_pose, const Eigen::MatrixXd&amp; information_matrix) { g2o::EdgeSE3* edge(new g2o::EdgeSE3()); edge-&gt;setMeasurement(relative_pose); edge-&gt;setInformation(information_matrix); edge-&gt;vertices()[0] = v1; edge-&gt;vertices()[1] = v2; graph-&gt;addEdge(edge); return edge;} ​ 回环边连接的两个顶点是用g2o::SE3表示的顶点，表示关键帧的位姿世界坐标系下，相对于第一帧的位姿。观测值是两个节点之间的相对位姿，采用Eigen::Isometry3d表示。构建的边的类型是用g2o::EdgeSE3表示的，计算的误差是一个6维的向量。g2o中的实现如下： VertexSE3，g2o中采用Eigen::Isometry3来描述当前帧的位姿 12345678910111213/** * \\brief 3D pose Vertex, represented as an Isometry3 * * 3D pose vertex, represented as an Isometry3, i.e., an affine transformation * which is constructed by only concatenating rotation and translation * matrices. Hence, no scaling or projection. To avoid that the rotational * part of the Isometry3 gets numerically unstable we compute the nearest * orthogonal matrix after a large number of calls to the oplus method. * * The parameterization for the increments constructed is a 6d vector * (x,y,z,qx,qy,qz) (note that we leave out the w part of the quaternion. */class VertexSE3 : public BaseVertex&lt;6, Isometry3&gt; {...} EdgeSE3，误差同样也是一个VertexSE3型的变量表示的，而VertexSE3实际上是Isometry3，Isometry3实际上又是（x,y,z,qx,qy,qz）不表示缩放。 123456789101112131415161718192021EdgeSE3 : public BaseBinaryEdge&lt;6, Isometry3, VertexSE3, VertexSE3&gt;{ ... // 虽然代码中的注释写明，这个误差表示的是j到i节点的变换的，z^-1 * (x_i^-1 * x_j)误差应该是这样的，但是实际写的时候好像写反了 void EdgeSE3::computeError() { VertexSE3 *from = static_cast&lt;VertexSE3*&gt;(_vertices[0]); VertexSE3 *to = static_cast&lt;VertexSE3*&gt;(_vertices[1]); Isometry3 delta=_inverseMeasurement * from-&gt;estimate().inverse() * to-&gt;estimate(); _error=internal::toVectorMQT(delta); } ...}// 其中Isometry3转换为6维的误差Vector6 toVectorMQT(const Isometry3&amp; t) { Vector6 v; // 表示从变换矩阵t中提取旋转矩阵，再转为归一化的四元数，返回四元数的实部，放在返回向量的后三位 v.block&lt;3,1&gt;(3,0) = toCompactQuaternion(extractRotation(t)); // 下面表示直接将平移从t中提取出来放在返回向量的前三位 v.block&lt;3,1&gt;(0,0) = t.translation(); return v;} ​ 加入到图中： 1234567891011// loop detection, should be false in first round of detection but it's correctstd::vector&lt;Loop::Ptr&gt; loops = loop_detector-&gt;detect(keyframes, new_keyframes, *graph_slam);for(const auto&amp; loop : loops) { Eigen::Isometry3d relpose(loop-&gt;relative_pose.cast&lt;double&gt;()); // calc_information_matrix is a reweight procedure Eigen::MatrixXd information_matrix = inf_calclator-&gt;calc_information_matrix(loop-&gt;key1-&gt;cloud, loop-&gt;key2-&gt;cloud, relpose); auto edge = graph_slam-&gt;add_se3_edge(loop-&gt;key1-&gt;node, loop-&gt;key2-&gt;node, relpose, information_matrix); graph_slam-&gt;add_robust_kernel(edge, private_nh.param&lt;std::string&gt;(\"loop_closure_edge_robust_kernel\", \"NONE\"), private_nh.param&lt;double&gt;(\"loop_closure_edge_robust_kernel_size\", 1.0));} 个人觉着，将回环边加入到图中时，顶点的添加顺序应该和相对位姿的作用方向严格对应，假设1&amp;2节点互换，相对位姿也求逆就可以了。 有小伙伴说VertexSE3在g2o中的实现是采用的右扰动，因此，和一般常见的左扰动不一致，就有点突然...也确实是这样的，亲测如此。 GPS点约束 ​ hdl_graph_slam中GPS信号是不断接收的，因此会有一个时间戳，通过硬件同步之后，激光和GPS完成时间同步，就可以通过时间找到最近GPS点对应的激光帧的位置，从而构建关系。 将一段滑窗内的gps点与攒起来的激光关键帧进行时间戳比较的时候，虽然找的是最近的，但是万一最近的gps点和某关键帧之间的时间差还是差很多，依然是无法建立关系的，需要及时剔除。 GPS点是WGS84坐标系下的，需要转成空间直角坐标系UTM下的北东高坐标才行。 误差方程 \\[ e=G(t)-p \\] 这种表示方法，说明一个gps点只能控制位置，无法控制旋转，因此没有R什么事情。 gps边的构建 ​ 构建一元边，GPS节点是固定的。koide这里认为gps定位结果如果认为xyz都有效，则使用add_se3_prior_xyz_edge类型的边，如果只有平面左边有效，则使用add_se3_prior_xy_edge，信息矩阵的权重和观测精度有关。这里认为信息矩阵就是协方差的逆，协方差可以看成是在三个维度上观测值的方差。 ​ 构建的一元边的类型分别是：g2o::EdgeSE3PriorXY和g2o::EdgeSE3PriorXYZ,都比较好理解。koide在使用时，误差采用的是估计值-观测值，和我的理解相反了，不过不影响结果。 123456void computeError() override { const g2o::VertexSE3* v1 = static_cast&lt;const g2o::VertexSE3*&gt;(_vertices[0]); // only translation is used Eigen::Vector3d estimate = v1-&gt;estimate().translation(); _error = estimate - _measurement;} ​ 加入到图： 123456789if(std::isnan(xyz.z())) { Eigen::Matrix2d information_matrix = Eigen::Matrix2d::Identity() / gps_edge_stddev_xy; edge = graph_slam-&gt;add_se3_prior_xy_edge(keyframe-&gt;node, xyz.head&lt;2&gt;(), information_matrix);} else { Eigen::Matrix3d information_matrix = Eigen::Matrix3d::Identity(); information_matrix.block&lt;2, 2&gt;(0, 0) /= gps_edge_stddev_xy; information_matrix(2, 2) /= gps_edge_stddev_z; edge = graph_slam-&gt;add_se3_prior_xyz_edge(keyframe-&gt;node, xyz, information_matrix);} IMU观测 误差方程 TODO IMU边的构建 TODO 整个后端优化流程 ​ ros环境下用roslaunch随便启动一个hdl_graph_slam的launch文件，都会启动如下四个节点：prefiltering_nodelet, scan_matching_odometry_nodelet， floor_detection_nodelet， hdl_graph_slam_nodelet，看名字就知道对应的功能是什么了。其实我对ros不熟悉，认为一个launch文件通过配置多个nodelet的方式同时启动多个节点就相当于实例化出多个对象，每个对象都可以开始做事情，之间可以快速的数据共享2。这些节点都是nodelet的派生类。 ​ prefiltering_nodelet节点主要负责接收从硬件传回来的点云数据，完成去畸变，简单距离过滤等操作，然后将其逐帧发布为/filtered_points主题。 ​ scan_matching_odometry_nodelet负责前端匹配，发布里程计消息。它也订阅了/filtered_points话题，一旦检测到消息，就调用cloud_callback() ，将传入的点云逐帧和之前的帧进行匹配，得到以前一帧点云为基准的相对位姿，并返回以全部帧中第一帧为基准的世界坐标下的位姿，核心是matching()函数。要随着激光帧的不断发布和接收，将new frame的位姿视为下一次前端匹配中的old frame的位姿，并以当前的匹配估计值作为下一次匹配的先验，提升匹配成功的概率。 \\[ T_{source}=T_{new keyframe}^{w}\\\\ T_{target}=T_{old frame}^{w}\\\\ T_{source}^{target} = T_{new keyframe}^{old keyframe} = matching()\\{ICP,NDT \\quad liked \\quad method\\} \\] ​ hdl_graph_slam_nodelet在一开始初始化的时候就自动订阅如下的主题，并开始循环接受其发出的消息：看名识功能 1234567/odom;/filtered_points;/gpsimu_driver/imu_data;/floor_detection/floor_coeffs;/gps/geopoint;/gpsimu_driver/nmea_sentence;/gps/navsat， ​ hdl_graph_slam_nodelet在初始化时通过订阅/odom和/filtered_points的消息并调用cloud_callback()，将估计的里程计位姿和点云绑定在一起，并检查当前帧是否构成成为关键帧的条件，满足才会将关键帧留下来。 ​ hdl_graph_slam_nodelet还包含了成员optimization_timer和map_publish_timer，都是ros下的一个定时器3类型，且在其虚函数onInit()函数中做了初始化。这两个定时器分别表示每隔3s做一次优化和每隔10s发布一次地图点的两个不同操作。optimization_timer_callback()和map_points_publish_timer_callback()就是定时器到点了之后执行的函数。 123456double graph_update_interval = private_nh.param&lt;double&gt;(\"graph_update_interval\", 3.0);double map_cloud_update_interval = private_nh.param&lt;double&gt;(\"map_cloud_update_interval\", 10.0);optimization_timer = mt_nh.createWallTimer(ros::WallDuration(graph_update_interval), &amp;HdlGraphSlamNodelet::optimization_timer_callback, this);map_publish_timer = mt_nh.createWallTimer(ros::WallDuration(map_cloud_update_interval), &amp;HdlGraphSlamNodelet::map_points_publish_timer_callback, this); ​ optimization_timer_callback()回调函数中，首先执行flush_keyframe_queue()判断是否有关键帧更新，并对已有的关键帧构建成图，包括添加节点，构建序列节点之间的边（观测就是相对位姿\\(T_{curr}^{prev}=T_{curr}^{-1}·T_{prev}\\)，估计值就是各自的位姿）。关键帧更新成功之后，开始依次调用flush_floor_queue(), flush_gps_queue()和flush_imu_queue()，功能分别是： flush_floor_queue()： 首先需要知道floor_detection_nodelet在一开始系统启动的时候就存在了，同时该节点会自动订阅/filtered_points节点的消息，收到消息之后就会执行cloud_callback()回调函数（onInit函数中），立马针对接收到的点云提取平面，发布平面参数。hdl_graph_slam_nodelet通过订阅相应的主题，就可以拿到平面提取结果。所有的平面提取结果是通过时间戳的形式和每一个关键帧建立关系的。因此flush_floor_queue()就是要通过时间比对，找到对应关系，往图中添加平面节点。 flush_gps_queue()：在hdl_graph_slam_nodelet的onInit()中设置了如果当前环境支持gps，就会自动分别从\"/gps/geopoint\", \"/gpsimu_driver/nmea_sentence\"和\"/gps/navsat\"节点订阅消息，分别执行gps_callback(), nmea_callback()和navsat_callback()。gps_callback()负责将现有的gps数据存储下来到队列中，nmea_callback()和navsat_callback()一样都是用已经写好的驱动包读取（解析）GNSS数据然后调用gps_callback()4，这样就把需要的数据都接收完了。然后flush_gps_queue()主要是通过时间检查，关联gps点和关键帧，找到对应关系，往图中添加gps节点。 flush_imu_queue()：TODO... ​ 这些传感器的约束就通过这三个函数引入了，如果这三个全都没有，直接退出优化，没有额外的观测，无法平差。其中任意一个有的话就继续。 ​ 接下来就开始回环检测，将检测到的回环帧们构建成回环约束加入到图中。用于回环检测的对象是，当前时刻之前攒下的局部滑动窗口中的关键帧和现存的关键帧集合，一开始是空的，隔一段时间之后才会有积累，因此第一次loop detection肯定返回false的。然后将临时的关键帧拷贝到集合中。最后就开始图优化的过程了。LiDAR SLAM的图优化这里没用什么技巧，就是正常的选择求解器，设定循环次数，开始优化就结束了。优化完之后每个节点的位姿通过KeyFrameSnapshot和KeyFrame的转换（内部构造函数）中直接将图的节点位姿传递给关键帧的位姿，用于保存。 ​ map_points_publish_timer_callback()就是将通过绑定的位姿将optimization_timer_callback()优化好的关键帧中的点云变换到统一的世界坐标系下，并抽稀，然后发布就完了。 Reference 在最新版的g2o中已经变成了和ceres一样的自动求导了... ↩︎ https://m.jb51.cc/xml/294932.html ↩︎ https://www.ncnynl.com/archives/201702/1296.html ↩︎ 实际中可能IMU中也集成了一个GNSS，因此有两个 ↩︎","link":"/blogs/2025/02/08/Hdl_graph_slam/"},{"title":"Hdl_graph_slam论文及代码解析_后端优化","text":"1. 针对性设计的平面提取方法 ​ 因为这里使用的传感器其实一个组装的VLP16型多线激光雷达+相机+imu的背包激光扫描仪，作者考虑到LiDAR有一定的安置误差(提前肯定标定了的，e.g.倾角)，而本文使用的又是室内场景平面，因此需要根据一个仪器安装的先验确定z轴方向指向哪里（默认传感器的坐标系为右前上，z轴指向天空）。得到这个倾角主要是为了修正LiDAR坐标系的z轴方向。这对后续的高度滤波和地面点判断都有一定的影响。 ​ 在提取平面时，为了提升效率，首先基于扫描仪的高度，通过高度滤波将一定高度之外的点去掉，同时对剩下的点云计算法向量（通过提前性的点云剔除，可以提升这里的计算效率）进行过滤，和z方向进行比较，保留地面点（和z轴夹角小就说明方向近似），用RANSAC的方式拟合平面参数方程。 这样就可以以较快的速度从单帧点云中提取出一个合适的平面。注意：原文中写的是直接用RANSAC提取平面的，这个非常的费时间，实际操作并不是这样子来的。 ​ 平面参数方程采用一般形式进行表达： \\[ \\begin{align} \\pi &amp;:= n_x*x+n_y*y+n_z*z+d=0 \\\\ \\pi &amp;:= [(n_x,n_y,n_z),d] \\end{align} \\] 2. 平面节点的构建以及优化 ​ 平面参数拿到之后如何抽象成为图中的一个节点，并参与优。在优化时，其实并不是所有帧都提取平面的，作者每隔10s从一个关键LiDAR帧中提取一个平面，然后引入到PGO中。不然也算不过来。 平面约束从何而来 ​ 约束嘛，肯定得有参考，作者的实验场景是室内，提取的还是地面，可想而知，约束是通过__该平面__（提取平面）的参数与__世界坐标系下的xoy平面平行的一个平面__（参考平面）确定的。更具体地，假设在t时刻从当前LiDAR激光帧中提取的平面方程为\\(\\pi(t):[n_p,d_p]\\)(local坐标系下,这里省略了\\(n_p(t),d_p(t)为n_p,d_p\\))，而给定的世界坐标系(canonical or world)下的参考平面方程为\\(\\pi(0):[n_b,d_b]\\)，也就是\\(\\pi(0):[(0,0,1),0]\\)(和其他方向的平面需要设置不同的法向量朝向)。即： \\[ \\begin{align} nx_p*x+ny_p*y+nz_p*z+d_p=0 \\\\ \\\\ nx_b*x+ny_b*y+nz_b*z+d_b=0 \\end{align} \\] ​ 这两个平面之间的差，两个平面之间的差需要比较法向量和截距（排除平行的情况）： 如果当前LiDAR帧的位姿估计的准确的话，提取得到的平面的法向量\\(n_p\\)应该和\\(n_b\\)是相近的，截距应该是相等的，排除沿着法向方向的平移现象： 作者这里参照的其实是一个发表在ICRA2016上的文章Cpa-SLAM1，中的方法完成了两个平面方程的参数化过程， \\[ \\pi := [(n_x,n_y,n_z),d]\\quad \\Longrightarrow \\quad\\tau(\\pi)=[arctan(\\frac{n_y}{n_x}),arctan(\\frac{n_z}{|n|}),d] \\] ​ \\(arctan(\\frac{n_y}{n_x}),arctan(\\frac{n_z}{|n|})\\)分别表示的是球坐标系下的azimuth（方向角）和elevation（高度角）\\(|n|\\)应该是在水平面内的投影。具体这么参数化的好处是啥呢，暂时还没有了解清楚，TODO... ​ 此外还需要注意的是注意： 平面约束是如何与节点位姿建立关系呢？（这个是平面可以作为约束参与优化的基础） 这里就涉及到一个坐标系转换的问题，一个是LiDAR点云帧的local系(因为点云就是从这个里面提取出来的)，一个是假定的canonical（world）系，两个需要在同一的坐标系下才能做运算，有两种思路，1）都变换到world下（koide采用的就是这种思路）；或者都同一变到canonical(world)坐标系下。这里就需要知道每一个LiDAR点云帧都保留了其在world坐标系下（相对于第一帧）的位姿\\(T_{iw}\\),通过\\(T_{iw}\\)可以将平面\\(\\pi(0)\\)变换到\\(\\pi(t)\\)的坐标系下，实现统一。 如何对一个平面进行变换？假设现在有了一个平面\\(\\pi\\)，在经过T变换之后，对应的平面参数\\(\\pi^{'}\\)应该是什么呢？如下所示。证明参见 \\[ \\pi^{'}=(T^{-1})^T·\\pi=(T^T)^{-1}·\\pi = \\left[ \\begin{array}{cc} R^{T} &amp; 0^{T} \\\\ -R^{T}t &amp; 1\\end{array} \\right]· \\left[ \\begin{array}{cc} n \\\\ d \\end{array} \\right] = \\left[ \\begin{array}{cc} R^Tn \\\\ d- R^Ttn \\end{array}\\right] \\] hdl_graph_slam中使用的参考平面为世界坐标系下的参考平面为\\(\\pi(0):[(0,0,1),0]\\)，而LiDAR激光帧的位姿\\(T_{iw}\\)表示的就是世界坐标系下的坐标，只是相对于第一帧而言的，因此从local系提取得到的平面参数中法向量本身可以看成是和\\([0,0,1]\\)的差，那么在计算误差时直接就可以将\\(\\tau(t)\\)看成是\\(e\\)误差，只需要对截距t做变换\\(T_{iw}\\)即可了，而这里使用的是地面，d=0，就省略了这一部分在实际代码中有所体现。（PS：更加复杂的情况需要修改g2o中的代码才行，不太行的样子...） 误差方程的构建 误差=观测值-预测值（通常是这样的，如果反过来只会影响jacobian的方程，对结果没有影响） 这里将变换到当前LiDAR坐标系下的\\(\\pi(0)\\)作为了观测值，提取的平面作为了预测值（按照我的理解，和他正好是反的，但是对结果没有啥影响） \\[ \\begin{aligned} 一直和z方向比:\\quad e = \\tau(\\pi(0)^{'}) - \\tau(\\pi(t)) \\\\ 和前一个提取的平面参数比:\\quad e = \\tau(\\pi(t-1)^{'}) - \\tau(\\pi(t)) \\end{aligned} \\] 最小二乘优化它的二次型即可。 \\[ E = e^T \\Omega e \\] a b 平面参与优化过程 ​ hdl_graph_slam中平面检测和LiDAR关键帧是放在独立的deque中存储的，又通过消息的发布和接收进行数据共享。运行launch时，会自动开启好几个nodelet，e.g.HdlGraphSlamNodelet, floor_detection_nodelet, ScanMatchingOdometryNodelet, PrefilteringNodelet。这几个nodelet处于一个进程中，但是可以独立干自己的事情，通过消息的publish和subscribe进行完成消息共享。 ​ 前端里程计在不断的完成关键帧的位姿估计，并存放在队列中，平面检测是每隔10s进行的（提取平面），也将估计结果存放在另一个队列中（1hz&lt;10hz的LiDAR帧率，而且LiDAR关键帧更低）。将选择得到的关键帧的与时间戳绑定，平面检测结果也和时间戳绑定，这样就可以通过时间上的对比完成两个数据之间的同步（或者称为数据关联）。完成平面提取结果和关键LiDAR帧的绑定之后，就可以构建平面约束了。引入图中的平面节点是canonical（world）坐标系下的平面（参考平面），也就是\\(\\pi(0):[(0,0,1),0]\\),利用与之时间匹配的LiDAR的pose，将参考平面和提取平面坐标系统一起来，构建平面约束边，误差计算方法是：首先将参考平面通过当前LiDAR帧pose（local系，表示世界坐标系下相对于第一帧的位姿？）的逆，变换到LiDAR点云的local系，然后和估计RANSAC估计出来的平面（本身就在local系下）做差。这一套都完成之后就构建好了一条平面边，加入到图中。如上图a 3. 源码解析 1. 平面提取 ​ 其实代码这部分和上述描述一致，注释好的代码见本仓库app/floor_detection_nodelet.cpp。 2. 引入平面节点的过程 ​ 实际引入过程和上述描述一致，注释好的代码见本仓库app/HdlGraphSlamNodelet-&gt;optimization_timer_callback()-&gt;flush_floor_queue()。 3. g2o已经实现好的平面节点以及边 注意：这个EdgeSE3Plane是koide自己实现的，可能和原始g2o中的不太一样。 12345678910111213141516171819202122232425/** * @brief plane edge, the error is stored as g2o::Plane3D(in fact is a vector3 but should be initialized by vector4(plane coefficient)) */class EdgeSE3Plane : public g2o::BaseBinaryEdge&lt;3, g2o::Plane3D, g2o::VertexSE3, g2o::VertexPlane&gt; {public: EIGEN_MAKE_ALIGNED_OPERATOR_NEW EdgeSE3Plane() : BaseBinaryEdge&lt;3, g2o::Plane3D, g2o::VertexSE3, g2o::VertexPlane&gt;() {} // error is 3d vector, azimuth, elevation, the length of intercept respectively void computeError() override { // current node pose const g2o::VertexSE3* v1 = static_cast&lt;const g2o::VertexSE3*&gt;(_vertices[0]); // plane node (canonical plane coeff is used here as observations) // i believe the estimate plane here is both ok, but TODO figure out) const g2o::VertexPlane* v2 = static_cast&lt;const g2o::VertexPlane*&gt;(_vertices[1]); // v1 is the pose in canonical(world) coordinate // w2n represents the transformation from canonical(world) to local // this pose should be understanded bind with whole plane node added to graph pipline Eigen::Isometry3d w2n = v1-&gt;estimate().inverse(); // transform the plane in canonical frame to current lidar coordinate Plane3D local_plane = w2n * v2-&gt;estimate(); // error should be measurement minus estimate value // i believe here is inversed but no effect to the result, given the eTe model _error = local_plane.ominus(_measurement); }} g2o定义的Plane3D给出了平面边误差方程的计算实现代码，其中实现的挺好的，就一个成员是Eigen::Vector4d,包含了从一个平面参数中提取球坐标系下方向角azimuth，高度角elevation等过程，重点关注求差__ominus，运算符*__重载过程（和上述讲的平面变换的过程一致）。 123456789101112131415161718192021222324252627282930313233343536373839Plane3D{...// update the current state, looks like its left-hand coordinate? BUGFIX// the rotation of elevation is countclockwiseinline void oplus(const Vector3&amp; v){ // construct a normal from azimuth and evelation; // this is from spherical coordinates to cartesian coordinate number_t _azimuth=v[0]; number_t _elevation=v[1]; number_t s=std::sin(_elevation), c=std::cos(_elevation); Vector3 n (c*std::cos(_azimuth), c*std::sin(_azimuth), s) ; // rotate the normal Matrix3 R=rotation(normal()); number_t d=distance()+v[2]; _coeffs.head&lt;3&gt;() = R*n; // the length of intercept is direct add but why negative? _coeffs(3) = -d; normalize(_coeffs); } inline Vector3 ominus(const Plane3D&amp; plane){ // construct the rotation that would bring the plane normal in (1 0 0) Matrix3 R=rotation(normal()).transpose(); Vector3 n=R*plane.normal(); number_t d=distance()-plane.distance(); return Vector3(azimuth(n), elevation(n), d); } };// exactly same with the plane transform formulainline Plane3D operator*(const Isometry3&amp; t, const Plane3D&amp; plane){ Vector4 v=plane._coeffs; Vector4 v2; Matrix3 R=t.rotation(); v2.head&lt;3&gt;() = R*v.head&lt;3&gt;(); v2(3)=v(3) - t.translation().dot(v2.head&lt;3&gt;()); return Plane3D(v2); };Vector4 _coeffs; // [n,d]...} 4. Reference Ma L, Kerl C, Stückler J, et al. CPA-SLAM: Consistent plane-model alignment for direct RGB-D SLAM[C]//2016 IEEE International Conference on Robotics and Automation (ICRA). IEEE, 2016: 1285-1291. ↩︎","link":"/blogs/2025/02/08/Hdl_graph_slam2/"},{"title":"Hexo进阶","text":"关于Hexo如何制作博客主页详见这里。 现象描述 ​ 按照hexo+github pages的博客搭建部署流程，hexo的博客主页会部署在https://yourgithubname.github.io/。本来没什么问题的，但是后面我想做一个个人主页（学术主页），按照academicpages/academicpages.github.io或者RayeRen/acad-homepage.github.io的方案，使用的也是https://yourgithubname.github.io/。这时候就有问题了，博客和个人主页的域名不就冲突了？ 我的目的是实现下面功能的东西。 从yourgithubname.github.io进入，访问的是我的个人主页。通过个人主页可以跳转到博客、建立页面。 从yourgithubname.github.io/blogs进入，访问的是我的博客，就是用hexo搭建好的。 从yourgithubname.github.io/resume进入，访问的就是我的一个个人简历。 本人菜鸡，完全不懂前端。尝试了几种不同的方案，包括切换repo分支的谜之操作，都试了，都不行。最后发现原来是对Hexo进行部署了解的不够细致。 Hexo部署过程 ​ 按照之前介绍Hexo搭建个人博客中的流程做好如下设置： 1234567891011121314151617# URL## If your site is put in a subdirectory, set url as 'http://yoursite.com/child' and root as '/child/'url: http://yourgithubname.github.io # 注意这里的url就是能够通过外网访问的博客主页链接，也就是Hexo将博客主页的内容放在了这个对应的同名仓库root: /permalink: :year/:month/:day/:title/permalink_defaults:pretty_urls: trailing_index: true # Set to false to remove trailing 'index.html' from permalinks trailing_html: true # Set to false to remove trailing '.html' from permalinks ... ... deploy: type: git repo: git@github.com:yourgithubname/yourgithubname.github.io.git branch: master ​ 然后执行hexo d，这样通过上面的url：http://yourgithubname.github.io就可以看到部署好的博客页面了。 1234567891011121314Mode LastWriteTime Length Name---- ------------- ------ ----d----- 2023-02-25 上午 11:45 .deploy_gitd----- 2023-02-06 上午 11:48 node_modulesd----- 2023-02-25 上午 11:44 publicd----- 2023-02-01 上午 11:08 scaffoldsd----- 2023-02-25 上午 09:24 sourced----- 2020-02-23 下午 04:10 themes-a---- 2020-02-23 下午 03:24 71 .gitignore-a---- 2023-02-25 上午 11:44 951152 db.json-a---- 2023-02-06 上午 11:48 138563 package-lock.json-a---- 2023-02-06 上午 11:48 678 package.json-a---- 2023-02-25 上午 11:56 203 README.md-a---- 2023-02-25 上午 11:44 3532 _config.yml 同时我在这个路径下初始化一个私有的仓库Blog，利用git管理这些写好的文件，防止丢失。也方便在不同的电脑端进行再次搭建。私有Blog仓库不会被别人访问到。别人只能看到yourgithubname.github.io这个仓库中的内容，但是这里面是经过处理的内容，无法逆向解析，我做不到。。。 Github Pages ​ GitHub Pages是GitHub提供的一个网页寄存服务，于2008年推出。可以用于存放静态网页，包括博客、项目文档甚至整本书。Jekyll软件可以用于将文档转换成静态网页，该软件提供了将网页上传到GitHub Pages的功能。一般GitHub Pages的网站使用github.io的子域名，但是用户也可以使用第三方域名。 ​ 按照Hexo博客部署的教程，我之前相当于开了一个yourgithubname.github.io的公有仓库，通过Pages的设置中的Build and deployment中激活了yourgithubname.github.io这个github上的次级域名。这个域名外网可以访问到。 ​ 那么部署是在做什么呢：简单来说就是在本地构建一个静态网页，然后发到特定的域名的过程。比如这里Hexo搭建的时候，通过Node.js帮我们搞了很多事情，利用Hexo提供的模板做了静态网页，然后用github pages蹭了一个域名，通过Hexo将网页信息部署到了https://yourgithubname.github.io主页的过程。部署时的内容生成到了yourgithubname.github.io这个仓库。（别人只能访问Hexo部署之后生成的文件） 理论上来说可以在github构建无限的公有仓库，都设置次级域名，都可以通过xxx访问了。 解决方案 新建一个blogs公开仓库（私有是不行的，和yourgithubname.github.io仓库同理），在仓库Settings中找到Pages,在Build and deployment中的Branch上设置main分支，/root路径，然后save。（中间可能会等一会，github pages响应一下）会发现在上方的GitHub Pages处，已经显示Your site is live at https://yourgithubname.github.io/blogs/了。（激活了新的次次级域名） 然后在Hexo的根目录下的_config.yml设置url和root如下：（调整网站部署的域名地址） 1234567891011121314151617# URL## If your site is put in a subdirectory, set url as 'http://yoursite.com/child' and root as '/child/'url: http://whu-lyh.github.io/blogs # 这个域名是新的已经更新的博客的主页地址，与blogs仓库同名root: /blogs # 这里按照要求也要修改permalink: :year/:month/:day/:title/permalink_defaults:pretty_urls: trailing_index: true # Set to false to remove trailing 'index.html' from permalinks trailing_html: true # Set to false to remove trailing '.html' from permalinks ... ... deploy: type: git repo: git@github.com:whu-lyh/blogs.git branch: main 重新hexo clean -g, hexo g, hexo d。 然后就成了。从https://yourgithubname.github.io/blogs访问博客页面了。 再说一下错误的方案： github仓库的setting中的Pages下面有个Custom domain，这个域名是要重新买的，搞一个CNAME，然后绑定到这里。就可以实现自定义域名访问了。 之前还试过调整yourgithubname.github.io这个仓库下面的分支，还以为调整分支能实现我的目的，结果发现完全不对。 个人主页 ​ fork一个academicpages.github.io，然后按照这个改一下，每次只需要修改内容之后push到对应的仓库，等待一会就自动部署到github.io上，即可看到页面更新了。如果不在本地预览，那么修改完主页内容之后，直接push到github.io的仓库就行， github pages会重新自动部署。 但是后面发现这个主页非常的臃肿，里面很多不需要的冗余内容，因此换成了这个。操作同理。 个人简历 ​ resume可以用类似的方式搞一个repo，然后找一些简历模板，css的。本地可以编辑好，采用和blogs相同的步骤部署就行。 也可以使用\\(\\LaTeX\\)来写，比如这里。直接在overleaf上面就能修改。 参考资料 https://blog.csdn.net/xuedan1992/article/details/83445756 https://goddywu.github.io/2018/02/24/%E4%BD%BF%E7%94%A8github%E5%AD%90%E7%9B%AE%E5%BD%95%E9%83%A8%E7%BD%B2hexo%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/ https://docs.github.com/en/pages/quickstart","link":"/blogs/2023/02/25/Hexo%E8%BF%9B%E9%98%B6/"},{"title":"Hexo初体验","text":"Hexo本身是一个静态博客生成工具，具备编译 Markdown、拼接主题模板、生成 HTML、上传 Git 或 FTP 等基本功能。本博客将不会介绍git实用技巧而是着重于介绍在Windows上hexo的搭建及测试过程 1、Node.js 安装 首先搭建hexo个人博客网站需要电脑中有Node.js环境，而Node.js即使是一个没有写过前端界面的人也可以完全傻瓜式安装完成的。参照官网下载对应版本Node.js。 另外如果你想要进一步学习Node.js这个强大的服务器端的JavaScript绚丽技术以及体验高性能服务配置技术，请移步这里 ,一路Next安装即可。最后在控制台或bash命令行上输入：node --version(或node -v)，以查看Node.js版本来验证否配置完成。 npm的install或者uninstall需要在安装Nodejs的目录下才能行，需要有package.json存在。 如果是在新电脑上安装之前的环境，直接npm install就能根据打包好的包的名字进行安装。npm install即可。 2、Hexo安装 在安装Node.js的时候一般来说会自动安装一个叫做npm的软件安装程序，功能类似于python中的pip以及linux下的apt-get。然后通过在本地路径打开命令行或git bash命令行，并输入：npm install hexo-cli -g，CLI = Command Line Interface为命令行界面。 2.1 Hexo初始化 在本地找个合适的位置新建一个文件夹，作为Hexo博客存放的位置，这里名为NotesRecording，并在此文件夹下打开控制台或bash命令行，并输入: hexo init NotesRecording，然后输入: hexo --version即可查看Hexo版本，如下: (这里采用了 icarus 主题，因此和你现在能看到的可能有所出入。) 在控制台或bash命令行输入：npm install，指定文件夹目录下有： node_modules: Hexo的依赖包，和插件 public：存放生成的页面,这些index.html都是要上传到服务器端的 scaffolds：生成文章的一些模板 source：用来存放编辑好的文章 source/_post：用来存放正式发布的文章 themes：存放喜欢的主题，比如本文的 icarus _config.yml: Hexo博客的配置文件 接着再运行：hexo server ，等待几秒之后，通过按照提示在本地浏览器打开 http://localhost:4000/ 网址，即可预览初始化好的Hexo博客界面。 2.2 Hexo配置以及主题修改 修改为中文：如 : language: zh-CN 修改Hexo的主题，可以从 官方主题 处寻找并下载。然后放置在themes路径下并在_config.yml配置文件中设置： 1theme: icarus(这里以icarus为例) 设置Hexo关联git 仓库，设置好关联的Git账号之后，就可以将每次写好的博客以及对Hexo的配置进行保存，方便后续进行回顾和修改。需要先安装hexo关联的git，命令如下：npm install hexo-deployer-git --save，在_config.yml文件中找到如下对应的地方，并修改: 1234deploy: type: git repo: https://github.com/yourGitName/yourGitName.github.io.git branch: master 配置好之后在控制台或者bash命令行中输入：Hexo -g -d，按照新的修改生成博客。 + 修改icarus配置文件，详见飞鱼的博客 + 在写博客时难免会有一些图片需要添加，Hexo在添加本地图片时需要修改两个地方： 找到Hexo下的_config.yml里的post_asset_folder，把这个选项从false改成true。 安装一个Hexo的插件npm install hexo-asset-image --save 即可。将图片放入这个文件夹，然后引用 3、环境配置好后就可以开始写博客啦 3.1 首先创建一个新的博客 1hexo new \"My New Post\" 本地文件夹中会出现一个名为“My New Post.md”的文档，如果在上述Hexo配置过程中开启了本地图片加载功能,则还会生成一个同名的文件夹，用来存放在.md文档中要上传的照片； 另外使用命令还会自动在md文档中生成一些头文件，包含属性信息，如下，可以更好地帮助构建Hexo界面上的文档显示。 新建文档时手动就该就行，自定义文件头的位置位于：/scaffolds/post.md`。如果是直接新建md文件，则只能手动拷贝一个合适的头文件到新建文档的最前面，就能正常显示了。 1234567---title: postName #文章页面上的显示名称，一般是中文date: 2020-02-28 23:38:32 #文章生成时间categories: 默认分类 #分类tags: [tag1,tag2,tag3] #文章标签，可空，多标签请用格式=description: 附加一段文章摘要，字数最好在140字以内，会出现在meta的description里面--- 3.2 博客预览 1hexo server (hexo -s) 通过在浏览器中打开 http://localhost:4000/ , 即可预览到刚刚创建好的博客内容，如有问题，可立马修改。 使用-p可以修改端口号。 3.3 生成Hexo文档 1hexo generate (hexo -g) 3.4 部署到远程服务器上 1hexo deploy (hexo -d) 打开对应的gitname.github.io即可查看博客啦。 4、注意事项 Hexo每次deploy，generate之后会加原来的文档资料全部覆盖掉，因此为了便于找回之前的内容，方便进行版本管理。建议使用github进行文档和操作同步，即在本地博客目录下同时初始化一个git仓库，每次更新完博客之后，随手进行仓库的同步更新，这样的话，将会极大地方便后续博客管理。 当你将写好的MarkDown文章推送到Hexo的时候，会发现Hexo默认显示了全部的文档内容，这对于博客内容比较多的人来说，显然是不合适的，因此有一个解决方案是：采用Html的语法，在合适的地方添加 ，当然也可以在hexo中设置&lt;!--more--&gt; 。 在generate之前最好再清理一下本地缓存，以免由于缓存更新延迟造成“误会”，hexo clean 。 如果出现下面的问题(在12.16.1版本上出现的非常频繁)，那么需要找到Nodejs的安装包，点击repair才能解决。 1234567891011121314151617181920212223internal/modules/cjs/loader.js:985 throw err; ^Error: Cannot find module 'D:\\SoftWare\\Nodejs\\node_modules\\npm\\bin\\npm-cli.js' at Function.Module._resolveFilename (internal/modules/cjs/loader.js:982:15) at Function.Module._load (internal/modules/cjs/loader.js:864:27) at Function.executeUserEntryPoint [as runMain] (internal/modules/run_main.js:74:12) at internal/main/run_main_module.js:18:47 { code: 'MODULE_NOT_FOUND', requireStack: []}internal/modules/cjs/loader.js:985 throw err; ^Error: Cannot find module 'D:\\SoftWare\\Nodejs\\node_modules\\npm\\bin\\npm-cli.js'\u001b[90m at Function.Module._resolveFilename (internal/modules/cjs/loader.js:982:15)\u001b[39m\u001b[90m at Function.Module._load (internal/modules/cjs/loader.js:864:27)\u001b[39m\u001b[90m at Function.executeUserEntryPoint [as runMain] (internal/modules/run_main.js:74:12)\u001b[39m\u001b[90m at internal/main/run_main_module.js:18:47\u001b[39m { code: \u001b[32m'MODULE_NOT_FOUND'\u001b[39m, requireStack: [] 5、问题记录 我个人常用的工作流是本地用Typora写好博客，然后用hexo部署到网页端。 5.1 Markdown冲突 Typora在写博客时可以手动添加目录，使用[TOC]，为了在hexo发布的时候页面也能显示目录，需要在.md文件的头部添加toc: true的标注。但是经过hexo发布之后，目录无法显示，目前考虑是一个不兼容的问题。如果想在发布的时候自动显示就不要手动添加[TOC]标记了。 Typora中的\\(\\LaTeX\\)代码公式渲染出来非常漂亮，但是经过hexo发布之后公式就出现了排版错误的情况。 要么是$$符号无法识别，要么是渲染出来和本地渲染结果不一样。由于我的hexo+icarus的版本比较老了，目前一些比较新的解决方案均无法实现，找了好久，试了很多都不行，最后找到一个适用于我的解决方案：主要问题应该就是渲染的问题，\\(\\LaTeX\\)代码写的应该没问题。首先npm uninstall卸载掉和math相关的所有库，e.g. hexo-math、hexo-filter-mathjax等，然后和官方的hexo-theme-icarus比较，看看少了哪些dependencies，e.g. hexo-renderer-marked、hexo-renderer-stylus、hexo-renderer-inferno等。pandoc需要独立安装。 1234567npm install hexo-renderer-marked --save # 原来icarus就是使用的marked作为渲染的# 上面的可以不用卸载，卸载了会发现hexo也没了，直接装hexo-renderer-pandoc就行。npm install hexo-renderer-pandoc --save # latex公式渲染之后，变得很奇怪，使用pandoc之后就和本地的一样了。但是得先装一个pandoc。# 下面的会自动安装上npm install hexo-renderer-ejs --savenpm install hexo-renderer-stylus --savenpm install hexo-renderer-inferno --save 最后得到package.json如下：（让然也可能有一些没用的dependencies）吓得我赶紧保存下来。 12345678910111213141516171819{ \"name\": \"hexo-related\", \"version\": \"1.0.0\", \"description\": \"\", \"main\": \"index.js\", \"dependencies\": { \"hexo-renderer-ejs\": \"^2.0.0\", \"hexo-renderer-inferno\": \"^0.1.3\", \"hexo-renderer-marked\": \"^6.0.0\", \"hexo-renderer-pandoc\": \"^0.3.1\", \"hexo-renderer-stylus\": \"^2.1.0\" }, \"devDependencies\": {}, \"scripts\": { \"test\": \"echo \\\"Error: no test specified\\\" &amp;&amp; exit 1\" }, \"author\": \"\", \"license\": \"ISC\"} Typora中使用markdown的语法进行脚注标记是正常的，但是hexo发布之后无法正常渲染。这个是hexo的问题，不是icarus主题的问题，有人曾说换用hexo-renderer-markdown-it可以解决，但是我尝试了，没用。但其实有用的是hexo-footnotes这个插件。 12npm install hexo-renderer-markdown-it --save #没用npm install hexo-footnotes --save #有用 一些关于markdown-it的插件解释。一顿操作之后的package.json文件。依然没反应。hexo-footnotes已经不再维护了。 12345678910111213141516171819202122{ \"name\": \"hexo-related\", \"version\": \"1.0.0\", \"description\": \"\", \"main\": \"index.js\", \"dependencies\": { \"hexo-renderer-ejs\": \"^2.0.0\", \"hexo-renderer-inferno\": \"^0.1.3\", \"hexo-renderer-markdown-it\": \"^6.1.0\", \"hexo-renderer-pandoc\": \"^0.3.1\", \"hexo-renderer-stylus\": \"^2.1.0\", \"markdown-it-cjk-breaks\": \"^1.1.3\", \"markdown-it-footnote\": \"^3.0.3\", \"markdown-it-task-lists\": \"^2.1.1\" }, \"devDependencies\": {}, \"scripts\": { \"test\": \"echo \\\"Error: no test specified\\\" &amp;&amp; exit 1\" }, \"author\": \"\", \"license\": \"ISC\"} Typora中插入公式、图表等markdown语法都没什么问题，但是hexo部署完之后就发现各种缩进问题，可能是因为空行导致的，因此如果发现有缩进错误，就尝试增加一个空行，可以解决问题。 5.2 图片渲染不兼容 问题 本地Typora写的博客，使用到hexo部署之后，其中的图片不能正确的显示。 Typora中使用![image name](image relative path)或者是使用html的语法&lt;div align=center&gt;&lt;img src=\"image relative path\" width=\"100%\" height=\"100%\"&gt;&lt;/div&gt;都可以加载图片，其中使用后者的原因是可以控制图片的位置和大小，排版出来比较美观。 后来喜欢用github的图床实现图片保存，但是后面发现图片数量增加时，图片保存的时候，名字不好取，而且非常不好管理，容易出现冲突，因此后面是否继续使用，打个问号。 但是hexo部署之后，网页端就打不开了，本地预览也不行。（出现问题的原因为图片的链接不正确。） hexo部署带有图床链接的图片时，也会自动重新拷贝一份图像到新的文件夹下，并不会直接使用图床链接。图片依旧加载不出来。 分析原因 使用的hexo-asset-image插件有问题（这个插件会给添加的图片一个错误的前缀，导致无法正确链接，只支持版本较低的hexo，e.g. 3.0，而我使用的是4.2.+，目前hexo-asset-image这个库已经暂停维护了）。有解决方案称，应该使用这个插件hexo-asset-img，于是按照要求首先使用npm uninstall hexo-asset-image卸载之前的插件，然后使用npm install hexo-asset-img安装新的插件。但是发现图片依然加载失败，后面发现是在插入图片时，原先使用的都是添加了./最为前缀的，这里完全不需要，直接写文件夹名字加图片名，比如：![](./Hexo初体验/Nodejs.png)，按照正常的流程清空-生成-部署，之后图片就正常显示了。But，如果typora中使用html的方式引入图片，一开始的命令是&lt;div align=center&gt;&lt;img src=\"./Bspline/viz_basis_function.svg\" width=\"100%\" height=\"100%\"&gt;&lt;/div&gt;但是这样只能在typora中看到，hexo部署之后就看不到了.使用&lt;div align=center&gt;&lt;img src=\"viz_basis_function.svg\" width=\"100%\" height=\"100%\"&gt;&lt;/div&gt;之后，typora中看不到，但是hexo部署之后可以。对于排版有一定要求的我，并不满意这样的解决方案。 定位问题 通过检查几种可能得解决方案后发现，主要是这些插件在生成图片链接的时候多多少少有点问题，问题如下所示。发现一个和我相同问题的老哥， 尝试了 一下，他的解决方案并不能解决我的问题，于是我开始小改了一下hexo-asset-image的代码。 可以发现，使用旧的插件部署之后，图片链接变成了http://localhost:4000/blogs/2023/03/06/B-Spline/viz_basis_function.svg， 而使用新的插件部署之后，在路径上自动添加了一个前缀http://localhost:4000/blogs/2023/03/06/B-Spline/B-Spline/viz_basis_function.svg 解决方案 可以重新仿照hexo-asset-image写一个插件，也可以直接hack掉他的源码，修改一下对应的路径。使用方法为： 12# 重新用回不维护的插件npm install hexo-asset-image 在node_modules/hexo-asset-image找到index.js这个文件，将里面的东西换成下面的内容： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566'use strict';var cheerio = require('cheerio'); // http://stackoverflow.com/questions/14480345/how-to-get-the-nth-occurrence-in-a-stringfunction getPosition(str, m, i) { return str.split(m, i).join(m).length;} var version = String(hexo.version).split('.');hexo.extend.filter.register('after_post_render', function(data){ var config = hexo.config; if(config.post_asset_folder){ var link = data.permalink; if(version.length &gt; 0 &amp;&amp; Number(version[0]) == 3) var beginPos = getPosition(link, '/', 1) + 1; else var beginPos = getPosition(link, '/', 3) + 1; // In hexo 3.1.1, the permalink of \"about\" page is like \".../about/index.html\". var endPos = link.lastIndexOf('/') + 1; link = link.substring(beginPos, endPos); var toprocess = ['excerpt', 'more', 'content']; for(var i = 0; i &lt; toprocess.length; i++){ var key = toprocess[i]; var $ = cheerio.load(data[key], { ignoreWhitespace: false, xmlMode: false, lowerCaseTags: false, decodeEntities: false }); $('img').each(function(){ if ($(this).attr('src')){ // For windows style path, we replace '\\' to '/'. var src = $(this).attr('src').replace('\\\\', '/'); if(!/http[s]*.*|\\/\\/.*/.test(src) &amp;&amp; !/^\\s*\\//.test(src)) { // For \"about\" page, the first part of \"src\" can't be removed. // In addition, to support multi-level local directory. var linkArray = link.split('/').filter(function(elem){ return elem != ''; }); var srcArray = src.split('/').filter(function(elem){ return elem != '' &amp;&amp; elem != '.'; }); if(srcArray.length &gt; 1) srcArray.shift(); src = srcArray.join('/'); $(this).attr('src', src); //$(this).attr('src', config.root + link + src); //console.info&amp;&amp;console.info(\"update link as:--&gt;\"+config.root); //console.info&amp;&amp;console.info(\"update link as:--&gt;\"+link); //console.info&amp;&amp;console.info(\"update link as:--&gt;\"+src); //console.info&amp;&amp;console.info(\"update link as:--&gt;\"+config.root + link + src); console.info&amp;&amp;console.info(\"update link as:--&gt;\" + link + src); } }else{ console.info&amp;&amp;console.info(\"no src attr, skipped...\"); console.info&amp;&amp;console.info($(this)); } }); data[key] = $.html(); } }}); 特别是第50行左右的地方：注释掉的就是之前的出问题的地方。（其他问题可同理解决。） 1234567$(this).attr('src', src);//$(this).attr('src', config.root + link + src);// 产生问题的地方//console.info&amp;&amp;console.info(\"update link as:--&gt;\"+config.root);//console.info&amp;&amp;console.info(\"update link as:--&gt;\"+link);//console.info&amp;&amp;console.info(\"update link as:--&gt;\"+src);//console.info&amp;&amp;console.info(\"update link as:--&gt;\"+config.root + link + src); // 产生问题的地方console.info&amp;&amp;console.info(\"update link as:--&gt;\" + link + src); But，突然发现这样之后再Hexo本地预览的时候，没法正常显示照片，就想着能否不用Html来居中图像，就发现了魔改icarus的模板的方案，需要在icarus的主体路径下.styl文件，在187行附近添加如下： 123456789101112131415.article .article-meta margin-bottom: 0.5rem !important .content font-size: 1.1rem blockquote.pullquote float: right max-width: 50% font-size: 1.15rem position: relative a word-wrap: break-word img # 图像居中 margin: auto # 图像居中 display: block # 图像居中 然后icarus默认的设置全部图像都自动居中刻，一些简单的图片不需要html也可以实现居中，复杂彩涉及到html语言了。 5.3 其他 hexo中设置related_posts似乎在生成时有问题，但是不影响部署。（换了一台电脑，问题消失了） 每个博客添加一个缩略图（和文章题目一起显示的那个）。这个属于主题的范畴与hexo无关了，icarus默认使用的事thumbnail.svg这个图像做的缩略图。我手动换成了其他的格式。如果有不一样的就手动设置就行。 在每个md文档的前面，有些属性可以设置。其中： 当只设置 banner 时，文章的缩略图 和 banner 将都是 banner 所设置的图片； 当只设置 thumbnail 时， 文章只有缩略图，无banner； 当同时设置 banner 和 thumbnail 时，banner 为 banner图，thumbnail 为缩略图， 两者各自生效； 例如这里就是：banner:/(article_year)/(article_month)/(article_day)/(article_name)/xxx.png 这里有点难受的就是，参考了这里的方法，在hexo部署的时候报了一个错误，而我又没解决，因此就放弃了。 缩略图没有显示的主要原因还是因为图片的链接错了，需要检查几个地方： 在hexo本地预览时，F12打开源码，找到一个没正常显示图像的位置，比如这里： 1234567891011&lt;article class=\"media\"&gt; &lt;a href=\"/blogs/2020/02/22/Hexo%E5%88%9D%E4%BD%93%E9%AA%8C/\" class=\"media-left\"&gt; &lt;p class=\"image is-64x64\"&gt; &lt;img class=\"thumbnail\" src=\"/blogs/2020/02/22/Hexo%E5%88%9D%E4%BD%93%E9%AA%8C/hexo-logo.png\" alt=\"Hexo初体验\"&gt; &lt;/p&gt; &lt;/a&gt;&lt;div class=\"media-content\"&gt; &lt;div class=\"content\"&gt; &lt;div&gt;&lt;time class=\"has-text-grey is-size-7 is-uppercase\" datetime=\"2020-02-22T07:38:32.000Z\"&gt;2020-02-22&lt;/time&gt;&lt;/div&gt; &lt;a href=\"/blogs/2020/02/22/Hexo%E5%88%9D%E4%BD%93%E9%AA%8C/\" class=\"title has-link-black-ter is-size-6 has-text-weight-normal\"&gt;Hexo初体验&lt;/a&gt; &lt;/div&gt; &lt;/div&gt;&lt;/article&gt; 可以发现图片的路径是/blogs/2020/02/22/Hexo%E5%88%9D%E4%BD%93%E9%AA%8C/Nodejs.png的格式，即部署时会自动转换成这个路径，那么我们需要做的就是在每个博客的开头设定/blogs之后的路径即可，比如本文就是thumbnail: /2020/02/22/Hexo初体验/hexo-logo.png，还要注意冒号后有一个空格。 对照上面的检查thumbnail的路径，一定写对，大概率缩略图就能显示了。 站内搜索，而不是直接联网搜索。 首先在主题的_config.yaml文件中找到search，设置use: local，icarus主题大约位于73行左右。 然后在博客的_config.yaml文件中添加如下，文件结尾处即可： 1234# search inside blogssearch: path: search.xml field: all 出现一个错误，导致无法部署成功，原来是_config.yml中的一个时间设置的不对，原来不知道为什么是beijing，改成timezone: 'Asia/Shanghai'就好了，详见。 部署时出现错误WARN No layout: index.html 解决方案：主题一定要选对，并且安装对，如果安装过程中提示错误，那就按照对应的说明安装相应的依赖库就行。 执行hexo -g时出错，错误为pandoc exited with code null 解决方案：安装pandoc就行。参考这里。 5.4 换台工作电脑 工作一台，家里一台，随时想写博客怎么办？只需要按照前面的步骤安装npm，pandoc，同步修改对应的插件（很重要），把日志克隆下来，开始写，写完部署，然后把本地的仓库使用git同步更新即可。 6、参考博客 小茗同学 fangzh的个人博客 韦阳的博客 ICARUS美化 图片渲染不兼容的可能解决方案1：改源码 图片渲染不兼容的可能解决方案2：改源码 站内搜索源于这里 博客缩略图的设置，以及这里，icarus官方issue中使用缩略图的讨论","link":"/blogs/2020/02/22/Hexo%E5%88%9D%E4%BD%93%E9%AA%8C/"},{"title":"IMU","text":"IMU主要由加速度计和陀螺仪构成，因此IMU中包含的原始数据是角速度和线加速度，包含timestamp ang_vel_x ang_vel_y ang_vel_z lin_acc_x lin_acc_y lin_acc_z，然后通过积分的方式得到__orientation__,position,__velocity__信息。 3轴IMU即只有3轴陀螺仪的IMU，其因为只有一个3轴陀螺仪，所以只能感知载体roll、pitch、yawl共3个自由度的姿态信息。 6轴IMU在3轴IMU的基础上加装了3轴加速度计，因此在感知载体姿态的基础上，还能感知载体3个自由度上的加速度信息。 9轴IMU在6轴IMu的基础上加装了3轴磁强计，由于3轴陀螺仪只能估计载体自身的相对位姿变化（通过加速度计也可获得载体的绝对roll和pitch），单凭3轴陀螺仪无法获取载体的全部姿态信息，而通过3轴磁强计就可以，本质上磁强计的感知原理类似于指南针。","link":"/blogs/2025/01/15/IMU/"},{"title":"KL-divergence","text":"动量蒸馏中用到了 点云配准 Jenson-Shannon divergence","link":"/blogs/2023/09/21/KL%20Divergence/"},{"title":"MLS position inconsistency correction","text":"Supplementary video of paper \"MuCoGraph: A Multi-scale Constraint Enhanced Pose Graph Framework for MLS Point Cloud Inconsistency Correction\", Accepted by Journal of Photogrammetry and Remote Sensing SCI1-TOP, IF=12.7.","link":"/blogs/2023/09/30/MLS-position-inconsistency-correction/"},{"title":"Linux BoostUp","text":"Common Product Tool GPU-Burn GPU压力测试。 Tmux Linux终端，一个好处是只需要开一个终端window就可以通过tmux开很多个pane这样，通过tab切换不同的应用程序，使用pane在一个窗口内切换不同的pane。 tmux可以在后台运行，即使关闭终端window，后台的程序也不会断开。 安装方法 1sudo apt-get install -y tmux 使用 12345678# 新建一个后台终端tmux new -t \"session name\"# 附加在现存的终端上tmux attach -t \"session name\"# 列出所有的sessiontmux ls# 关闭sessiontmux kill-session -t \"session name\" 其他快捷键 key what it does ctrl-b, % split the screen in half from left to right ctrl-b, \" split the screen in half from top to bottom ctrl-b, x kill the current pane ctrl-b, 上下键 switch to the pane in whichever direction you press ctrl-b, d detach from tmux, leaving everything running in the background ctrl-b(按住), 方向键 adjust the size of the pane ctrl-b,[ make the mouse scrolling enable 其他更多快捷键，参见github-tmux-cheatsheet。 一些小问题 vscode远程连接服务器，总是提示断开。测试过的方案有：根据提示在ssh的config文件中添加如下，使得vscode每隔60s就像服务器发送一个信号，这样就不会断开了。(但是似乎没什么用？) 12ServerAliveInterval 60ServerAliveCountMax 3 正确的解决方案应该是，由于服务器采用本地集群的方式开放了一个公网端口，使用ssh连接非常容易出现断联的情况，因此应该使用tmux构建进程，使得进程在服务器本地运行，使得进程和本地窗口解除绑定，这样运行的程序就是在远端的本地进行的。 TOP 显示了系统总体的 CPU 和内存使用情况，以及各个进程的资源使用情况。详情见这里。 不需要安装，默认Ubuntu自带。常见缩写， 涉及Linux cpu负载相关知识： Idle： 处于空闲状态，没有任务需要调度。 id：空闲状态的时间占比。 avg：？？ sy：内核态代码的运行时间比，sy高说明内核占用太多资源，或者用户进程发起了太多的系统调用。 ni：niceness不为0的进程代码运行时间比，默认情况下，进程的niceness值都为0，但可以通过命令nice来启动一个进程并指定其niceness值，niceness的取值范围是-20到19，值越小，表示优先级越高，越优先被内核调度。 hi&amp;si：这两个值反映了CPU有多少时间花在了中断处理上，hi（hardware interrupts）是硬件中断，si(softirqs)是软件中断。硬件中断一般由I/O设备引起，如网卡、磁盘等，发生硬件中断后，CPU需要立即处理，当硬件中断中需要处理的事情很多时，内核会生成相应的软中断，然后将耗时且不需要立即处理完成的操作放在软中断中执行，比如当网卡收到网络包时，需要CPU立即把数据拷贝到内存中去，因为网卡自带的缓存较小，如果不及时处理的话后面的数据包就进不来，导致丢包，当数据拷贝到内存中之后，就不需要那么着急的处理了，这时候可以将处理数据包（协议栈）的代码放在软中断中执行。 wa：处于I/O等待状态的时间占比。通常情况下，当CPU遇到一个I/O操作时，会先触发I/O操作，然后去干别的，等I/O操作完成后，CPU再接着继续工作，但如果这时系统比较空闲，CPU没有别的事情可以做，那么CPU将处于等待状态，这种处于等待状态的时间将会被统计进I/O wait，也就是说CPU处于I/O wait状态即CPU闲着没事干在等I/O操作结束，和idle几乎是一样的。这个值高说明CPU闲且I/O操作多或者I/O操作慢，但低并不能说明没有I/O操作或者I/O操作快，有可能是CPU在忙别的，所以这只是一个参考值，需要和其他的统计项一起来分析。 使用 1top Htop 相比top，htop可以看到更加丰富的CPU信息。 安装方法 1sudo apt-get install htop 使用 1htop 示例图如下所示： 其他快捷键 通过F2可以实现进阶操作，比如修改配色，在F2之后的color界面，通过鼠标或者键盘上下键可以切换颜色，比如Broken gray就比默认颜色更好一些。 ESC可以退出编辑。在htop界面都有写。 查看硬盘IO，htop同样可以参考这里可以实现。（本身top是可以的，此外有iotop这样的软件可以用）。 F2-&gt;Setup-&gt;Display Option，点击空格选中“Detailed CPU time”； 选择Setup-&gt;Meters，使用右箭头和上下箭头键，选中Available meters-&gt;CPU average计数器，添加到Right column； 在Right column中添加后，用上下箭头、回车调整位置，然后按空格，修改计数器类型为CPU(Text)。 之后在htop中就会出现如下所示的栏，表示硬盘io率。 image-20231009151319057 设置完之后还需要保存设置，才能在下一次打开htop时保持和之前一样的设置。但是我设置F10没有用。 Ubuntu20.04自带的System Monitor 其实自带的就很好用，那些花里胡哨的反而比较麻烦。可以看系统，进程，和文件系统。 lm-sensors 用于查看风扇温度， 比如新装了电脑如果CPU支持超频，那么打开CPU超频的话就会导致水冷风扇转速和降温效果达到最高，甚至有点异响。或者用于检查其他硬件是否有问题。 安装方法 1sudo apt-get install lm-sensors 使用 1sensors 就会得到如下的显示： 1234567891011121314151617181920212223242526coretemp-isa-0000 # CPU内核温度Adapter: ISA adapterPackage id 0: +47.0°C (high = +100.0°C, crit = +100.0°C)Core 0: +32.0°C (high = +100.0°C, crit = +100.0°C)Core 1: +33.0°C (high = +100.0°C, crit = +100.0°C)Core 2: +33.0°C (high = +100.0°C, crit = +100.0°C)Core 3: +35.0°C (high = +100.0°C, crit = +100.0°C)Core 4: +31.0°C (high = +100.0°C, crit = +100.0°C)Core 5: +47.0°C (high = +100.0°C, crit = +100.0°C)Core 6: +34.0°C (high = +100.0°C, crit = +100.0°C)Core 7: +33.0°C (high = +100.0°C, crit = +100.0°C)acpitz-acpi-0Adapter: ACPI interfacetemp1: +27.8°C (crit = +105.0°C)iwlwifi_1-virtual-0 #Intel WiFi温度数据Adapter: Virtual devicetemp1: +40.0°C nvme-pci-0500 # GPU温度Adapter: PCI adapterComposite: +41.9°C (low = -273.1°C, high = +81.8°C) (crit = +84.8°C)Sensor 1: +41.9°C (low = -273.1°C, high = +65261.8°C)Sensor 2: +47.9°C (low = -273.1°C, high = +65261.8°C) Filezilla 往已知IP的远程服务器上传输大量的数据。 安装方法 1sudo apt-get install filezilla 使用方法 1filezilla 可以调整文件传输并行线程数。 不同平台的文件编码方式差异导致文件传输之后无法识别的问题。 文本文件中出现很多空行，解决方案：传输的文件类型需要按照二进制的方式进行传输 sh文件无法识别，解决方案，sed -i \"s/\\r//\" *.sh Putty 除了使用filezilla还可以使用putty和服务器之间传输数据，也很方便，比如传文件pscp -r 目录 用户名@LinuxIP:目录，也可以有界面 VSCode 连接服务器 服務器上輸出了loss等日誌，但是沒有開tensorboard的結構，如何通過ssh訪問呢？解決方案參考這裏： 在本地雞上使用ssh -L 10008:127.0.0.1:10008 root@IP將服務器的端口映射到本地，（windows不需要这一步就可以做到，直接vscode连接了之后就行） 在服務器上使用tensorboard --logdir='/root/lyh/code/AE-CrossModal/log/checkpoints/May17_11_25_14_spherical' --port=10008打開tensorboard。 這樣本地才能通過瀏覽器http://localhost:10008看到。 配置C++开发环境 在vscode中可以以直接运行的方式跑C++程序，前提是按照如下的方式配置： fuser Git 出现代码没有修改，但是git diff提示很多改动。如下： 12old mode 100755 new mode 100644 解决方案： 1git config core.filemode false Git推送代码时出现问题，fatal: CRLF would be replaced by LF in: 解决方案： 12git config --global core.autocrlf falsegit config --global core.safecrlf false Github中存储大量的数据，如何快速下载？ 解决方案：因为大文件使用的是LFS，是Git Large File Storage（LFS），因此需要在Git安装并配置好SSH密钥，连接到GitHub、huggingface或其他代码仓库。 LINUX系统： 123curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | sudo bashsudo apt-get install git-lfsgit lfs install 也可以通过软件包管理器（如yum或apt）安装Git LFS。 Windows系统： 直接：git lfs install如果显示Git LFS initialized说明已经OK。然后再git clone就行了。 HuggingFace数据的快速下载 使用官方huggingface_hub可以更加高效一些，然后在使用的时候再从本地加载。github一个下载加速的快捷工具HuggingFace-Download-Accelerator。 首先安装huggingface_hub，但是这个安装的时候与网络有很大的关系，很容易出现网络错误。 1pip install -U huggingface_hub 命令行下载：(比如下载CV-Cities数据集) 1python hf_download.py --dataset gaoshuang98/CV-Cities --save_dir ../CV-Cities --use_mirror True --use_hf_transfer False 如果下载失败了之后，重新运行的话，还可以续下。 如果是需要在代码中下载权重，那么在python xx.py之前添加HF_ENDPOINT=https://hf-mirror.com可以提升下载速度。然后再转到本地存储下来避免二次下载。 Torchhub模型的快速下载 如果想站在预训练好的大模型上进一步开展工作，可以使用如下的方式加载一个模型： 1torch.hub.load('facebookresearch/dinov2', 'dinov2_vitb14') 这种方式需要联网下载，但是有时候网络实在是一言难尽，因此需要换一种方式。 联网下载的模型权重一般存放在/root/.cache/torch/hub/checkpoints/这里。例如，我的该路径下有： 12345root@930e6ca51e89:~/.cache/torch/hub# lscheckpoints facebookresearch_dinov2_main trusted_listroot@930e6ca51e89:~/.cache/torch/hub# cd checkpoints/root@930e6ca51e89:~/.cache/torch/hub/checkpoints# lsdinov2_vitb14_pretrain.pth dinov2_vits14_pretrain.pth 因此，如果想要离线加载模型，需要手动下载对应的权重，然后拷贝到/root/.cache/torch/hub/checkpoints/路径下，并在上一级目录中手动下载对应的模型文件仓库（其中的hubconf.py文件很重要）。 这一步可以写一个脚本，一次性移动到指定位置。 然后加载模型的方法就变成了。 1torch.hub.load('/root/.cache/torch/hub/facebookresearch_dinov2_main', 'dinov2_vits14', trust_repo=True, source='local') pip库安装 1pip cache remove * 删除下载文件时的缓存 1pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple 使用国内的云服务，速度大大提升。 1ImportError: libGL.so.1: cannot open shared object file: No such file or directory 解决方案：apt-get install -y libgl1 1ImportError: libgthread-2.0.so.0: cannot open shared object file: No such file or directory 解决方案：apt-get install -y libglib2.0-0 1libX11.so.6: cannot open shared object file: No such file or directory 解决方案：apt install -y 0 1ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions 降低numpy版本，可能是numpy的bug。numpy1.24.3有bug，1.21.6就无了。 1RuntimeError: cuDNN error: CUDNN_STATUS_INTERNAL_ERROR 这个错误有可能是因为GPU显存不够了。调整网络结构或者减少batch_size才行。 1RuntimeError: Ninja is required to load C++ extensions 解决方案：pip install ninja 1libcudart.so.12: cannot open shared object file: No such file or directory 解决方案：在对应路径下面找到相应的版本，替换就行。比如sudo ldconfig /usr/local/cuda-10.2/lib64","link":"/blogs/2023/09/25/Linux-BoostUp/"},{"title":"Markdown初体验","text":"本文结合菜鸟教程 与个人实践完成 （仅用于博主个人经验记录） ## Markdown语言介绍 Markdown 是一种轻量级标记语言，它允许人们使用易读易写的纯文本格式编写文档。 Markdown 语言在 2004 由约翰·格鲁伯（英语：John Gruber）创建。 Markdown 编写的文档可以导出 HTML 、Word、图像、PDF、Epub 等多种格式的文档。 Markdown 编写的文档后缀为 .md, .markdown。 可以编辑MarkDown的编辑器种类很丰富，如Typora, Notepad++, VSCode 笔者目前使用的是比较常用的 Notepad++ 配合 MarkDownViewer++ 插件进行编辑的。 （博客导出为PDF有问题，存为HTML网页没问题，公式，图表功能不全） 1、层次划分 标题划分 # \"#\"最少的标题字号最大 ## ### #### ##### ###### 第7级就是普通字体了 小标题 第一小点 第二小点 第三小点 \"+\"号也行 &gt; 再来一行 整段缩进 &gt; 第一层 &gt;&gt; 第二层 &gt;&gt;&gt; 第三层 列表 - 第一行 - 第二行 * 第三行 *比-的行间距要大一些 2、插入图片 插入本地图片 ![name](url) 插入相对路径即可，但是想要作为博客上传到网络上时，就需要将对应的图片也上传，而且图片还不能太大，不然的话就会导致加载很慢而失败。 插入网络图片 ![name2](url) 直接跟着网络上的图片链接即可，如下： ![极地星光] (http://img0.dili360.com/ga/M01/02/D7/wKgBzFQ28e-AZ_M2AAHHuRnwnLQ779.jpg@!rw17) 目前Markdown只能添加图片，若想调整图片大小，只能通过Html中标签的方式进行修改缩小一半并居中显示图片 &lt;div align=right&gt;&lt;img src=\"http://img0.dili360.com/ga/M01/01/FA/wKgBy1Q2wYGADMaxAAg9yYHclXE843.jpg@!rw17\" width=\"50%\" height=\"50%\"&gt;&lt;/div&gt; 3、插入链接 - [name](url)，如: 百度 - 或者直接写链接url也可以 4、插入代码片段 - 用反引号()，也就是~在英文输入法下对应的那个键,包含单行代码 - 用反引号 `` 将代码包起来 5、首行缩进 &amp;enmsp;原生MarkDown不支持首行缩进,采用斜两个&amp;emsp;&amp;emsp;来解决. 6、 字体变化 123456*斜体文本*_斜体文本_**粗体文本**__粗体文本__***粗斜体文本***___粗斜体文本___ &gt; 若要想文档更加绚烂点的话，就只能使用Html的格式来进行修改了 + 我是黑体字 + 我是微软雅黑 + 我是华文彩云 + 我是红色 + 我是绿色 + 我是蓝色 + 我是尺寸 + 我是黑体，绿色，尺寸为5 12345678&lt;font face=\"黑体\"&gt;我是黑体字&lt;/font&gt;&lt;font face=\"微软雅黑\"&gt;我是微软雅黑&lt;/font&gt;&lt;font face=\"STCAIYUN\"&gt;我是华文彩云&lt;/font&gt;&lt;font color=red&gt;我是红色&lt;/font&gt;&lt;font color=#008000&gt;我是绿色&lt;/font&gt;&lt;font color=Blue&gt;我是蓝色&lt;/font&gt;&lt;font size=5&gt;我是尺寸&lt;/font&gt;&lt;font face=\"黑体\" color=green size=5&gt;我是黑体，绿色，尺寸为5&lt;/font&gt; 7、添加短划线 ~~删除文字~~ 8、添加表格 左对齐 | 右对齐 | 居中对齐 | :- | -: | :- : | 单元格 | 单元格 | 单元格 | 单元格 | 单元格 | 单元格 | 9、公式&amp;图表 未探索，还需要进一步学习高级功能 Markdown高级 - 公式 &gt;&gt; 需要使用额外latex &amp; tex，然后自动渲染 - 图表 &gt;&gt; notepad+=中这两个功能好像支持的不是很好，目前没有测试成功。","link":"/blogs/2020/02/29/Markdown%E5%88%9D%E4%BD%93%E9%AA%8C/"},{"title":"Nvidia Driver Installation","text":"初始教程 查看系统显卡 lspci | grep -i vga，会弹出设备编号，在这里找到对应的型号，然后在这里下载。 下载对应驱动 位于Downloads路径下的NVIDIA-Linux-x86_64-450.80.02.run tips: 检查cuda版本和显卡驱动的对应关系. 卸载之前的显卡驱动 sudo apt-get automove --purge nvidia-× 给.run文件权限 sudo chmod a+x xxx.run 关闭图形界面 ctrl+alt+f1 关闭lightdm服务 sudo service lightdm stop 安装驱动 sudo xxx.run -no-x-check -no-nouveau-check -no-opengl-files 打开lightdm sudo service lightdm start 如果没反应，再试试 sudo syetemctl start gdm.service or sudo syetemctl enable gdm.service 打开图形化界面 ctrl+alt+f7 重启 最近更新 Ubuntu22.04似乎不用这么麻烦了，直接重装完之后就有显卡驱动了，试图卸载过，但是重装失败，还不如直接用预先安装好的。 ubuntu电脑自动开启Security Boot之后显卡驱动会挂掉，需要进入bios，在Security 中找到Security Boot，调整成为Disable，然后显卡驱动就又好了。 Secure Boot本来是个好事，但是在linux下面似乎不太行，尤其是那种独立带界面的主机。参考这里。","link":"/blogs/2023/04/17/NVIDIA-Driver-Installer/"},{"title":"OSG中的坐标系","text":"OSG中的坐标系和OpenGL中的坐标系 OSG中采用四元数表示旋转：osg::Quat(angle to rotate, rotate around axis); ///*** ///Q quaternion * P quaternion means that first conduct a rotation P,Second conduct a rotation Q, means a fusion about two rotations with a multiplication operation ///*** The osg coordinate definition as left-hand coordinate which is right-front-up(x-y-z) and the OpenGL coordinate definition also as left-hand coordinate which is right-up-behind(x-y-z), z axis is pointer to outside the screen The OSG default viewport is along down direction, so heading is rotate to be equal to the y positive direction, rotate axis is x axis 参考博客 https://blog.csdn.net/tmljs1988/article/details/7561887","link":"/blogs/2020/03/11/OSG%E4%B8%AD%E7%9A%84%E5%9D%90%E6%A0%87%E7%B3%BB/"},{"title":"Rotation Average","text":"What is Rotation Averaging? Problem1 Given a set of rotation matrices \\(C_i, i=\\{1,2,...,n\\}\\), the average of them is ? Rotation Averaging is to calculate the average of a set of rotation matrices. Averaging is to get the best estimate of all rotations. (Single rotation averaging) Or equivalently, Rotation Averaging is the problem of estimating a set of \\(n\\) unknown orientations \\(R_1,...,R_n \\in SO(d)\\) from noisy measurements \\(\\bar{R} \\in SO(d)\\) of the relative rotations \\(R_i^{-1}R_j\\) between them. (Multi rotation averaging) In practical the rotation averaging problem could be categoried into : Single rotation averaging、Multi rotation averaging and Conjugate rotation averaging. Single rotation averaging: for instance, used in the case where several measurements of a single rotation R are given. These may be for instance measurements of the orientation of an object, derived from measurements taken with different cameras in a calibrated network. If the measurements are noisy, they can be averaged to find a mean. Multi rotation averaging: for instance, estimate the rotation of camera in SFM. More practical applications in OpenMVG. conjugate rotation averaging: for instance, hand-eye coordinate problem, that is, consider a robot manipulating some object, which is also observed by a stationary camera. The orientation of the object can be computed at each moment through knowledge of the geometry of the robot (for instance, joint angles). At the same time, the orientation of the object can be computed from the images taken from the camera. This gives two separate estimates of the orientation of the object (expressed as a rotation), but these are in different coordinate frames. By solving the conjugate rotation problem, one can compute the relationship between the robot and camera frames. For all these problems, Rotation Averaging is to find provably optimal and convergent solutions. Rotation Averaging12 Assume the average rotation matrix is \\(\\bar{C}\\), The angle \\(\\Delta \\delta_i\\) between \\(\\bar{C}\\) and \\(C_i\\) , \\(C_i \\mbox{ and }\\bar{C} \\in SO(3)\\), could be calculated as followings: \\[ \\Delta C_i=\\bar{C}^TC_i \\] The cosine value of \\(\\Delta \\delta_i\\) is: \\[ \\begin{align} cos \\Delta \\delta_i &amp;= \\frac{tr(\\Delta C_i)-1}{2} \\\\ &amp;=\\frac{tr(\\bar{C}^TC_i)-1}{2} \\\\ \\end{align} \\] The sum of all cosine value of \\(\\Delta \\delta\\), also known as \\(Karcher\\) mean: \\[ \\begin{align} \\Sigma_i^n cos \\Delta \\delta_i &amp;= \\Sigma_i^n\\frac{1}{2}(tr(\\bar{C}^TC_i)-1) \\\\ &amp;=\\frac{1}{2} \\Sigma_i^ntr(\\bar{C}^TC_i)-\\frac{n}{2} \\end{align} \\] Minimize the sum of angles between \\(\\bar{C}\\) and \\(C_i\\) is to maximize \\(\\Sigma_i^ntr(\\bar{C}^TC_i)\\). ==??? why minimize??? to get the best estimate== \\[ \\begin{align} \\Sigma_i^ntr(\\bar{C}^TC_i) &amp;= tr(\\Sigma_i^n \\bar{C}^TC_i) \\\\ &amp;=tr( \\bar{C}^T \\Sigma_i^nC_i) \\mbox{ // trace operator} \\\\ &amp;=tr( \\bar{C}^T U\\Sigma V^T) \\mbox{ // why?}\\\\ &amp;=tr( V^T\\bar{C}^T U\\Sigma) \\mbox{ // trace operator} \\end{align} \\] where \\(V^T,U,\\bar{C}^T\\) are orthogonal matrices[^ 3]. Then set \\(O=tr(V^T \\bar{C}^T U)\\)， it is also orthogonal matrix. \\[ \\begin{align} tr(V^T\\bar{C}^T U\\Sigma) &amp;= tr(O \\Sigma) \\\\ &amp;= tr( \\left[\\begin{array}{ccc} O_{11} &amp; O_{12} &amp; O_{13} \\\\ O_{21} &amp; O_{22} &amp; O_{23} \\\\ O_{31} &amp; O_{32} &amp; O_{33} \\end{array} \\right] \\left[\\begin{array}{ccc} \\delta_{11} &amp; &amp; \\\\ &amp; \\delta_{22} &amp; \\\\ &amp; &amp; \\delta_{33} \\end{array} \\right] ) \\\\ &amp;= O_{11} \\delta_1 + O_{22} \\delta_2 + O_{33} \\delta_3 \\end{align} \\] where \\(O\\) is orthogonal matrix, means \\(\\Sigma_{j=1}^3 O_{jk}^2=1, \\mbox{ for} \\quad k=1,2,3\\). And the \\(O_{11} \\leq 1,O_{22} \\leq 1,O_{33} \\leq 1\\). Let \\(O_{11} = 1,O_{22} = 1,O_{33} = 1\\), Then \\[ O=\\left[\\begin{array}{ccc} 1 &amp; &amp; \\\\ &amp; 1 &amp; \\\\ &amp; &amp; 1 \\end{array} \\right] =I \\] then $V^T {C}^T U=I {C}T=VUT {C} =UV^T $. Then check the determinant of \\(UV^T\\), which should be 1. \\[ \\bar{C}=U \\left[ \\begin{array}{ccc} 1 &amp; &amp; \\\\ &amp; 1 &amp; \\\\ &amp; &amp; det(UV^T) \\end{array} \\right] V^T \\mbox{ // why?} \\] Code OpenMVG &amp; Ceres for LM optimization. Simplest toy code test: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546// Rotation averaging in a triplet:// 0_______2// \\ /// \\ /// \\ /// 1TEST (rotation_averaging, RotationLeastSquare_3_Camera){ //-- // Setup 3 camera that have a relative orientation of 120 degree // Set Z axis as UP Vector for the rotation // They are in the same plane and looking in O={0,0,0} //-- const Mat3 R01 = RotationAroundZ(2.*M_PI/3.0); //120 degree const Mat3 R12 = RotationAroundZ(2.*M_PI/3.0); //120 degree const Mat3 R20 = RotationAroundZ(2.*M_PI/3.0); //120 degree std::vector&lt;RelativeRotation&gt; vec_relativeRotEstimate; vec_relativeRotEstimate.push_back(RelativeRotation(0,1, R01)); vec_relativeRotEstimate.push_back(RelativeRotation(1,2, R12)); vec_relativeRotEstimate.push_back(RelativeRotation(2,0, R20)); //- Solve the global rotation estimation problem : std::vector&lt;Mat3&gt; vec_globalR; // More in header file L2RotationAveraging(3, vec_relativeRotEstimate, vec_globalR); EXPECT_EQ(3, vec_globalR.size()); // Check that the loop is closing EXPECT_MATRIX_NEAR(Mat3::Identity(), (vec_globalR[0]*vec_globalR[1]*vec_globalR[2]), 1e-8); //-- // Check that the found relative rotation matrix give the expected rotation. // -&gt; the started relative rotation (used in the action matrix). //// /!\\ Translations are not checked they are 0 by default. //-- Mat3 R; Vec3 t, t0 = Vec3::Zero(), t1 = Vec3::Zero(); RelativeCameraMotion(vec_globalR[0], t0, vec_globalR[1], t1, &amp;R, &amp;t); EXPECT_NEAR(0, FrobeniusDistance( R01, R), 1e-2); RelativeCameraMotion(vec_globalR[1], t0, vec_globalR[2], t1, &amp;R, &amp;t); EXPECT_NEAR(0, FrobeniusDistance( R12, R), 1e-2); RelativeCameraMotion(vec_globalR[2], t0, vec_globalR[0], t1, &amp;R, &amp;t); EXPECT_NEAR(0, FrobeniusDistance( R20, R), 1e-2);} Shonan Rotation Averaging4 This is a fast, simple, and elegant rotation averaging algorithm that is guaranteed to recover globally optimal solutions under mild assumptions on the measurement noise. The method employs semidefinite relaxation in order to recover provably globally optimal solutions of the rotation averaging problem. Code Already inside GTSAM-4.1 RCD: Rotation Coordinate Descent5 RCD is a fast rotation averaging algorithm that achieves global optimality under mild noise conditions on the noise level of the measurements. Code RCD Hybrid Rotation Averaging: A Fast and Robust Rotation Averaging Approach7 Code Graph Optimizer: This library contains not only rotation averaging solvers, but also some popular methods in 3D vision, such as translation averaging, clustering, etc. The library is designed to deal with large scale optimization problems, and is easy to extend. iRotAvg6 incrementally solves rotation averaging. Code iRotAvg Diff What is the difference between rotation averaging and SLAM ? Or status estimation? SLAM tries to estimate both translation and rotation,while rotation averaging estimate the optimal rotation only. Others rotation averaging used by Fast Point Transformer, is a post-process optimization scheme? Perhaps yes. Reference Hartley R, Trumpf J, Dai Y, et al. Rotation averaging[J]. International journal of computer vision, 2013, 103: 267-305. ↩︎ https://www.cnblogs.com/JingeTU/p/16818609.html ↩︎ https://en.wikipedia.org/wiki/Orthogonal_matrix ↩︎ Shonan Rotation Averaging: Global Optimality by Surfing \\(SO(p)^n\\), ECCV 2020 ↩︎ Rotation Coordinate Descent for Fast Globally Optimal Rotation Averaging, CVPR 2021 ↩︎ Visual SLAM: Why bundle adjust?, ICRA 2019 ↩︎ Hybrid Rotation Averaging: A Fast and Robust Rotation Averaging Approach, CVPR 2021 ↩︎","link":"/blogs/2023/02/09/Rotation-Average/"},{"title":"ROS basic usage and manager","text":"ROS编译 catkin_make是cmake，make的进一步封装。路径位于workspace下，src之上使用:catkin_makeros会自己找到src下面的源代码，并开始build，如果src下面有好几个源代码，就通过DCATKIN_WHITELIST_PACKAGES指定一个就行： 1catkin_make -DCATKIN_WHITELIST_PACKAGES=\"package1;package2\" 安装则catkin_make install, 使用catkin_make -DCMAKE_INSTALL_PREFIX=/opt/ros/groovy install指定要安装在哪里。 清理安装文件catkin_make clean。 环境配置 如果发现ros依赖的python2和conda使用的python3版本出现冲突，需要使用catkin_make -DPYTHON_EXECUTABLE=/usr/bin/python3来手动选择版本，但是一味的设置python3，会导致ros本身出现不小的问题。 按照opencv_contrib官网的命令，找到对应版本的opencv和opencv_contrib（3.4.19），重新编译了带有opencv_contrib的opencv（之前版本是3.2.0），中间由于版本问题，搞错了很多次。最终opencv安装于：/usr/local/include/opencv2，/usr/local/bin/和/usr/local/lib 常见操作 查看ros版本 rosversion -d，或者rosparam get /rosdistro 查看某个软件的版本 pkg-config --modversion *** ​ pkg-config 是通过.pc文件查找看有那些库文件的。 ​ 默认情况下，会去 prefix/lib/pkgconfig/ 路径下查找，具体到 Linux 系统，就是 /usr/lib/pkgconfig/ 目录，若找不到，则会去 PKG_CONFIG_PATH 环境变量指定的路径下查找。因此，如果我们安装的库文件不在系统环境变量中，需要将其添加到 PKG_CONFIG_PATH 中. ​ 如果实在是找不到，那么可以根据这个教程手动创建一个。 e.g. 查看opencv的版本 pkg-config --modversion opencv 3.2.0 pkg-config --cflags opencv -I/usr/include/opencv pkg-config --cflags --libs opencv -I/usr/include/opencv -lopencv_shape -lopencv_stitching -lopencv_superres -lopencv_videostab -lopencv_aruco -lopencv_bgsegm -lopencv_bioinspired -lopencv_ccalib -lopencv_datasets -lopencv_dpm -lopencv_face -lopencv_freetype -lopencv_fuzzy -lopencv_hdf -lopencv_line_descriptor -lopencv_optflow -lopencv_video -lopencv_plot -lopencv_reg -lopencv_saliency -lopencv_stereo -lopencv_structured_light -lopencv_phase_unwrapping -lopencv_rgbd -lopencv_viz -lopencv_surface_matching -lopencv_text -lopencv_ximgproc -lopencv_calib3d -lopencv_features2d -lopencv_flann -lopencv_xobjdetect -lopencv_objdetect -lopencv_ml -lopencv_xphoto -lopencv_highgui -lopencv_videoio -lopencv_imgcodecs -lopencv_photo -lopencv_imgproc -lopencv_core sudo find / -iname ``\"*opencv*\"查看ubuntu中有那些地方包含了opencv 找到当前仓库中的opencv.pc的路径是在/usr/lib/x86_64-linux-gnu/pkgconfig/opencv.pc。猜测其他的pc可能在镜像制作的时候，也是被放在这里。 刷新当前环境，有时候找不到ros命令就需要刷新环境了。 source ./devel/setup.bash 查看bag中的信息 rosbag info -y outdoor.bag 运行bag文件 rosbag play ourdoor.bag","link":"/blogs/2023/01/16/ROS%20basic%20manager/"},{"title":"SLAM要点","text":"偏导数 优化方程稀疏性的解释 SLAM优化函数中，H矩阵和B矩阵是稀疏的，因此可以针对性的进行一些算法设计来加速求解。 H和B为什么是稀疏的，直观解释如下所示： 基于SVD分解计算旋转和平移向量 点云配准任务详见pcl中的点云配准 如果可以得到两个点云之间的同名点对，那么就可以计算出旋转和平移向量的闭式解，以二维点集之间的相对变换为例进行解释： 首先对原始的点云进行归一化操作，即减去对应质心点的坐标，得到\\(\\tilde{\\mathbf{X}}, \\tilde{\\mathbf{Y}}\\)； \\[ \\tilde{x}=x_i-\\bar{x},\\tilde{y}=y_i-\\bar{y},i=1,...,N \\] 计算加权协方差矩阵； \\[ \\mathbf{H}=\\tilde{\\mathbf{X}}^{T} \\mathbf{E} \\tilde{\\mathbf{Y}} \\] 其中\\(\\mathbf{E}=\\mbox{diag}(e_1,e_2,...,e_N)\\). 对\\(\\mathbf{H}\\)做SVD分解即可计算从\\(\\mathbf{X}\\)到\\(\\mathbf{Y}\\)的旋转矩阵; \\[ \\begin{align} [\\mathbf{U},\\mathbf{S},\\mathbf{V}] &amp;= \\mbox{SVD}(\\mathbf{H}) \\\\ \\hat{\\mathbf{R}} &amp;= \\mathbf{V} \\left[\\begin{array}{ccc} 1 &amp;0 &amp;0 \\\\ 0 &amp;1 &amp;0 \\\\ 0 &amp;0 &amp;\\mbox{det}(\\mathbf{V}\\mathbf{U}^{T}) \\end{array} \\right] \\mathbf{U}^{T} \\end{align} \\] 其中det()是行列式。 最后再计算平移向量； \\[ \\hat{\\mathbf{t}}=\\bar{y}-\\hat{\\mathbf{R}\\bar{x}} \\] 至于背后的数学推导，见这里。 PCL中的代码解释，详见另外一篇博客，或者文章《Least-Squares Rigid Motion Using SVD》。","link":"/blogs/2025/05/21/SLAM-union/"},{"title":"VS开发Tricks","text":"用户宏 由于在开发时不可避免的会遇到多个环境，在不同环境之间进行切换是一个很麻烦的事情，因此使用用户宏可以很好的帮助我们进行环境切换和别名替换，便于多人协同开发。 在属性管理器中选中任意配置环境中的Microsoft.Cpp.x64.user ，弹出如下页面： 用一个你知道的缩写来作为名字，e.g. ThirdParty，对应的本地路径作为值即可。 在后续其他工程使用时可以使用$(ThirdParty)来表示该本地路径。非常方便。 Tips 也可以选择将其设置为开发环境，即在代码编译过程中会使用你定义好的路径中的环境进行链接。 ##### 生成事件 本地开发前或者后，很可能需要自定义生成的可执行文件的路径，但是又不想修改系统默认生成的路径$(SolutionDir)$(Platform)\\$(Configuration)\\ 那么可以通过两种方式做到上述操作： - 使用Cmake管理工程项目；（这里已经使用VS管理了，就先不介绍这种方法啊，具体可以参考CMake-practice这个文档） - 可以尝试使用 生成事件, 如下图所示： 其实这里生成事件使用的就是Windows自带的DOS控制台WindowsBat的命令。 1. 例如你要将本工程中的.h文件拷贝到上述自定义宏路径$(ThirdParty)\\include下。 1XCOPY \"..\\$(ProjectName).h\" \"$(ThirdParty)\\include\" /D /R /Y 2. 再例如你要将本工程中生成的lib和dll文件分别拷贝到自定义的\\((ThirdParty)\\bin`和`\\)(ThirdParty)`下 12XCOPY \"..\\x64\\$(ProjectName).dll\" \"$(ThirdParty)\\bin\" /D /R /Y &amp; XCOPY \"..\\x64\\$(ProjectName).lib\" \"$(ThirdParty)\\lib\" /D /R /YXCOPY \"..\\x64\\$(ProjectName)_d.dll\" \"$(ThirdParty)\\bin\" /D /R /Y &amp; XCOPY \"..\\x64\\$(ProjectName)_d.lib\" \"$(ThirdParty)\\lib\" /D /R /Y ###### Tips 注意DOS命令如果写错会导致项目生成失败； 当你命令中路径出现错误，或者待处理的文件不存在时，也会导致生成失败； 当你的工程项目没有生成（源代码没有修改）时，上述生成事件命令也不会执行。 ##### 调试 - 调用堆栈","link":"/blogs/2021/01/17/VS%E5%BC%80%E5%8F%91Tricks/"},{"title":"Kinematic mapping trajectory estimation","text":"Integrated trajectory estimation for 3D kinematic mapping with GNSS, INS and imaging sensors: A framework and review1 方法分类 多步方法。 ​ 流程：首先用Kalman filtering 将GNSS和IMU融合到一起，如果轨迹足够准确，可以直接获得3D点云。也可以在后面加一个平差步骤，结合影像传感器的观测实现融合传感器定向，目的是：1）改正轨迹；2）传感器定向和标定；3）获取3D模型数据，e.g.点云。 ​ 需要有一些假设：通常假设轨迹误差是由于缓慢变化的 GNSS 误差或未补偿的惯性传感器漂移造成的，因此是低频的，而轨迹的较高频率分量相对准确。 实际上，校正要么与飞行几何相关联，作为每条带的固定偏移，要么建模为缓慢时变。 由于轨迹误差在带内也可能变化很大，因此这种调整在实践中通常需要高度灵活的校正模型，而这也是的模型有较高的过拟合风险，导致点云中出现全局的变形。 ​ 这些问题是的在传感器层级进行统一的误差建模的方法开始流形。 联合方法。 ​ 主要流行于多传感器融合。 ​ 值得注意的是，根据最终应用的不同，对平台轨迹的要求也存在一些差异。 出于导航目的，例如汽车导航或机器导航，人们通常对平滑的车辆轨迹感兴趣。 对于测量，即传感器测量的地理配准，感兴趣的轨迹是成像传感器本身的轨迹，它可能相对于车架是刚性的，也可能不是刚性的。 为此，任何振动都不应被视为噪声，因此不会被滤除，因为这些振动确实会影响测量。 同样，地理配准的精度要求也很高。 标称激光测距精度约为 2 厘米，但据报道，对于足够平坦的地形，毫米范围内的偏差已被报道。 因此，轨迹精度通常是限制因素。 由于机载遥感的高测量范围，方向误差（无论是轨迹误差还是扫描仪和 INS 之间的未对准）占主导地位。 ​ 可以按照耦合方式进行划分： ​ 松耦合是指轨迹级别的误差建模：来自不同传感器的位置和/或方向估计被组合成一个综合轨迹估计。 以损失部分信息换来计算效率的提升，实现复杂度相较于紧耦合是比较小的。 ​ 紧耦合是指误差在传感器级别建模； 即测量以原始形式组合，并且只产生一个轨迹估计。 - - Multi-sensor platform Taxonomy of filtering methods. 在Kalman filter下面还可以加一个error state kalman filter。 建模框架 ​ 轨迹估计需要对两个有些不同的方面进行建模：传感器测量的建模和轨迹本身的建模。 虽然经典方法将轨迹（以及其他时变量）表示为状态变量的离散时间序列，但一些较新的公式使用连续表示。 ​ 通常，有必要在成像传感器采样时间获得轨迹估计。 如果此类测量的数量很大，则可能无法在所有这些时间明确估计轨迹，要求轨迹可以以某种方式由相对较少数量的参数表示，有两种方案：1）计算固定时间点的轨迹估计，并使用插值法得出所需的中间值，或2）使用可在需要时进行评估的显式连续时间表示。 文献总结 ​ 这个Tong 20132中做了基于高斯过程的状态估计，Furgale 20123-2013做了基于Spline的状态估计。但是两种方法之间的区别和联系，以及又是是什么，尚不明确。Furgale使用的B-Spline的表示方法是Qin的方案。高斯过程的方案需要对运动有一个先验，一般使用的都是高斯白噪声。这样才能得到可逆的协方差矩阵，提升计算效率。 连续轨迹表示在减少参数数量和轨迹保真度之间进行权衡。 这种权衡通常会导致更高频率的平滑，这可能是理想的，也可能不是理想的，具体取决于应用。 讨论 趋势 From recursive filtering to batch optimization：组合导航的解决方案以前基于递归估计，即卡尔曼滤波器类型的解决方案。 最近，基于批量 MAP 估计的方法越来越受欢迎。 存在增量或简化的解决方案，但主要是出于性能原因：尽管计算量大，但理论上更可取全批量处理方法。 From discrete to continuous trajectory representations：经典的过滤方法将位置和方向的演变参数化为一组离散的状态。 由于包含多个可能异步采样的传感器需要以非常高的频率估计位置和方向，因此连续轨迹参数化已被证明是有用的并且被广泛使用，尤其是在机器人社区中。 这允许在任意时间评估位置和方向。 除了随机先验之外，还可以通过选择合适的轨迹表示来合并关于轨迹的额外“确定性”先验信息。 另一方面，如果测量是同步的或线性插值就足够了，则连续公式的计算要求可能更高。 应该提到的是，迄今为止还没有对所有不同的轨迹表示进行详尽的比较。 From trajectory level to sensor level error modelling：轨迹级误差建模对于小误差或遵循某些特征的误差是有效的。 然而，这种方法可能导致轨迹变形，随后导致 3D 模型变形，因为忽略了基础测量（GNSS 和 IMU）。 估计算法的进步以及可用的计算能力导致了整体多传感器估计方法的趋势，其中误差在传感器级别建模，即以紧密耦合的方式。 Towards mathematically rigorous modelling：最近提出的方法采用了更复杂的数学技术。 这以不同的方式表现出来：对于轨迹表示，越来越多的经典欧拉角表示受到批评，并被尊重底层李群结构的参数化方法所取代。 以前，加权最小二乘法只是作为一种优化工具使用，但现在它主要用于概率框架内，因为对准确随机误差建模的需求变得更加明显。 对于这些统计解释，所做的工作是为了合并具有不同的、可能是先验未知概率密度的误差。 在计算可行的情况下，首选提供强大理论保证的估计器，无论是关于统计最优性还是数值性能。 挑战 ​ 从纯理论的角度来看，紧耦合的全批量估计没有缺点，其中同时考虑所有测量。 与增量或松散耦合的方法相比，可以预期紧密耦合的全局方法在鲁棒性和准确性方面表现更好。 然而，这种“完全紧耦合”方法的实用公式已被证明是难以捉摸的。 在大多数情况下，进行简化以允许更有效的处理，或者传感器以松散的方式部分耦合以简化模型和必要的计算。 在各种简化和不同的耦合组合中，还没有建立明显优越的方法。 如果趋势是存在的，并且全局紧耦合是优越的，那么为什么在实践中没有体现出来呢？ 我们认为这主要是由于两个原因，概述如下: Model complexity：虽然采用更紧密耦合的方法在实践中通常表现出更高的性能，但它需要付出巨大的努力。 对于传感器级误差建模，需要深入了解传感器才能准确地对误差建模，而不会在估计中引入系统误差。 为此，必须访问原始传感器数据。 这对于受到出口限制并且通常不允许访问原始数据而仅提供集成导航解决方案的高质量 IMU 来说尤其如此。 然而，对于 GNSS 数据，这个问题已经解决了：RINEX 提供了一种标准化的、文档化的数据交换格式。 然而，紧耦合需要同时估计所有相关参数和测量值。 与松散耦合相比，这导致更高的处理和内存要求。 更高效、可并行化的算法和更快的硬件将使进一步利用紧密的传感器耦合成为可能。 Lack of comparative studies：上述所有方法都经过实验评估，但针对不同的传感器模式和应用，并且主要是基于个体，这些都没有比较过。 Cioffi 针对不同的机器人场景将离散时间和基于样条的 SLAM 实现进行了比较。 然而，不同方法之间的一般深入比较是困难的，一方面是由于缺乏高精度参考数据，另一方面是因为很少有实现是公开可用的，并且由于模型的复杂性而不会经常进行重新实现。 第 5 节中介绍的文献中提供了不同方法的示例应用，特别是不同轨迹表示的示例应用。在一些研究中，低级和高级硬件的组合用于测试关于参考轨迹的新方法 更好的系统。 然而，评估更好系统的问题仍然存在。 任何比较也必然限于特定用例：对轨迹解决方案的要求，以及对平台动力学、振动和传感器噪声等系统行为的假设，因应用而异。 对于移动激光扫描，尤其是在城市环境中，由于 GNSS 接收不良或多径效应导致的定位误差起着很大的作用。 对于机载应用，GNSS 通常没有问题，但需要高精度定位，因为由于测量范围较长，定位误差对地理参考数据有很大影响。 Challenges for kinematic mapping applications：运动学映射应用中普遍的高精度和准确度要求提出了进一步的挑战。 尽管在这方面已经做了大量工作来提高低成本传感器的精度，但许多测量应用程序仍然依赖于昂贵的高级硬件。 由于需要对各种算法组件进行微调，可用的处理解决方案需要经验丰富的操作员。 其他基于部分处理工作流程的商业黑盒解决方案，这些解决方案在报告的准确性方面往往过于乐观。 展望 ​ 总而言之，许多不同领域的贡献取得了很大进展。 几个明显的趋势已经确立。 然而，== 最佳解决方案仍不清楚==。 因此，主要的挑战是允许对不同方法进行严格的评估和比较，这反过来又需要合适的基准数据。 未来在这个方向上的工作将允许开发更准确、可靠和自动的轨迹估计方法，这反过来有利于所有与运动学映射相关的活动。 Pöppl F, Neuner H, Mandlburger G, et al. Integrated trajectory estimation for 3D kinematic mapping with GNSS, INS and imaging sensors: A framework and review[J]. ISPRS Journal of Photogrammetry and Remote Sensing, 2023, 196: 287-305. ↩︎ Tong C H, Furgale P, Barfoot T D. Gaussian process gauss–newton for non-parametric simultaneous localization and mapping[J]. The International Journal of Robotics Research, 2013, 32(5): 507-525. ↩︎ Furgale P, Barfoot T D, Sibley G. Continuous-time batch estimation using temporal basis functions[C]//2012 IEEE International Conference on Robotics and Automation. IEEE, 2012: 2088-2095. ↩︎","link":"/blogs/2025/02/08/TrajectoryEstimation/"},{"title":"WindowBat","text":"bat中的一些语法学习，用于MicroStation多人编译 Parameter Setting 1、系统参数 %SystemRoot% === C:(%windir% 同样) %ProgramFiles% === C:Files %USERPROFILE% === C:and Settings(子目录有“桌面”,“开始菜单”,“收藏夹”等) %APPDATA% === C:and SettingsData %TEMP% === C:11~1(%TEM% 同样) %APPDATA% === C:and SettingsData %OS% === Windows_NT (系统) %Path% === %SystemRoot%;%SystemRoot%;%SystemRoot%(原本的设置) %HOMEDRIVE% === C: (系统盘) %HOMEPATH% === and Settings :: 枚举当前的环境变量 #### 2、传递参数给批处理文件 #### %[1-9]表示参数，参数是指在运行批处理文件时在文件名后加的以空格(或者Tab)分隔的字符串。变量可以从%0到%9，%0表示批处理命令本身，其它参数字符串用 %1 到 %9 顺序表示。 ## Basic Command ## #### 0、help #### 可以在console 输入 help /？查看 #### 1、echo #### 语法: echo [{on|off}] [message] ECHO [ON | OFF] 打开回显或关闭回显功能。 ECHO 显示当前回显设置。 ECHO [message] 显示信息。 echo off 表示在此语句后所有运行的命令都不显示命令行本身；默认是on，on时会显示如： C:&gt;命令行。 在实际应用中我们会把这条命令和重定向符号( 也称为管道符号，一般用 &gt; &gt;&gt; ^ )结合来实现输入一些命令到特定格式的文件中。 #### 2、@* #### 表示不显示@后面的命令，(在入侵过程中自然不能让对方看到你使用的命令啦) @ 与 echo off 相象，但它是加在每个命令行的最前面，表示运行时不显示这一行的命令行(只能影响当前行)。 Sample： @echo off (此语句常用于开头，表示不显示所有的命令行信息，包括此句) #### 3、Goto* #### 语法：goto label (label是参数，指定所要转向的批处理程序中的行。) 指定跳转到标签行，找到标签行后，程序将处理从下一行开始的命令。 label标签的名字可以随便起，但是最好是有意义的，字母前必须加个冒号“:”来表示这个字母是标签。 goto命令就是根据这个冒号来寻找下一步跳到到那里。经常与 if 配合使用，根据不同的条件来执行不同的命令组。 #### 4、Rem #### rem 输出信息，可以用“::”代替 #### 5、Pause #### 挂起，使console运行结束后不退出 #### 6、Call #### 语法: __call [[Drive:][Path] FileName [BatchParameters]] [:label [arguments]]__ 参数: [Drive:][Path] FileName 指定要调用的批处理程序的位置和名称。filename 参数必须具有 .bat 或 .cmd 扩展名。 调用另一个批处理程序，并且不终止父批处理程序。如果不用call而直接调用别的批处理文件，那么执行完那个批处理文件后将无法返回当前文件并执行当前文件的后续命令。 call 命令接受用作调用目标的标签。如果在脚本或批处理文件外使用 Call，它将不会在命令行起作用。 Sample：call=\"%cd%\\test2.bat\" haha kkk aaa(调用指定目录下的 test2.bat，且输入3个参数给他) Sample：call test2.bat arg1 arg2(调用同目录下的 test2.bat，且输入2个参数给他) 注：可以调用自身(死循环、递归) #### 7、Start #### 用的不多，调用外部程序，所有的 DOS命令 和 命令行程序 都可以由 start命令 来调用。 入侵常用参数： MIN 开始时窗口最小化 SEPARATE 在分开的空间内开始 16 位 Windows 程序 HIGH 在 HIGH 优先级类别开始应用程序 REALTIME 在 REALTIME 优先级类别开始应用程序 WAIT 启动应用程序并等候它结束 parameters 这些为传送到命令/程序的参数 Sample：start /MIN test2.bat arg1 arg2(调用同目录下的 test2.bat，且输入2个参数给他，且本窗口最小化) Sample：e:\\\"program files\"\\极品列车时刻表\\jpskb.exe(文件路径名有空格时) #### 8、If #### if 表示将判断是否符合规定的条件，从而决定执行不同的命令。有三种格式: 1. if 语法: if [not] \"参数\" == \"字符串\" 待执行的命令 参数如果等于(not表示不等，下同)指定的字符串，则条件成立，运行命令，否则运行下一句。(注意是两个等号) Sample: if \"%1\" == \"a\" format a: {`Sample: if {%1} == {} goto noparms `} 2. if exist 语法: if [not] exist [路径]文件名 待执行的命令 如果有指定的文件，则条件成立，运行命令，否则运行下一句。 Sample: if exist config.sys edit config.sys(表示如果存在这文件，则编辑它，用很难看的系统编辑器) Sample: if exist config.sys type config.sys(表示如果存在这文件，则显示它的内容) 3. if errorlevel number 语法: if [not] errorlevel 待执行的命令 如果程序返回值等于指定的数字，则条件成立，运行命令，否则运行下一句。(返回值必须按照从大到小的顺序排列) Sample: 12345@echo offXCOPY F:\\test.bat D:\\IF ERRORLEVEL 1 (ECHO 文件拷贝失败) Else IF ERRORLEVEL 0 ECHO 成功拷贝文件pause 很多DOS程序在运行结束后会返回一个数字值用来表示程序运行的结果(或者状态)，称为错误码errorlevel或称返回码。 常见的返回码为0、1。通过if errorlevel命令可以判断程序的返回值，根据不同的返回值来决定执行不同的命令。 + 4) else 语法： if 条件 (成立时执行的命令) else (不成立时执行的命令) 如果是多个条件，建议适当使用括号把各条件包起来，以免出错。 Sample: if 1 == 0 ( echo comment1 ) else if 1==0 ( echo comment2 ) else (echo comment3 ) 注：如果 else 的语句需要换行，if 执行的行尾需用“^”连接，并且 if 执行的动作需用(括起来)，否则报错 Sample: if 1 == 0 ( echo comment1 ) else if 1==0 ( echo comment2 ) ^ else (echo comment3 ) + 5) 比较运算符: 12345678EQU - 等于 (一般使用“==”)NEQ - 不等于 (没有 “!=”,改用“ if not 1==1 ”的写法)LSS - 小于LEQ - 小于或等于GTR - 大于GEQ - 大于或等于if /i {%1}=={} (set _BUILDARGS=+a) else (set _BUILDARGS=+avilC)rem /i 表示启动IF命令扩展，使得IF可以支持多种运算操作：{%1}=={}如果第一个参数为空，就设置buildargs为+a 就是bmake后面跟的参数，否则就设置为其他的 #### 9、Choice #### choice 使用此命令可以让用户输入一个字符(用于选择)，从而根据用户的选择返回不同的 errorlevel，然后配合 if errorlevel 选择运行不同的命令。 注意：choice命令为DOS或者Windows系统提供的外部命令，不同版本的choice命令语法会稍有不同，请用choice /?查看用法。 使用时应该加/c:参数，c:后应写提示可输入的字符，之间无空格。它的返回码为1234 Sample: choice /c:dme defrag,mem,end 将显示: defrag,mem,end[D,M,E]? Sample: 1234choice /c:dme defrag,mem,endif errorlevel 3 goto defrag (应先判断数值最高的错误码)if errorlevel 2 goto memif errotlevel 1 goto end #### 10、For #### for 对一组文件中的每一个文件执行某个特定命令。主要用于参数在指定的范围内循环执行命令。 + 1)for {%variable | %%variable} in (set) do command [command-parameters] %variable 指定一个单一字母可替换的参数。变量名称是区分大小写的，所以 %i 不同于 %I 在批处理文件中使用 FOR 命令时，指定变量建议用 __%%variable__而不要用 %variable。 (set) 指定一个或一组文件。可以使用通配符。 command 指定对每个文件执行的命令。 command-parameters 为特定命令指定参数或命令行开关。 + 2)如果命令扩展名被启用，下列额外的 FOR 命令格式会受到支持: + a. FOR /D %variable IN (set) DO command [command-parameters] 如果集里面包含通配符，则指定与目录名匹配，而不与文件名匹配。 + b. FOR /R [[drive:]path] %variable IN (set) DO command [command-parameters] 检查以 [drive:]path 为根的目录树，指向每个目录中的FOR 语句。 如果在 /R 后没有指定目录，则使用当前目录。如果集仅为一个单点(.)字符，则枚举该目录树。 + c. FOR /L %variable IN (start,step,end) DO command [command-parameters] 该集表示以增量形式从开始到结束的一个数字序列。 如：(1,1,5) 将产生序列 1 2 3 4 5； 而(5,-1,1) 将产生序列 (5 4 3 2 1)。 + d. 有或者没有 usebackq 选项: FOR /F [\"options\"] %variable IN (file-set) DO command FOR /F [\"options\"] %variable IN (\"string\") DO command FOR /F [\"options\"] %variable IN (command) DO command 参数\"options\"为: fileset 为一个或多个文件名。继续到 fileset 中的下一个文件之前，每份文件都被打开、读取并经过处理。处理包括读取文件，将其分成一行行的文字， 然后将每行解析成零或更多的符号。然后用已找到的符号字符串变量值调用 For 循环。以默认方式，/F 通过每个文件的每一行中分开的第一个空白符号。跳过空白行。 你可通过指定可选 \"options\" 参数替代默认解析操作。这个带引号的字符串包括一个或多个指定不同解析选项的关键字。 这些关键字为: 12345678eol=c - 指一个行注释字符的结尾(就一个字符),(如“;”)skip=n - 指在文件开始时忽略的行数。delims=xxx - 指分隔符集。这个替换了空格和跳格键的默认分隔符集。tokens=x,y,m-n - 指每行的哪一个符号被传递到每个迭代的 for 本身。这会导致额外变量名称的分配。m-n格式为一个范围。通过 nth 符号指定 mth。如果符号字符串中的最后一个字符星号，那么额外的变量将在最后一个符号解析之后分配并接受行的保留文本。usebackq - 指定新语法已在下类情况中使用:在作为命令执行一个后引号的字符串并且一个单引号字符为文字字符串命令并允许在 filenameset中使用双引号扩起文件名称。 + 3)Sample: + a. 如下命令行会显示当前目录下所有以bat或者txt为扩展名的文件名。 for %%c in (.bat .txt) do (echo %%c) + b. 如下命令行会显示当前目录下所有包含有 e 或者 i 的目录名。 for /D %%a in (e i) do echo %%a + c. 如下命令行会显示 E盘test目录 下所有以bat或者txt为扩展名的文件名。 for /R E:%%b in (.txt .bat) do echo %%b for /r %%c in (*) do (echo %%c) :: 遍历当前目录下所有文件 + d. 如下命令行将产生序列 1 2 3 4 5 for /L %%c in (1,1,5) do echo %%c + e. 以下两句，显示当前的年月日和时间 For /f \"tokens=1-3 delims=-/. \" %%j In ('Date /T') do echo %%j年%%k月%%l日 For /f \"tokens=1,2 delims=: \" %%j In ('TIME /T') do echo %%j时%%k分 + f. 把记事本中的内容每一行前面去掉8个字符 setlocal enabledelayedexpansion for /f %%i in (zhidian.txt) do ( set atmp=%%i set atmp=!atmp:~8! if {!atmp!}=={} ( echo.) else echo !atmp! ) :: 读取记事本里的内容(使用 delims 是为了把一行显示全,否则会以空格为分隔符) for /f \"delims=\" %%a in (zhidian.txt) do echo.%%a + g. FOR /F \"eol=; tokens=2,3* delims=, \" %i in (myfile.txt) do @echo %i %j %k 该行会分析 myfile.txt 中的每一行，忽略以分号打头的那些行，将每行中的第二个和第三个符号传递给 for 函数体，用逗号和/或 空格分隔符号。请注意，此 for 函数体的语句引用 %i 来获得第二个符号，引用 %j 来获得第三个符号，引用 %k来获得第三个符号后的所有剩余符号。对于带有空格的文件名，你需要用双引号将文件名括起来。为了用这种方式来使用双引号，还需要使用 usebackq 选项，否则，双引号会被理解成是用作定义某个要分析的字符串的。 %i 在 for 语句中显式声明，%j 和 %k 是通过tokens= 选项隐式声明的。 可以通过 tokens= 一行指定最多 26 个符号，只要不试图声明一个高于字母 \"z\" 或\"Z\" 的变量。请记住，FOR 变量是单一字母、分大小写和全局的变量；而且，不能同时使用超过 52 个。 还可以在相邻字符串上使用 FOR /F 分析逻辑，方法是，用单引号将括号之间的 file-set 括起来。这样，该字符串会被当作一个文件中的一个单一输入行进行解析。 最后，可以用 FOR /F 命令来分析命令的输出。方法是，将括号之间的 file-set 变成一个反括字符串。该字符串会被当作命令行，传递到一个子 CMD.EXE，其输出会被捕获到内存中，并被当作文件分析。如以下例子所示: FOR /F \"usebackq delims==\" %i IN (set) DO @echo %i 会枚举当前环境中的环境变量名称。 + 4)continue 和 break 利用 goto 实现程序中常用的 continue 和 break 命令, 其实非常简单 continue: 在 for 循环的最后一行写上一个标签，跳转到这位置即可 break: 在 for 循环的外面的下一句写上一个标签，跳转到这位置即可 &gt; Sample: 12345678for /F [\"options\"] %variable IN (command) DO (... do command ...if ... goto continueif ... goto break... do command ...:continue):break ### For循环补充 ### &gt; /D 参数只能显示当前目录下的目录名字 @echo off for /d %%i in (window?) do @echo %%i pause &gt; /R 递归进入根目录树[Drive:]Path，在树的每个目录中执行for 语句。如果在 /R 后没有指定目录，则认为是 当前目录。如果 Set 只是一个句点 (.)，则只枚举目录树。 系统帮助的格式: FOR /R[[drive:]path] %%variable IN (set) DO command for /r %%i in (.exe) do @echo %%i 列出所有exe的名字 for /r c: %%i in (.exe) do @echo %%i 列出c盘的exe名字 对于FOR /F %%i IN (file) DO command file为文件名，按照官方的说法是，for会依次将file中的文件打开，并且在进行到下一个文件之前将每个文件读取到内存， 按照每一行分成一个一个的元素，忽略空白的行，看个例子。 &gt; for/f \"delims= \" %%i in (a.txt) do echo %%i 输出a.txt文件中的每一行，用空格隔开？ #### 11、Ping #### 测试网络联接状况以及信息包发送和接收状况。但是不能够测试端口。 语法：ping IP地址或主机名 [-t] [-a] [-n count] [-l size] 参数含义： -t 不停地向目标主机发送数据； -a 以IP地址格式来显示目标主机的网络地址； -n count 指定要Ping多少次，具体次数由count来指定； -l size 指定发送到目标主机的数据包的大小。 Sample: ping 192.168.0.1 -t (不停的测试192.168.0.1，按ctrl+c停止) Sample: for /L %%a in (0,1,255) do ping 192.168.0.%%a -n 1 &gt;&gt; tmp.txt (ping一下所有的局域网电脑) #### 12、Telnet #### 测试端口使用 telnet IP地址或主机名 端口，使用tcp协议的 Sample: telnet 192.168.0.1 80 (测试192.168.0.1的80端口) #### 13、Color #### color [attr] 颜色属性由两个十六进制数字指定 -- 第一个对应于背景，第二个对应于前景。每个数字 可以为以下任何值: 0 = 黑色 8 = 灰色 1 = 蓝色 9 = 淡蓝色 2 = 绿色 A = 淡绿色 3 = 浅绿色 B = 淡浅绿色 4 = 红色 C = 淡红色 5 = 紫色 D = 淡紫色 6 = 黄色 E = 淡黄色 7 = 白色 F = 亮白色 如果没有给定任何参数，此命令会将颜色还原到 CMD.EXE 启动时的颜色。这个值来自当前控制台 窗口、/T 命令行开关或 DefaultColor 注册表值。 如果尝试使用相同的前景和背景颜色来执行rem COLOR 命令，COLOR 命令会将 ERRORLEVEL 设置为 1。 只有一个参数时，设置字体。只有一个字母时默认时设置字体的颜色 #### 14、Exit #### exit退出 #### 15、ShutDown #### shutdown -s +秒数（xx秒之后自动关闭） #### 16、Dir #### 显示目录中的文件和子目录列表。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546DIR [drive:][path][filename] [/A[[:]attributes]] [/B] [/C] [/D] [/L] [/N] [/O[[:]sortorder]] [/P] [/Q] [/R] [/S] [/T[[:]timefield]] [/W] [/X] [/4] [drive:][path][filename] 指定要列出的驱动器、目录和/或文件。 /A 显示具有指定属性的文件。 属性 D 目录 R 只读文件 H 隐藏文件 A 准备存档的文件 S 系统文件 I 无内容索引文件 L 解析点 - 表示“否”的前缀 /B 使用空格式(没有标题信息或摘要)。 /C 在文件大小中显示千位数分隔符。这是默认值。用 /-C 来禁用分隔符显示。 /D 跟宽式相同，但文件是按栏分类列出的。 /L 用小写。 /N 新的长列表格式，其中文件名在最右边。 /O 用分类顺序列出文件。 排列顺序 N 按名称(字母顺序) S 按大小(从小到大) E 按扩展名(字母顺序) D 按日期/时间(从先到后) G 组目录优先 - 反转顺序的前缀 /P 在每个信息屏幕后暂停。 /Q 显示文件所有者。 /R 显示文件的备用数据流。 /S 显示指定目录和所有子目录中的文件。 /T 控制显示或用来分类的时间字符域。 时间段 C 创建时间 A 上次访问时间 W 上次写入的时间 /W 用宽列表格式。 /X 显示为非 8.3 文件名产生的短名称。格式是 /N 的格式， 短名称插在长名称前面。如果没有短名称，在其位置则 显示空白。 /4 用四位数字显示年可以在 DIRCMD 环境变量中预先设定开关。通过添加前缀 - (破折号)来替代预先设定的开关。例如，/-W。上面是CMD命令自带的说明文件。dir /d 只显示当前目录下的文件名称dir /od 按文件修改时间排序，递增；dir /o-d 按文件修改时间排序，递减dir /od/tc 按文件创建时间排序，递增dir /o-d/tc 按文件创建时间排序，递减dir/on 按文件名排序对应，递增dir/o-n 按文件名排序对应，递减dir/oe 按扩展名排序对应，递增dir/o-e 按文件名排序对应，递减dir /s /b &gt;a.txt 打印文件夹下的所有文件 #### 17、重定向符 #### mycommand &gt;mylog.txt 2&gt;&amp;1 应该是最经典的用法了。 命令的结果可以通过“%&gt;”的形式来定向输出，%表示文件描述符：1为标准输出stdout、2为标准错误stderr。系统默认%值是1，也就是“1&gt;”，而1&gt;可以简写为&gt;，也就是默认为&gt;。 stdout的默认目标是终端，stderr的默认目标为也是终端。我们在批处理中执行： echo text &gt;result.txt ，我们就可以在屏幕上会看到 echo text 1&gt;result.txt ，即是这个道理。 其中&amp;需要直接与重定向符号结合使用。 应用实例： 1、将结果输出到result.txt net stop myservices &gt;&gt;result 2&gt;&amp;1 2、隐藏程序输出结果 net stop myservices &gt;nul 2&gt;nul 微软关于重定向的文章：使用命令重定向操作符 可以使用重定向操作符将命令输入和输出数据流从默认位置重定向到其他位置。输入或输出数据流的位置称为句柄。 下面列出可用的句柄。 句柄 句柄的数字代号 描述 1234STDIN 0 键盘输入 STDOUT 1 输出到命令提示符窗口 STDERR 2 错误输出到命令提示符窗口 UNDEFINED 3-9 句柄由应用程序单独定义，它们是各个工具特有的 数字 0 到 9 代表前 10 个句柄。可以使用命令 Cmd.exe 运行程序，并对该程序前 10 个句柄中的任何一个句柄进行重定向。要指定要用的句柄，请在重定向操作符之前键入该句柄的数字。如果未定义句柄，则默认的 &lt; 重定向输入操作符是 0，而默认的 &gt; 重定向输出操作符是 1。键入 &lt; 或 &gt; 操作符之后，必须指定数据的读写位置。可以指定文件名或其他现有的句柄。 要指定重定向到现有句柄，请使用与 (&amp;) 字符，后面接要重定向的句柄号（即 &amp;句柄号）。 例如，下面的命令可以将句柄 2（即 STDERR）重定向到句柄 1（即 STDOUT）： 2&gt;&amp;1 下表列出了可用于重定向输入和输出数据流的操作符。 12345678重定向操作符 描述 &gt; 将命令输出写入到文件或设备（如打印机），而不是命令提示符窗口或句柄。&lt; 从文件而不是从键盘或句柄读入命令输入。&gt;&gt; 将命令输出添加到文件末尾而不删除文件中已有的信息。&gt;&amp; 将一个句柄的输出写入到另一个句柄的输入中。&lt;&amp; 从一个句柄读取输入并将其写入到另一个句柄输出中。| 从一个命令中读取输出并将其写入另一个命令的输入中。也称作管道。默认情况下，可以从键盘将命令输入（即 STDIN 句柄）发送到 Cmd.exe，然后由 Cmd.exe 将命令输出（即 STDOUT 句柄）发送到命令提示符窗口。 ## 使用组合命令(Compound Command) ## + 1.__&amp; Usage：第一条命令 &amp; 第二条命令 [&amp; 第三条命令...] 用这种方法可以同时执行多条命令，而不管命令是否执行成功 Sample： 123456789C:\\\\&gt;dir z: &amp; dir c:\\\\Ex4rch The system cannot find the path specified. Volume in drive C has no label. Volume Serial Number is 0078-59FB Directory of c:\\\\Ex4rc2002-05-14 23:51 &lt;DIR&gt; .2002-05-14 23:51 &lt;DIR&gt; ..2002-05-14 23:51 14 sometips.gif + 2.&amp;&amp; Usage：第一条命令 &amp;&amp; 第二条命令[&amp;&amp; 第三条命令...] 用这种方法可以同时执行多条命令，当碰到执行出错的命令后将不执行后面的命令，如果一直没有出错则一直执行完所有命令； 12345678910111213141516Sample：C:\\\\&gt;dir z: &amp;&amp; dir c:\\\\Ex4rchThe system cannot find the path specified.C:\\\\&gt;dir c:\\\\Ex4rch &amp;&amp; dir z:Volume in drive C has no label.Volume Serial Number is 0078-59FBDirectory of c:\\\\Ex4rch2002-05-14 23:55 &lt;DIR&gt; .2002-05-14 23:55 &lt;DIR&gt; ..2002-05-14 23:55 14 sometips.gif1 File(s) 14 bytes2 Dir(s) 768,671,744 bytes freeThe system cannot find the path specified. 在做备份的时候可能会用到这种命令会比较简单，如： dir file://192.168.0.1/database/backup.mdb &amp;&amp; copy file://192.168.0.1/database/backup.mdb E:\\backup 如果远程服务器上存在backup.mdb文件，就执行copy命令，若不存在该文件则不执行copy命令。这种用法可以替换IF exist了 ：） + 3.||__ Usage：第一条命令 || 第二条命令 [|| 第三条命令...] 用这种方法可以同时执行多条命令，当碰到执行正确的命令后将不执行后面的命令，如果没有出现正确的命令则一直执行完所有命令； 12345678910Sample：C:\\\\Ex4rch&gt;dir sometips.gif || del sometips.gifVolume in drive C has no label.Volume Serial Number is 0078-59FBDirectory of C:\\\\Ex4rch2002-05-14 23:55 14 sometips.gif1 File(s) 14 bytes0 Dir(s) 768,696,320 bytes free 组合命令使用的例子： sample： @copy trojan.exe \\\\%1\\admin$\\system32 &amp;&amp; if not errorlevel 1 echoIP %1 USER %2 PASS %3 &gt;&gt;victim.txt + 4.__管道命令的使用 + 1. | 命令 Usage：第一条命令 | 第二条命令 [| 第三条命令...] 将第一条命令的结果作为第二条命令的参数来使用，记得在unix中这种方式很常见。 sample： time /t&gt;&gt;D:\\IP.log netstat -n -p tcp|find \":3389\"&gt;&gt;D:\\IP.log start Explore 看出来了么？用于终端服务允许我们为用户自定义起始的程序，来实现让用户运行下面这个bat，以获得登录用户的IP。 + 2. &gt;、&gt;&gt;输出重定向命令 将一条命令或某个程序输出结果的重定向到特定文件中, &gt; 与 &gt;&gt;的区别在于，&gt;会清除调原有文件中的内容后写入指定文件，而&gt;&gt;只会追加内容到指定文件中，而不会改动其中的内容。 sample1： echo hello world&gt;c:\\hello.txt (stupid example?) sample2: 时下DLL木马盛行，我们知道system32是个捉迷藏的好地方，许多木马都削尖了脑袋往那里钻，DLL马也不例外，针对这一点我们可以在安装好系统和必要的应用程序后，对该目录下的EXE和DLL文件作一个记录： 运行CMD--转换目录到system32--dir.exe&gt;exeback.txt &amp; dir .dll&gt;dllback.txt, 这样所有的EXE和DLL文件的名称都被分别记录到exeback.txt和dllback.txt中, 日后如发现异常但用传统的方法查不出问题时,则要考虑是不是系统中已经潜入DLL木马了. 这时我们用同样的命令将system32下的EXE和DLL文件记录到另外的exeback1.txt和dllback1.txt中,然后运行: CMD--fc exeback.txt exeback1.txt&gt;diff.txt &amp; fc dllback.txt dllback1.txt&gt;diff.txt. (用FC命令比较前后两次的DLL和EXE文件,并将结果输入到diff.txt中 ),这样我们就能发现一些多出来的DLL和EXE文件, 然后通过查看创建时间、版本、是否经过压缩等就能够比较容易地判断出是不是已经被DLL木马光顾了。 没有是最好，如果有的话也不要直接DEL掉，先用 regsvr32 /u trojan.dll 将后门DLL文件注销掉,再把它移到回收站里，若系统没有异常反映再将之彻底删除或者提交给杀毒软件公司。 + 3. &lt; 、&gt;&amp; 、&lt;&amp; \"&lt;\" 从文件中而不是从键盘中读入命令输入。 \"&gt;&amp;\" 将一个句柄的输出写入到另一个句柄的输入中。 \"&lt;&amp;\" 从一个句柄读取输入并将其写入到另一个句柄输出中。 这些并不常用，也就不多做介绍 ## 字符串处理 ## + 1) 分割字符串，以查看时间为例 %源字符串:~起始值,截取长度% (起始值从0开始；截取长度是可选的，如果省略逗号和截取长度，将会从起始值截取到结尾； 截取长度如果是负数，表示截取到倒数第几个。)__ 123456\"%time%\" 显示如：\"11:04:23.03\" (完整的时间\"hh:mm:ss.tt\")\"%time:~0,5%\" 显示\"hh:mm\"(即\"11:04\")，其中0表示从右向左移位操作的个数，5表示从左向右移位操作的个数\"%time:~0,8%\" 显示标准时间格式\"hh:mm:ss\"(即\"11:04:23\"，前8个字符串)\"%time:~3,-3%\"显示\"mm:ss\"(即从第4个开始,截去最后3个的字符串)\"%time:~3%\" 显示\"04:23.03\"(即去掉前4个字符串)\"%time:~-3%\" 显示\".tt\"(即最后3个字符串) 上面的字串分割格式，也可以用于其它地方，如目录路径：\"%cd:~0,10%\" + 2) 替换字符串 1234set a=\"abcd1234\"echo %a% 显示：\"abcd1234\"set a=%a:1=kk% 替换“1”为“kk”echo %a% 显示：\"abcdkk234\" + 3) 字符串合并 由于没有直接的字符串合并函数，只能用笨方法了。 set str1=%str1%%str2% (合并 str1 和 str2) + 4) 计算字符串长度 没有现成的函数。如下程序利用 goto形成循环，不断将字符串截短1，并记录截短的次数，到字符串变成空时的次数即长度。 1234567891011121314151617set testStr=This is a test string:: 将 testStr 复制到str，str 是个临时字符串set str=%testStr%:: 标签，用于goto跳转:next1:: 判断str是不是空，如果不是则执行下边的语句if not \"%str%\"==\"\" (:: 算术运算，使num的值自增1，相当于num++或者++num语句set /a num+=1:: 截取字符串，每次截短1set \"str=%str:~1%\":: 跳转到next1标签: 这里利用goto和标签，构成循环结构goto next1):: 当以上循环结构执行完毕时，会执行下边的语句echo testStr=%testStr%echo testStr的长度为：%num% + 5) 截取字符串时，需要传递参数 直接 echo %args:~%num%,-5% 没办法想要的字符串，(这里没懂)需要如下两步 setlocal enabledelayedexpansion echo !args:~%num%,-5! ## Registration Table Command Omit ## see more detials at here中的第六条 ## More Tips ## + \"&gt;&gt;\"追加， “&gt;”在文件中末尾添加 + 创建文件夹 md d: mkdir d: + 在命令末尾加上“&gt;NUL 2&gt;NUL”，表示隐蔽返回信息。 + 清屏 cls + 打开文件浏览器 start explorer.exe /e, /select,%_LOGFILE%（%_LOGFILE%指代文件路径+后缀） + 修改文件的后缀名 ren C:*.jpg .JPG for /r %%c in (.jpg) do (ren %%c .JPG) :: 修改当前目录下的所有文件的后缀名，包括子目录的 + 修改文件的文件名 rename test.jpg test2.JPG rename .jpg .888.JPG + 获取当前路径 cd ./ set CURE_PATH=%cd% + 打开某网站 start Chrome.exe www.baidu.com* + show the current dir's name （for的用法） @echo off for /d %%i in (???) do @echo %%i pause 这样的话如果你当前目录下有目录名字只有1-3个字母的,就会显示出来,没有就不显示了。 + del del /f /q \"%_LOGFILE%\" 将logfile变量对应的文件强制删掉，且无需提示 /f 是强制删除所有属性的文件 /q是无需确认直接删除要是再加上/s开关，就可以删除子文件加中的文件 + choice choice 使用此命令可以让用户输入一个字符，从而运行不同的命令。使用时应该加/c:参数，c:后应写提示可输入的字符，之间无空格。它的返回码为1234 如: choice /c:dme defrag,mem,end 将显示 12345678910111213141516defrag,mem,end[D,M,E]?Sample：Sample.bat的内容如下:@echo offchoice /c:dme defrag,mem,endif errorlevel 3 goto defrag （应先判断数值最高的错误码）if errorlevel 2 goto memif errotlevel 1 goto end:defragc:\\\\dos\\\\defraggoto end:memmemgoto end:endecho good bye 此文件运行后，将显示 defrag,mem,end[D,M,E]? 用户可选择d m e ，然后if语句将作出判断，d表示执行标号为defrag的程序段，m表示执行标号为mem的程序段，e表示执行标号为end的程序段，每个程序段最后都以goto end将程序跳到end标号处，然后程序将显示good bye，文件结束。 + call 批脚本里的 %* 指出所有的参数(如 %1 %2 %3 %4 %5 ...) + set 显示、设置或删除 cmd.exe 环境变量。 SET [variable=[string]] variable 指定环境变量名。 string 指定要指派给变量的一系列字符串。 要显示当前环境变量，键入不带参数的 SET。 如果命令扩展被启用，SET 会如下改变: 可仅用一个变量激活 SET 命令，等号或值不显示所有前缀匹配 SET 命令已使用的名称的所有变量的值。例如: SET P 会显示所有以字母 P 打头的变量 如果在当前环境中找不到该变量名称，SET 命令将把 ERRORLEVEL 设置成 1。 SET 命令不允许变量名含有等号。 在 SET 命令中添加了两个新命令行开关: SET /A expression SET /P variable=[promptString] #### More and More Details #### 具体语法还需详查看bat语法格式， markdown语法参见此。 另外，FOR 变量参照的替换已被增强。你现在可以使用下列 选项语法: 1234567891011121314%~I - 删除任何引号(\")，扩展 %I%~fI - 将 %I 扩展到一个完全合格的路径名%~dI - 仅将 %I 扩展到一个驱动器号%~pI - 仅将 %I 扩展到一个路径%~nI - 仅将 %I 扩展到一个文件名%~xI - 仅将 %I 扩展到一个文件扩展名%~sI - 扩展的路径只含有短名%~aI - 将 %I 扩展到文件的文件属性%~tI - 将 %I 扩展到文件的日期/时间%~zI - 将 %I 扩展到文件的大小%~$PATH:I - 查找列在路径环境变量的目录，并将 %I 扩展 到找到的第一个完全合格的名称。如果环境变量名 未被定义，或者没有找到文件，此组合键会扩展到 空字符串 可以组合修饰符来得到多重结果: 123456%~dpI - 仅将 %I 扩展到一个驱动器号和路径%~nxI - 仅将 %I 扩展到一个文件名和扩展名%~fsI - 仅将 %I 扩展到一个带有短名的完整路径名%~dp$PATH:I - 搜索列在路径环境变量的目录，并将 %I 扩展 到找到的第一个驱动器号和路径。%~ftzaI - 将 %I 扩展到类似输出线路的 DIR 在以上例子中，%I 和 PATH 可用其他有效数值代替。%~ 语法 用一个有效的 FOR 变量名终止。选取类似 %I 的大写变量名 比较易读，而且避免与不分大小写的组合键混淆。","link":"/blogs/2020/03/21/WindowBat/"},{"title":"WindowBat实战","text":"自动拷贝文件 123456789101112131415@echo offclscd ./binREM 打印当前文件夹中的dll名称dir *.dllfor /r %%j in (*.dll) do ( REM 拷贝Release版的dll到指定目录 echo %%j | find \"_d\" || xcopy %%j E:path\\Release\\ /Y REM 拷贝Debug版的dll到指定目录 echo %%j | find \"_d\" &amp;&amp; xcopy %%j E:path\\Debug\\ /Y)PAUSE 批量自动移动文件并自动建立同名文件夹 123456789101112131415161718192021222324252627@echo offREM 首先遍历最外层的文件夹，for /f %%i in ('\"dir /ad/b/on *.*\"') do ( echo \"First Dir: %%~fi\" REM MKDIR OF DESTINATION md E:\\Destination\\%%i cd %%~fi REM 获取到子文件夹之后再递归遍历子文件夹 for /f %%j in ('\"dir /ad/b/on *.*\"') do ( echo \"Second Dir:%%~fj\" REM MKDIR OF DESTINATION md E:\\Destination\\%%i\\%%j cd %%~fj REM 拷贝每个文件到预定的路径中 for %%k in (*.las) do ( echo \"Third Dir:%%~fk\" REM COPY EACH LAS FILE xcopy %%k E:\\Destination\\%%i\\%%j\\ /E /D /R /Y ) REM 返回到上层文件夹，继续后续的遍历 cd .. ) REM 同理 cd ..)REM 脚本运行完之后不退出pause","link":"/blogs/2020/03/21/WindowBat%E5%AE%9E%E6%88%98/"},{"title":"Windows-BoostUp","text":"Sublime中文乱码 自觉抵制涉猎台独相关的NotePad++，使用Sublime作为文本编辑器 但是在显示中文的时候容易出现乱码，因此需要安装一个插件ConvertToUTF8 注意可能Typora打开会出现乱码，直接重新保存成UTF8就行了。 解决步骤 打开Sublime Text，按 ctrl+` 或者点击菜单栏 View下的Show Console 调出控制台终端界面 == Sublime Text2 对于Sublime Text2，输入粘贴以下代码到底部命令行，并回车 1import urllib2,os,hashlib; h = 'df21e130d211cfc94d9b0905775a7c0f' + '1e3d39e33b79698005270310898eea76'; pf = 'Package Control.sublime-package'; ipp = sublime.installed_packages_path(); os.makedirs( ipp ) if not os.path.exists(ipp) else None; urllib2.install_opener( urllib2.build_opener( urllib2.ProxyHandler()) ); by = urllib2.urlopen( 'http://packagecontrol.io/' + pf.replace(' ', '%20')).read(); dh = hashlib.sha256(by).hexdigest(); open( os.path.join( ipp, pf), 'wb' ).write(by) if dh == h else None; print('Error validating download (got %s instead of %s), please try manual install' % (dh, h) if dh != h else 'Please restart Sublime Text to finish installation') == Sublime Text3 对于Sublime Text3，输入粘贴以下代码到底部命令行，并回车 1import urllib.request,os,hashlib; h = 'df21e130d211cfc94d9b0905775a7c0f' + '1e3d39e33b79698005270310898eea76'; pf = 'Package Control.sublime-package'; ipp = sublime.installed_packages_path(); urllib.request.install_opener( urllib.request.build_opener( urllib.request.ProxyHandler()) ); by = urllib.request.urlopen( 'http://packagecontrol.io/' + pf.replace(' ', '%20')).read(); dh = hashlib.sha256(by).hexdigest(); print('Error validating download (got %s instead of %s), please try manual install' % (dh, h)) if dh != h else open(os.path.join( ipp, pf), 'wb' ).write(by) 等待一会儿之后Ctrl+Shift+P 打开Package Control来安装插件，打开之后输入install，选择Install Package，然后选择ConvertToUTF8插件。 参考链接 GPU压力测试工具 FurMark2 提供界面，测试GPU在不同工号下是否有问题。 内存压力测试工具 Prime95可通过计算一个Prime相关的数学问题来，验证内存和CPU是否有问题，但是不建议长时间的测试，一方面会过度损耗电脑，另一方面还比较耗电。。","link":"/blogs/2025/02/08/Windows-BoostUp/"},{"title":"Zotero食用指南","text":"初衷 ​ 文献管理其实是一项需要在最开始就把工作流做好的，事半功倍。之前使用了如下的方案进行文献管理： EndNote，写文章插入citation很好用，各种标签功能也挺好用，但是云盘空间太小，无法和pdf联动，而我喜欢把笔记写在pdf上，EndNote似乎无法直接把pdf导入，只能管理基本的文献元数据，没达到我想的那种方式。后面也就只在写文章需要添加引用的时候用了。中文比较友好。奈何我需要先写SCI。 Mendeley，英文非常好，但是多平台同步太慢了，经常卡死，而且后面客户端也不更新了。无法使用。用起来很气人。 NoteExpress一开始不好用，结果后面变好用了之后也没注意到。似乎写中文毕业论文也比较好用。主要是简单。 Zotero在多年前用过，当时一系列插件还不是很健全，用起来不是很美。就没用了。 ​ 导致现状就是：笔记写在了pdf文件上，采用本地文件夹管理的方式，文件多了+时间长了+ipad联动等需求激增，想好好管理一下，发现一时间竟然没有合适的方案。 方案 zotero+坚果云 ​ zotero安装和坚果云申请就不说了。网上一大堆。虽然坚果云每个月上传下载有流量限制，但是忍过最初的几个月之后，剩下的时候不需要全部更新，应该也能顶住。 插件 ZotFile Source Folder for Attaching New Files:存放由zotero管理文件时，pdf等文件的位置，storage下是采用一种zotero默认8位数字和字母的组合的编码方式存储的文件，以.zip方式存储，根本无法和pdf文件名字对应。无法直接使用。 Location of Files:自定义的文件统一存放路径，可以根据设置好的文件/文件夹重命名方式将导入的文献重新按照统一的格式移动到这个路径中。（也就是说如果是本地文件导入了之后，这里会重新生成一个新的换了名字的相同文件，旧的就可以删掉了，每个新增的文件都需要手动移动一下位置，可以批量操作）。 use subfolder defined by /%c（%T是按照文献类别来分），这里设置的是按照我在zotero中分类的条目进行的文章归纳，这样带来的好处是，分享到其他地方仍然可以看到简单的分档归纳，问题是，文章如果想给多个分类条目，就会导致文章重复出现，因此需要在zotero中使用tag进行管理。 这里选择的文件重命名方式是“期刊简写_年份_文章名字”的方式。因为文章良莠不齐，根据期刊名字可以迅速筛掉一部分文献，根据年限可以找到最近的文章，最后才看名字，如果不相关的肯定不会下载。这种方式非常适合将pdf导出的时候，没有zotero这一套，只有pdf文件也可以进行学习。 工作流 移动端负责的是文献阅读与标注，在 Zotero 完成文献的管理后，将想看的文献发送到 iPad 上进行阅读，完成 ZotFile 的设置后，对于我们想要发送到 iPad 上的文献，右键单击，依次选择「Manage Attachments 」-&gt;「Send to subfolders on tablet」，就能够将文献按照其在 Zotero 自定义分类中的情况，创建相应的子文件夹，发送到先前设定到的目标位置。 这里其实还有一个选项，直接就是「Send to tablet」，这个选项只会将 PDF 文件发送过去，而不会创建子文件夹，对于一些临时看的文献可以选择该选项。我选择将文献发送到 iCloud 的一个文件夹中，便于在 iPad 上进行访问。发送完成后，可以在 Zotero 的侧边栏发现新增了两个分类，分别为「Tablet Files」和「Tablet Files (modified) 」，前者里面放的就是我们发送到平板上的所有文件（其实这也是类似于打标签）。 发送到 iPad 后，就可以利用各种 PDF 阅读器对文献进行标注。自带的「文件」能够进行简单的批注，实际上手时也发现足够自己使用了，但是有一个我个人不太喜欢的问题，就是「文件」会挡住文献的右边缘，不利于充分利用空间。为了尽可能模拟在纸张上阅读文献的感觉，我找到了一个叫做「PDF Viewer」的免费软件，解决了边缘空白无法利用的问题。 在 iPad 上完成文献的阅读后，进入 Zotero，在「Tablet Files」分类中找到想要取回的文献，右键单击，依次选择「Manage Attachments 」-&gt;「Get from Tablet」，就可以将标注后的 PDF 文件重新取回到 Zotero 的文件存储位置，并覆盖原来的文件，使得标注的内容得以同步。标注后的 PDF 文件体积通常会变大不少。 参考 http://zotfile.com/index.html#renaming-rules https://www.zhihu.com/question/23572825 https://andyluojj.github.io/post/zotero-kua-she-bei-wen-xian-guan-li/ https://blog.csdn.net/haoji007/article/details/127623641 jaseminum 管理中文文献的。 IF 这个插件似乎没啥用。 Zotero-Better-Notes 官方笔记见这里。 Chartero 浏览阅读的历史记录，可以看出本月看了多少文章。 创建的Chartero文件不要删掉，不然会丢掉之前的阅读记录。官方文档见这里。 阅读文章的时候，想随时翻译。 Q I want to translate manually. A Go to Edit-&gt;Preferences-&gt;PDF Translate-&gt;General, uncheck the Automatic Translation. Click the translate button on the popup or sidebar to translate. Q I want a translate shortcut. A Press shortcut Ctrl+T after you selected some text. If you are in the collection view, the titles' translation will show/hide. Zotero-Tag 官方文档在这里。可以给文章打上颜色标签，阅读的时候更容易找到想要的那个标签。 多平台同步 多平台同步的思路和流程见这里： 如果想换电脑了，而坚果云有限制（下载限制一个周期内3G）。那么可以直接把存放文件库的那个文件夹直接全部拷贝到新的电脑上，然后按照下面的设置新的路径： 然后在新电脑上就可以直接打开啦，官方文档参见这里。坚果云会自动进行同步，将旧有的文件信息不动（不会耗费流量），修改的进行同步。 注意：不要手贱删掉zotero云端的文章，不然同步的时候，本地的文件也就没有了。 参考 https://sspai.com/post/64283 其他 PDF全文索引 ​ 如果发现之前的文章找不到对应的文章了，只剩下一个假索引说明，是动了zotero的原始文件存储的位置，需要重新生成一下索引就可以了。一般来说默认新导入的文章是会自动更新索引的。Zotero空闲时会自动对PDF进行索引。但是如果发现打不开pdf了，手动更新一下就行。 文献导入后不同图标的含义 ​ 这些都是zotero自动识别出来的，可以修改。 白色+横道：期刊 白色+横道+两个小人：会议 白色+黄色铅笔：arxiv 如果发现导入的pdf自动检索不出来，可以手动更新，找到这个bibtex文件，然后导入的时候选择从剪贴板导入，然后和之前那个错误的合并一下就行。 文献导入 ​ 导入一篇文献需要完成三步操作：拖入 PDF 文献，等待元数据检索完成并检查（或先导入元数据再拖入 PDF 文件），最后右键选择 Rename Attachments。 ​ 或者直接在浏览器端，使用zotero connector将文件导入。这种平时浏览的话比较方便。 文献删除 ​ 一般来说导入的文章会存成软链接的方式，因此直接在zotero删除条目时，只会删掉软链接，文章还是不动的，可以在工具-&gt;管理附件-&gt;转换已链接文件为已存储文件。这样就一下子都可以把文件都删掉。 文献元数据更新 ​ 由于某些文献发表时间太久了，或者是发表在某个野鸡期刊上的，可能找不到doi号，进而也无法更新元数据。这种类型的pdf就不管了，文章水平也不怎么样，可以看，但是引用意义不大。 更新方式 选中文献，然后在工具中选择抓取DOI，如果能找到，那么恭喜，可以选择更新元数据，条目信息就更新了，文章也可以继续被更新； 如果找不到，那么在crossref上搜一下，找不到就没办法了。 https://formlesslab.top/2021/10/13/%E5%AD%A6%E6%9C%AF/Zotero/Zotero-%E6%89%B9%E9%87%8F%E4%BF%AE%E6%94%B9%E5%85%83%E6%95%B0%E6%8D%AE/ 信息中各个label中的意义 因为添加了Zotero IF Pro Max破解版（原版好像有问题）等插件，因此会有一些额外的bonus的数据给出来。 馆藏目录表示的是影响因子，但是不知道是加了哪个插件，现在影响因子和期刊标签，引用量都可以显示出来了。 存档位置表示的是引用量 索书号：对应JCR分区，只对SCI有效 只有使用了zotero自带的pdf阅读器才能记录有zotero style和chatero的进度条信息产生，但是pdf的注释需要手动导出才能将注释记录到pdf中。 参考链接 http://zotfile.com/index.html#renaming-rules https://zhuanlan.zhihu.com/p/31453719 https://zhuanlan.zhihu.com/p/108366072","link":"/blogs/2023/03/06/Zotero/"},{"title":"linux command usage","text":"一些常用的Linux的命令记录 Common Command 查看当前系统的版本 1cat /etc/issue 查看当前所安装的软件 1dpkg -l 查看某软件安装路径 dpkg -L | grep ftp 查看ftp的位置 查看软件版本 aptitude show 后面跟着软件名字 change the environment gedit ~/.bashrc then add some thing and sources ~/.bashrc 删除带锁文件夹（文件） 1sudo chmod -R 777 文件或文件夹 打开隐藏文件 1ctrl+h 创建快捷方式 以给Typora创建快捷方式为例： 首先创建一个typora.desktop的文件，将下列内容写入该文件中， 12345[Desktop Entry]Name=TyporaExec=/home/amazinghao/Downloads/Typora-linux-x64/bin/Typora-linux-x64/TyporaType=ApplicationIcon=/home/amazinghao/Downloads/Typora-linux-x64/bin/Typora-linux-x64/resources/assets/icon/icon_512x512.png 然后把这个文件拷贝到系统应用目录下，sudo cp typora.desktop /usr/share/applications/， 搞定。 文件解压 批量解压 1for f in *.tgz; do tar -xvf \"$f\"; done 文件太大压缩包分成多个部分，解压到一个文件夹下 xxx.tar.gz.00.tar.gz.01.tar.gz.02 12cat TRAIN.tar.gz.* | tar -zxvtar -zxv VAL.tar.gz 文件夹软连接 将一个文件夹软连接到另一个文件夹，但是在docker容器路径映射中没用。而且文件夹修改会同步生效。在使用ls命令时，文件夹路径后会有@符号。 1ln -s tar_dir src_dir 删除apt的缓存 节约磁盘空间，虽然下次再下载的时候时间会长一些。 1apt-get clean 服务器ssh服务开启 123sudo /etc/init.d/ssh status # 检查ssh服务状态sudo /etc/init.d/ssh startservice ssh start # 或者 需要先检查是否有openssh安装 12apt-get updateapt-get install -y openssh-server vim 然后设置密码，才能远程连接 123vim /etc/ssh/sshd_config # 设置允许密码连接passwd #设置密码service ssh restart # 重新打开ssh服务 服务器容器远程连接 首先服务器需要开启openssh服务 直接使用控制台终端连接 1ssh -p port_id root@server_ip vscode连接 需要一个插件Remote-SSH。然后点击远程资源服务器-远程，然后输入ssh -p port_id root@server_ip会更新配置config配置文件。比如： Host custom_name ​ HostName ip ​ Port 10008 ​ User root 查看IP 12ifconfigapt-get install net-tools 清空回收站 1sudo rm -rf ~/.local/share/Trash/* 查看cpu的核数 1cat /proc/cpuinfo| grep \"cpu cores\"| uniq 如何在ubuntu中添加一个软件的快捷方式，例如Typora 123456789101112#首先使用vim新建一个文件vim typora.desktop\"#在文件中输入下列内容[Desktop Entry]Name=TyporaExec=/opt/Typora-linux-x64/TyporaType=ApplicationIcon=/opt/Typora-linux-x64/resources/asserts/icon/icon_512x512.png#退出vim#拷贝这个文件到系统路径下sudo cp typora.desktop /usr/share/applications/#可能需要重启就出现了。","link":"/blogs/2020/05/07/linux-command-usage/"},{"title":"pcl中的体素滤波","text":"体素滤波 Voxel滤波作为一种很常见的滤波方法，但是其PCL内部代码却值得学习，因此今天转载一篇关于pcl中实现的体素滤波的方法。 基本上参考博客：https://blog.csdn.net/u013630299/article/details/105661194 #### Voxel_grid.h 需要添加头文件：#include &lt;pcl/filters/voxel_grid.h&gt; 必须保证Dx&gt;hx，Dy&gt;hy(这两个条件是必须)，第四步的时候是计算voxel空间索引.准确降采样就是在每个voxel索引里面取中值，或者随机取一个点，然后输出的点云就是降采样后的点云. 也就是说，下采样后的点云还是原始点云中的点？❤ Approximate_voxel_grid.h 需要添加头文件：#include &lt;pcl/filters/approximate_voxel_grid.h&gt; 核心源码也比较短，还有待研究。 和exact downsampling的前四步一样，先算出voxel的空间索引 ，然后通过哈希函数映射到对应的容器里面，这里假设有100个容器，按照图里面给的例子，以h%container作为hash函数映射的值，放到对应的容器里面，这样的话会出现什么情况呢，16,116对应的容器是一样的，而两个h对应的hx，hy，hz是不一样的，这就是哈希冲突。怎么处理哈希冲突呢？ 把原来容器里面的点全都取出来，清空，随机取其中的一个点作为输出，然后把新的点放进来，继续填容器的操作。相当于是拿了100个容器，一直从一堆点里面淘点，10000个点放到100个容器里面必然会有索引的冲突，一有冲突就把之前放进去的点拿出来，随机取一个点作为输出，清空，再往里面放新的点。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172template &lt;typename PointT&gt; voidpcl::ApproximateVoxelGrid&lt;PointT&gt;::applyFilter (PointCloud &amp;output){ int centroid_size = 4; if (downsample_all_data_) centroid_size = boost::mpl::size&lt;FieldList&gt;::value; // ---[ RGB special case std::vector&lt;pcl::PCLPointField&gt; fields; int rgba_index = -1; rgba_index = pcl::getFieldIndex (*input_, \"rgb\", fields); if (rgba_index == -1) rgba_index = pcl::getFieldIndex (*input_, \"rgba\", fields); if (rgba_index &gt;= 0) { rgba_index = fields[rgba_index].offset; centroid_size += 3; } for (size_t i = 0; i &lt; histsize_; i++) { history_[i].count = 0; history_[i].centroid = Eigen::VectorXf::Zero (centroid_size); } Eigen::VectorXf scratch = Eigen::VectorXf::Zero (centroid_size); output.points.resize (input_-&gt;points.size ()); // size output for worst case size_t op = 0; // output pointer for (size_t cp = 0; cp &lt; input_-&gt;points.size (); ++cp) { int ix = static_cast&lt;int&gt; (floor (input_-&gt;points[cp].x * inverse_leaf_size_[0])); int iy = static_cast&lt;int&gt; (floor (input_-&gt;points[cp].y * inverse_leaf_size_[1])); int iz = static_cast&lt;int&gt; (floor (input_-&gt;points[cp].z * inverse_leaf_size_[2])); unsigned int hash = static_cast&lt;unsigned int&gt; ((ix * 7171 + iy * 3079 + iz * 4231) &amp; (histsize_ - 1)); he *hhe = &amp;history_[hash]; if (hhe-&gt;count &amp;&amp; ((ix != hhe-&gt;ix) || (iy != hhe-&gt;iy) || (iz != hhe-&gt;iz))) { flush (output, op++, hhe, rgba_index, centroid_size); hhe-&gt;count = 0; hhe-&gt;centroid.setZero ();// = Eigen::VectorXf::Zero (centroid_size); } hhe-&gt;ix = ix; hhe-&gt;iy = iy; hhe-&gt;iz = iz; hhe-&gt;count++; // Unpack the point into scratch, then accumulate // ---[ RGB special case if (rgba_index &gt;= 0) { // fill r/g/b data pcl::RGB rgb; memcpy (&amp;rgb, (reinterpret_cast&lt;const char *&gt; (&amp;input_-&gt;points[cp])) + rgba_index, sizeof (RGB)); scratch[centroid_size-3] = rgb.r; scratch[centroid_size-2] = rgb.g; scratch[centroid_size-1] = rgb.b; } pcl::for_each_type &lt;FieldList&gt; (xNdCopyPointEigenFunctor &lt;PointT&gt; (input_-&gt;points[cp], scratch)); hhe-&gt;centroid += scratch; } for (size_t i = 0; i &lt; histsize_; i++) { he *hhe = &amp;history_[i]; if (hhe-&gt;count) flush (output, op++, hhe, rgba_index, centroid_size); } output.points.resize (op); output.width = static_cast&lt;uint32_t&gt; (output.points.size ()); output.height = 1; // downsampling breaks the organized structure output.is_dense = false; // we filter out invalid points} &amp;emsp;&amp;emsp;为什么Dx必须&amp;gt;hx,后面的y也一样，Dx其实就是x的进位，h的表达式类似于hx*1+hy*10+hz*10*10，如果Dx=x了那必然会出现不同范围的点指到同一个索引h里面，譬如假设Dx=10，hx可以等于10，以（hx，hy）作为坐标的话，（0,1）和（10,0）在同一个voxel里面，显然这是不对的。 疑问 我之前得到的voxel采样之后就不是原来的点云了，这个假设是怎么来的？","link":"/blogs/2020/06/11/pcl%E4%B8%AD%E7%9A%84%E4%BD%93%E7%B4%A0%E6%BB%A4%E6%B3%A2/"},{"title":"loss functions","text":"一些常见的损失函数调包就行，复杂的得自己写。损失函数中没有可训练的参数，因此通常直接使用torch.nn.functional中的函数即可。例如一些简单的损失函数： 1234import torch.nn as nncls_criterion = nn.CrossEntropyLoss()dist_criterion = nn.MSELoss() # Use L2 loss functionhinge_criterion = nn.HingeEmbeddingLoss() 还可以参照pytorch-metric-learning这个库 Sigmoid 准确的来说他不是损失函数，是激活函数，用来提升非线性的，但是后面常用，e.g. softmax中有，因此先学习一下。 Sigmoid数学公式 Sigmoid2 nll_loss 负对数似然损失函数(Negtive Log Likehood)，对应多分类问题： \\[ nll\\_loss = -\\frac{1}{N}\\Sigma_{i=1}^N \\mathcal{y}_i (logsoftmax) \\] 其中\\(y_i\\)是==one_hot==编码后的数据标签，NLLLoss()得到的结果即是\\(y_i\\)与logsoftmax()激活后的结果相乘再求均值再取反。（实际在用封装好的函数时,传入的标签无需进行one_hot编码） ==ont_hot==：在多分类(不是多标签分类)任务中，标签不在是二值量。需要将原来的一个标量，表示为向量，只有对应位置处的值为1，其他都是0，确保加和为1. 12345678target = torch.tensor([0, 2, 3, 1, 4])one_hot = F.one_hot(target).float()&gt;&gt;&gt; print(one_hot)tensor([[1., 0., 0., 0., 0.], [0., 0., 1., 0., 0.], [0., 0., 0., 1., 0.], [0., 1., 0., 0., 0.], [0., 0., 0., 0., 1.]]) Softmax 从argmax-&gt;softargmax-&gt;softmax而来，目的是为了找到一个数列中的最大值，在分类任务中找到概率做大的那个类就是分类的结果。softmax是指数标准化函数，又称为归一化指数函数，将多个神经元的输出，映射到 (0,1) 范围内的K维向量，并且归一化保证和为1，从而使得多分类的概率之和也刚好为1。数学原理如下： \\[ Softmax(\\mathcal{z}_i)=\\frac{\\exp (\\mathcal{z}_i)}{\\Sigma_j \\exp (\\mathcal{z}_j)} \\] \\(\\mathcal{z}_j\\)非常大或者非常小的时候就会导致指数计算出现上溢出和下溢出的问题。那么就可以统一对z的取值进行修改，比如减去\\(c=max(z)\\)，这样就不会上溢出了。但是还存在下溢出，通过数值计算中的等式变换避免下溢出的情况，即使用log函数进行变换。实际计算softmax的方式就变成如下logsoftmax形式，同时保证和为1. \\[ \\begin{align} Log(Softmax(\\mathcal{z}_i))&amp;=Log (\\frac{\\exp (\\mathcal{z}_i-c)}{\\Sigma_j \\exp (\\mathcal{z}_j-c)}) \\ &amp;= (\\mathcal{z}_i-c)-Log(\\Sigma_j \\exp(\\mathcal{z}_j)-c) \\end{align} \\] Binary Cross-Entropy 用于二分类任务，针对每个输入样本，计算预测的概率和真实标签之间的不相关性。torch.nn.BCELoss。 \\[ L = -\\left(y_{\\text{true}} \\cdot \\log(y_{\\text{pred}}) + (1 - y_{\\text{true}}) \\cdot \\log(1 - y_{\\text{pred}})\\right) \\] \\(y_{true}\\)表示真实二值标签，要么0要么1，\\(y_{pred}\\)表示正确类的预测概率，可以先用sigmoid将每个神经元输出的logits值归一化到[0,1]区间成为概率，这里不保证所有的值加起来等于1 。函数输入是(B,C)的向量矩阵，表示B个样本、C个类别和(B,C)个二值标签。 Cross-Entropy loss 交叉熵主要用于多分类任务。torch.nn.CrossEntropyLoss()。交叉熵公式表示如下： \\[ H(p,q)=-\\Sigma_i P(i)\\log Q(i) \\] 发现\\(H(p,q)\\)的计算不依赖于\\(P\\)矩阵，而仅仅与\\(P\\)的真实类别的index有关。 当input满足一定条件时，nll_loss和torch.nn.CrossEntropyLoss()是等价的。交叉熵是定义在两个one-hot向量之间的，更具体地说是定义在两个概率向量之间nll是定义在一个模型上的，取决于模型本身可以取不同的形式。步骤：1）将预测的值通过softmax进行归一化保证无上溢出问题；2）再log运算保证无下溢出问题；3）最后与真值计算负对数似然损失。 pytorch官网给出了很好的解释： 实际代码实现中就是将nnl_loss和log_softmax（可以认为就是归一化得到0-1概率值的过程）的结果进行了结合。 不需要对输入的标签进行==one_hot==编码，只需要输入对应的真实标签==（标量）==，内部自动one_hot。 还可以在计算误差是对每个类别进行加权，只需要传入一个权重矩阵就行。 传入的logits值不需要进行归一化（但是实际使用来看，还是归一化比较好），也不需要是正数，或者加起来和为1。 输出的结果依据input来，如果是一个C，那么输出就是一个标量，如果传入的是一个batch的数据，那么输出就是B个值。其他见官方说明。 1234567891011121314151617181920&gt;&gt;&gt; import torch&gt;&gt;&gt; import torch.nn.functional as F&gt;&gt;&gt; import torch.nn as nn&gt;&gt;&gt; x = torch.randn(5, 5)&gt;&gt;&gt; target = torch.tensor([0, 2, 3, 1, 4]) # 标签 这里还有一个torch.tensor与torch.Tensor的知识点https://blog.csdn.net/weixin_40607008/article/details/107348254&gt;&gt;&gt; one_hot = F.one_hot(target).float() # 对标签进行one_hot编码&gt;&gt;&gt; softmax = torch.exp(x)/torch.sum(torch.exp(x), dim = 1).reshape(-1, 1)&gt;&gt;&gt; logsoftmax = torch.log(softmax)&gt;&gt;&gt; nllloss = -torch.sum(one_hot*logsoftmax)/target.shape[0]&gt;&gt;&gt; nlllosstensor(1.8566)###下面用torch.nn.function实现一下以验证上述结果的正确性&gt;&gt;&gt; logsoftmax = F.log_softmax(x, dim = 1)&gt;&gt;&gt; nllloss = F.nll_loss(logsoftmax, target) # 无需对标签做one_hot编码&gt;&gt;&gt; nlllosstensor(1.8566)###最后我们直接用torch.nn.CrossEntropyLoss验证一下以上两种方法的正确性&gt;&gt;&gt; cross_entropy = F.cross_entropy(x, target)&gt;&gt;&gt; cross_entropytensor(1.8566) #发现是一样的 Triplet loss 公式详见点云定位的docx文档。torch.nn.TripletMarginLoss。 需要注意正负样本的选择，有不同的方式，比较常见的有两种: 一种是off-line提前计算好，这种方式需要依赖数据集中的其他信息，例如坐标，因此还是属于有监督学习的范畴; 一种是online利用网络提取的特征进行动态分类，如困难样本挖掘，这种方式训练会耗时一些，但是性能是最最优的。 该函数支持多个负样本的计算，其实就是循环，如果把每个负样本的损失计算单独拎出来，结果是一样的。 1234criterion = nn.TripletMarginLoss(margin=margin_value, p=2, reduction='sum')for n in range(negCount): negIx = (torch.sum(negCounts[:i]) + n).item() loss += criterion(anchor[i: i + 1], positives[i: i + 1], negatives[negIx:negIx + 1]) InfoNCE 全称：Information Noise-Contrastive Estimation。 是Noise-Contrastive Estimation的改进版。最初是在MoCo一文中了解到的。因为MoCo将多模态学习表达为了字典查询问题，因此可以这么说InfoNCE loss can also be interpreted as a kind of classification, where you have K-1 negative classes and 1 positive class 目的是为了通过优化的方式最大化多模态特征之间的互信息，从而使得隐向量表达多个模态之间的公有表征。The 。 相比NCE 损失，可以避免图像数量太多导致的softmax无法计算问题。 其使用mini-batch内的其他样本直接作为负样本。常见于对比学习的loss中，对比学习中假设一个anchor对应一个postive，那么这种方式就存在一些问题，比如恰好找到了相邻位置的正样本，使得所谓的负样本其实是正样本来的。因此有一些工作对此进行了改进，如CWCL。 在多模态对比学习任务中，优化Info-NCE 损失函数可以理解为最大化两个模态互信息的下界，使得隐藏层更能包含两个模态的共有信息。公式表达如下： \\[ \\mathcal{L}_{Info\\_NCE}=-log \\Large( \\frac{\\exp (q \\cdot k ^+ /\\tau)}{\\exp (q \\cdot k ^+ /\\tau)+\\Sigma_{k^-}\\exp (q \\cdot k ^- /\\tau)}) \\] \\(q,k^+,k^-\\)，分别表示query、positive，negatives的特征，负样本可有多个。特征向量之间的点乘表示两个特征之间的相似性。使用了softmax的思路进行标准化，实际使用时：就是准备好正负样本对之后，使用Cross-Entropy进行分类的。 实际问题 loss波动很厉害是为什么呢？batch_size小的时候，波动厉害是正常的，还有一种情况就是学习率太高了，导致有问题。the training loss oscillates and fails to converge. 可能需要固定一些tokenizar，不然训练会不稳定。","link":"/blogs/2023/12/27/loss-functions/"},{"title":"pcl中的点云配准","text":"记录PCL中涉及到点云配准的代码 [TOC] PCL中ICP算法实现的核心代码注释 点云配准 给定两个点云\\(\\mathbf{X}=\\{x_1,...,x_n\\},\\mathbf{Y}=\\{y_1,...,y_n\\}\\)，点云配准是为了求解两个点云之间的相对旋转\\(\\mathbf{R}\\)和相对平移\\(\\mathbf{t}\\)，他们满足如下的优化方程： \\[ E(\\mathbf{R},\\mathbf{t})=\\frac{1}{N_p}\\Sigma_{i=1}^{N_p}||x_i-\\mathbf{R}q_i-\\mathbf{t}||^2 \\] 如果知道两个点云中的同名对一点关系，那么就可以直接计算得到上述非线性函数的最优解，因此ICP算法中一个核心的突破点就是如何建立正确的同名点、如何从大量的包含错误对应的同名点中删选出正确的关系。 作为基础库，ICP的代码实现中最核心的一个过程是computeTransformation函数。 对应点类 求解位姿时需要根据同名对应点来计算，因此PCL中设计了一个同名对应类来保存这种数据。 一个有争议的地方在于：不少学者认为点云中不存在同名点的说法。个人认为，在当前激光雷达获取的点云密度非常高的情况下，同一区域重复扫描的点云之间可以认为是存在同名点的，只是同名点可以是一定距离阈值内的对应。比如2cm等。这个概念和图像领域中的匹配也是一致的，像素分辨率低的时候还不是一样可以进行配准对齐。 correspondence1 pointcorrespondence3d 变换矩阵求解 基于SVD分解的变换矩阵求解 基于LM的变换矩阵求解 基于LLS的变换矩阵求解 基于LM优化点到面距离变换矩阵求解 判断是否收敛的标准 MSE值 变换矩阵之间的差异 迭代次数","link":"/blogs/2025/04/10/pcl%E4%B8%AD%E7%9A%84%E7%82%B9%E4%BA%91%E9%85%8D%E5%87%86/"},{"title":"ALS数据采集成果制作要求","text":"根据规范：http://www.nrsis.org.cn/mnr_kfs/file/read/75d2c98b7b855b1b508b280ac53187ac 机载点云数据高程中误差在不同比例尺上精度要求是不同的。 最大允许中误差为中误差的2倍。 比例尺 地形类别 数字高程模型成果高程中误差 点云数据高程中误差 1:500 平地 0.2 0.15 丘陵地 0.4 0.25 山地 0.5 0.35 高山地 0.7 0.50 1:1000 平地 0.2 0.15 丘陵地 0.5 0.35 山地 0.7 0.5 高山地 1.5 1.0","link":"/blogs/2025/02/08/%E6%8E%A7%E5%88%B6%E7%82%B9%E6%A3%80%E6%A0%B8-ALS%E9%87%87%E9%9B%86%E7%B2%BE%E5%BA%A6%E8%A6%81%E6%B1%82/"},{"title":"关于控制点检核的一些思考","text":"使用地面控制点检核ALS点云精度 任务描述 ​ 使用地面布设的外业控制点GCP来检核ALS点云条带平差之后的绝对位置精度。如下图所示，红圈中的是GCP点，紫色和灰色是两个条带的ALS点云。图中显示了在\\(z\\)方向上的偏差。 ​ 通过观察，有一部分控制点是在平面区域采集的，有一些是在边缘比较锋利的区域采集的。 目前存在的问题 ​ 本身ALS点云就比较稀疏，再加上GCP也是离散的布设的，导致很难找到对应同名关系，想要找到对应位置的值就只能通过内插来实现。 ​ 内插方法有很多，但是直接在ALS里面内插不是很现实，可以考虑转成格网，mesh的形式，然后基于新的数据表达方式再内插。例如可以用arcgis生成DTM，DEM，内插到高分辨率，然后再采样点和GCP做计算。 解决方案 最终论证，通过地面控制点应该是无法做到水平精度检核的，只能做到高程方向的检核。 相关方法 A Quantitative Assessment of LIDAR Data Accuracy1 ​ 文章里面的高程和平面精度是分开计算的。 对于高程精度 首先只能选择平面上的控制点。GCP是有规律线性分布的方式布设的，因此作者就选择1m范围内的点作为领域点，然后拟合平面，计算高程方向上的偏差。 对于平面精度 由于对应关系不好确定，采用两个曲线先平移后相交的方式确定对应关系。首先找到地面控制点一定半径内的点作为候选对应同名点，然后绘制曲线，通过在东(北)方向以0.01\\(m\\)平移曲线，找到和GCP最吻合的位置（好像是逐位置计算误差，找到误差最小的就以对应时刻的步长作为偏移量），就说明找到了ALS和GCP之间的同名关系。曲线绘制方式是，在东(北)方向和高程方向构成的平面中分别投影GCP和ALS点云，消除高度偏差之后，就可以得到两条大致重叠的曲线。 问题： 依然确实存在平面点不对应的问题，导致精度计算出现问题。 此外，要求GCP是线性分布的，不然没法计算曲线。对检核点的布设要求很高。 Accuracy of ground surface interpolation from airborne laser scanning (ALS) data in dense forest cover2 简介 ​ DTM的精度取决于激光系统测量值的精度和准确度、点云滤波的精度（因为需要滤除地面点才能做DTM），以及需要内插来解决空洞问题。其中内插精度为影响DTM精度第二主要因素，因此文章主要是想在森林密集的区域，通过比较生成的DTM的精度来进一步验证9种内插方式的精度。涉及到的内插方式有：==反距离加权、最近邻、自然内插、Delauney三角网、多层-B-Spline、三次样条、Thin-Plate Spline、Thin-Plate Spline by TIN、克里金插值法==。对比方法为使用cross-validation的方式，将预测值与真值GT做差，计算偏差和RMSE。 方法 简介 方法实现 IDW:反距离权重 距离越近的点，值越相近 ArcGIS NeN:最近邻域 首先构建Thiessen多边形，直接将处于多边形内的点全部都赋予参考点的值 GDAL NN:自然邻域3 首先构建Thiessen多边形，根据上采样点的位置更新多边形，用多边形的中心，后续每个点的插入进来更新多边形，动态变化 Delauney Triangulation:狄罗妮三角化 构建TIN，得益于三角网的构建，将落在三角网内的点，用线性内插或者是多项式内插的方式来采样值，base点是三角网的格网点 ArcGIS MBA:多尺度-B-Spline4 构建层级的B-Spline SINTEF,ddemidov Cubic Spline:三次样条5 基于三次Spline函数实现表面近似 GDAL,[SAGA][] Thin-Plate Spline6 基于三次Spline的2D泛化形式 GDAL Thin-Plate Spline by TIN 在TIN构建的三角网内构建TPS，实现内插 [SAGA][] Kriging:克里金 构建semi-variogram，然后计算一些地理相关的参数，实现空间相关的内插 ArcGIS 结论 ​ 内插方法的精度和想要生成的DTM的分辨率有关，DTM分辨率越低，内插精度越差，但是不同内插方法之间的RMSE在点云密度、熵密度、地面坡度等因素下变化不明显。NN和Spline类的方法总体精度相近，但是NN的方法不需要额外的输入，而且效率要比样条线的高一些。其中： 反距离权重的精度最低。同时NeN、克里金插值方法受到点密度和陡峭坡度地形影响大，精度会降低。 样条线类的方法得到的表面更加平滑，也接近真值，不同函数之间的RMSE均比较小，适用于崎岖的地形=坡度大、陡峭的地方。不同的样条基函数之间没有明显差异。反倒是越复杂计算时间越长。 只有克里金插值方法受熵密度的影响大，其他方法由于测试数据的问题，并不能得出很充分的相关关系。 NN，DT，Spline-based 方法受到地面点密度、地面坡度变化的影响小。 Scattered data interpolation with multilevel B-splines4 Motivation ​ 目的是从离散点云中实现点云表面拟合B-spline approximation (BA)。现有方法也有用B-spline的，但是依然受限于平滑性，时间复杂性，限定范围内的数据分布等的限制。因此本文提出使用层级的bicubic B-spline修正方法来逼近直接拟合B-spline，并且实现了最小的内存占用。本文是从Image morphing中借鉴过来的。 Basic Idea ​ Let \\(\\Phi_{ij}\\) be the value of the \\(ij\\)-th control point on lattice \\(\\Phi \\in \\Omega ^{(m+3) \\times (n+3)}, \\Omega = \\{ (x,y)| 0 \\leq x &lt;m, 0 \\leq y &lt; n \\}\\), located at \\((i,j)\\) for $ i =-1,0,...,m+1$ and \\(j =-1,0,...,m+1\\). The ==approximation function== \\(f\\) is defined in terms of these control points by: \\[ f(x,y)=\\Sigma_{k=0}^3\\Sigma_{l=0}^3B_k(s)B_l(t)\\sigma_{(i+k)(j+1)} \\] where \\((x,y)\\) is a scattered point in \\(\\Omega\\), \\(i=\\lfloor x \\rfloor -1,i=\\lfloor y \\rfloor-1,s= x-\\lfloor x \\rfloor\\), and \\(t=y-\\lfloor y \\rfloor,t \\in [0,1)\\). \\(B_k,B_l\\)是均匀三次B-spline函数. 即 \\(f: \\Omega \\mapsto \\mathbb{R}\\)表明了函数\\(f\\)将平面domain的点映射为一个表面。 With this formulation, the problem of deriving function \\(f\\) is reduced to solving for the control points in \\(\\Phi\\) that best approximate the scattered data in \\(P=\\{(x_c,y_c,z_c)\\}\\). Methodology ​ 本文通过多层B-spline来实现表面近似任务中平滑性和准确性之间的平衡。使用控制顶点的层级性得到一系列的函数，通过求和实现近似。coarse的顶点提供粗略的近似，使用finer的顶点构成的函数来优化精度。 ​ 那么使用B-spline来做数据拟合最终调整的是什么呢？根据B-pline的定义和另一篇博客可知。近似的目的就是要不断调整样条曲线中控制点的权值，使得能够最大限度的拟合所给的离散数据。理解这个很重要。控制点的位置是固定分布在domain的，也就是随着knot的。表面拟合的结果和控制点的分辨率是有关系的。 分辨率越低，越能覆盖到更多的数据点，大量的数据点会得到比较平滑的拟合结果。 分别率越低，因为指用到了局部的信息进行拟合，因此局部拟合的更好，但是全局来看不同区域之间的过渡不是也很好，有很多零的区域。 ​ 作者提出首先在\\(\\Omega\\)域内构建层级的控制点\\(\\Phi_0,\\Phi_1,...,\\Phi_h\\)。相邻层间控制点数量比为1:2，首先在coarest的控制点\\(\\Phi_0\\)上运行一次BA算法作为初始平滑近似\\(f_0\\)。这样会在一些散点上有较大的偏差，例如在点\\(P_1\\{(x_1,y_1,z_1)\\}\\)上存在较大的偏差\\(\\Delta^1 z_c\\)(上标1表示是第一次近似得到的偏差)，用\\(\\Delta^1 z_c\\)替换\\(z_1\\)，变成\\(P_1\\{(x_1,y_1,\\Delta^1 z_c)\\}\\)。依次类推，用\\(f_0+f_1\\)可以得到一个更小的偏差\\(\\Delta^2 z_c=Z_c-f_0(x_c,y_c)-f_1(x_c,y_c)\\)。那么从coarest的\\(\\Phi_0\\)开始直到finer的控制点\\(\\Phi_h\\)，最终的近似结果可以表示为\\(f=\\Sigma_{k=0}^hf_k\\)，即一系列层级近似结果的叠加。只需要在全部的点上做一次分辨率低的近似就可以得到全局的形状。按照上述方案，就实现渐进式的平滑近似。时间复杂度是\\(\\mathcal{O}=hp+\\frac{4}{3}mn\\)，空间复杂度是\\(\\mathcal{O}=p+\\frac{4}{3}mn\\)，并且仍然可以实现\\(C^2\\)的平滑性。\\(mn\\)是domain的范围，是正整数。\\(p\\)是3D点。 ​ 由上可知，需要不断的计算B-Spline函数，导致计算效率下降，作者因此提出一种局部B-Spline精化方法实现计算效率的提升。此外作者还根据数据分布提出一种自适应的分层方法。这里就先略了。重点关注前面。 相关实现 SINTEF，实现了文献 4 中的多尺度样条曲线表面拟合，但是代码比较老了，需要额外编译，除了代码框架复杂一些，编译不是问题。 ddemidov: 基于C++11做了一个文献 4 新的版本，实现了adaptive 的MBA，开发了python的API，并且是header-only的方式，方便使用。根据官方提供的jupyter notebook的测试显示，两个库对于相同数据的内插结果之间并没有很大的误差。 Smooth Approximation and Rendering of Large Scattered Data Sets5 Motivation ​ 表面拟合任务要求：近似程度要高、可视质量要好、适用于大数据量、高效、数值计算稳定、自适应性好以及算法简单易实现等。基于spline的方法有很多，e.g. NURBS要求数据分布均匀，存在依赖矩形的分布空间，近似误差大等问题。其他spline的方法，依赖三角网，而且对数据分布要求较高，还需要全局最小二乘近似等。Related Work写的不错。 Methodology ​ 本文提出一种两阶段方法实现表面美观、属性好的表面拟合方法。Step1：仅使用==局部==少量的数据点计算离散的最小二乘多边形段discrete least squares polynomial pieces，基于==SVD==构建了\\(Bernstein-B \\'{e} zier\\)形式以根据实际点云分布空间初始多边形的次数。Step2：基于\\(C^1\\)连续条件结合相邻的三角化\\(Bezier\\)块直接得到剩余多边形段。算法不需要全局计算，不依赖三角网，不需要计算导数。 ​ 基于\\(C^1\\)连续的bivariate cubic spline实现了大场景下散点的最优近似拟合。使用局部多边形最小二乘近似的方式来减少数据的局部差异和非均匀分布的问题。但是考虑到实际数据分布，算法使用的cubic spline的次数是自适应变化的。算法的复杂度是和点数成线性关系的。这里去掉了从数据生成三角网的过程，而算法在介绍的时候依赖三角网的生成。中间使用了LOD加速计算。 ​ 最后使用了\\(Bernstein-B \\'{e} zier\\)来评估和渲染spline。通过计算spline点和散点之间的单向\\(Housdorff\\)距离来评估质量。 结论 点云越密，构建的多边形阶数越高。拟合误差最大为\\(m\\)级。 在一块a Vpro/8 graphics board可以做到10FPS。 相关实现 [SAGA][]：SAGA - System for Automated Geoscientific Analyses - is a Geographic Information System (GIS) software with immense capabilities for geodata processing and analysis. SAGA is programmed in the object oriented C++ language and supports the implementation of new functions with a very effective Application Programming Interface (API). Functions are organised as modules in framework independent Module Libraries and can be accessed via SAGA’s Graphical User Interface (GUI) or various scripting environments (shell scripts, Python, R, ...). 提供了编译好的可执行程序和源代码。针对内插方法，SAGA已经实现了B-spline Approximation、Cubic Spline Approximation、Multilevel B-Spline、Multilevel B-Spline (3D)、Multilevel B-Spline for Categories、Multilevel B-Spline form Grid Points、Thin Plate Spline、Thin Plate Spline (TIN)。包含了文章[^ 4]中提到的大部分算法。每种内插方法配有注释。简单测试之后发现确实和文章中提到的结论一致，起码效率方面表现相同。 Approximate thin plate spline mappings6 ​ Thin plate spline是一种常见的使用基函数实现从\\(\\mathbb{R}^2\\)到\\(\\mathbb{R}^2\\)坐标映射的方法。本身TPS是cubic spline的2D泛化形式，TPS模型包含一个仿射模型作为一个特例。TPS模型需要对一个超大的密集矩阵\\(p \\times p\\)进行求逆，\\(p\\)是点数。为了减少求逆的运算量，提出了很多的改进方法，包括使用局部对应点集来估计全部对应关系的方法，本文结合高斯径向基网络领域中的相关方法来讨论基于这个思路的近似方法的优缺点。指出借鉴径向基函数的方法不满足principal warp分析7的要求，因此借助经典矩阵补全技术进行完善。最后，作者讨论了一种使用全部近似基函数来近似目标集数据的方法，即\\(Nystor\\ddot{o}m\\)近似法实现TPS映射。最后作者并总结了三种近似方法之间的优缺点：基于局部点采样并考虑全部目标集的方法的效果都不错，基于\\(Nystor\\ddot{o}m\\)近似的方法不但可以实现principal warp 分析，同时在子集采样结果不好时表现出最优的性能。并用实验突出了在图像编辑方面的优势。 数学有点啃不动。详见文章6和8。 LR B-Spline ​ 最新版书籍8中全面细致的总结了不同地形表面表达方式之间的区别，并肯定了local refine B-Spline表达形式（其实是一类方法）的好处。 Surface type Representation and data structure Algorithm and control of accuracy Surface smoothness Restricting data volume Raster Values on regular mesh Spatial interpolation to define sample values. Accuracy checked after creation Depends on interpolation method for evaluation between mesh Pre-set mesh resolution defining data volume B-spline surface Piecewise polynomials on regular mesh, any bidegree Coefficients calculated by local/global approximation. Accuracy checked after surface creation Depends on polynomial bidegree and knot multiplicity Pre-set mesh resolution defining data volume TIN Triangulation Triangulate point cloud + thinning or adaptive triangulation. Accuracy can be checked during creation Piecewise linear Pre-set approximation tolerance and/or max allowed data volume LR B-spline surface Piecewise polynomials on LR axis-parallel mesh, any bidegree Coefficients calculated by local/global approximation. Local adaption by checking accuracy during construction and refinement where needed. Depends on polynomial bidegree and knot multiplicity Pre-set approximation tolerance or restrictions in adaptive algorithm 相关实现 SINTEF下属的应用数学研究所开发的GoTools，The core module contains generic tools and spline functionality. The additional modules contain functionality for intersections, approximative implicitization, parametrization, topology, and more. 包含NURBS 和TIN模板库。 References [SAGA]: https://sourceforge.net/projects/saga-gis/ \"Conrad,O.,Bechtel,B.,Bock,M.,Dietrich,H.,Fischer,E.,Gerlitz,L.,Wehberg,J.,Wichmann,V.,andBoehner,J.(2015):SystemforAutomatedGeoscientificAnalyses(SAGA)v.2.1.4.Geosci.ModelDev.,8,1991-2007,doi:10.5194/gmd-8-1991-2015.\" Elaksher A, Ali T, Alharthy A. A Quantitative Assessment of LIDAR Data Accuracy[J]. Remote Sensing, 2023, 15(2): 442. ↩︎ Cățeanu M, Ciubotaru A. Accuracy of ground surface interpolation from airborne laser scanning (ALS) data in dense forest cover[J]. ISPRS International Journal of Geo-Information, 2020, 9(4): 224. ↩︎ A brief description of natural neighbour interpolation ↩︎ Lee S, Wolberg G, Shin S Y. Scattered data interpolation with multilevel B-splines[J]. IEEE transactions on visualization and computer graphics, 1997, 3(3): 228-244. ↩︎ Haber J, Zeilfelder F, Davydov O, et al. Smooth approximation and rendering of large scattered data sets[C]//Proceedings Visualization, 2001. VIS'01. IEEE, 2001: 341-571. ↩︎ Donato G, Belongie S. Approximate thin plate spline mappings[C]//Computer Vision—ECCV 2002: 7th European Conference on Computer Vision Copenhagen, Denmark, May 28–31, 2002 Proceedings, Part III 7. Springer Berlin Heidelberg, 2002: 21-31. ↩︎ Bookstein F L. Principal warps: Thin-plate splines and the decomposition of deformations[J]. IEEE Transactions on pattern analysis and machine intelligence, 1989, 11(6): 567-585. ↩︎ Kermarrec G, Skytt V, Dokken T. Optimal Surface Fitting of Point Clouds Using Local Refinement: Application to GIS Data[M]. Springer Nature, 2023. ↩︎","link":"/blogs/2025/02/08/%E5%85%B3%E4%BA%8E%E6%8E%A7%E5%88%B6%E7%82%B9%E6%A3%80%E6%A0%B8%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83/"},{"title":"点云数据处理","text":"记录一下目前在点云数据处理中比较头疼的问题。 虽然大家都说移动测量系统很好，采集的点云精度很高。但是真实情况是，在很多情况下，尤其是出现下面几种情况的时候，点云的精度都不能达到实际生产任务需要。 生产经验少，有好的解决方案随时更新。 由于镜像问题导致的点云异常 点云重访中的位置偏差","link":"/blogs/2025/05/21/%E7%82%B9%E4%BA%91%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/"},{"title":"激光雷达传感器","text":"记录几种常见的激光雷达类型 机械式、固态式、半固态、单线激光雷达 禾赛Pandar40 从下图可以看出它的线束在纵向方向是不均匀分布的。 其基本参数如下所示： MID360 Video 不同类型传感器获取的数据对比 单线激光雷达","link":"/blogs/2025/01/15/%E6%BF%80%E5%85%89%E9%9B%B7%E8%BE%BE%E4%BC%A0%E6%84%9F%E5%99%A8/"},{"title":"电力线走廊点云切档","text":"记录一些之前项目中的任务需求，避免遗忘。 电力线走廊点云全局图 点云数据处理需要切档，切档依赖电力杆塔的位置。切档的方式有两种： 沿着垂直于走廊的方向向两侧延伸一段距离可以得到长方形的点云分档； 沿着相邻点云杆塔之间电力线夹角的角平分线分割； 长方形切分 角平分线切分 两种分割方式之间存在差异，因此有一个任务是需要将不同的分档点云进行转换。 补充之后的效果如下所示（白色和红色就是计算出来的需要补充的区域）：","link":"/blogs/2025/04/10/%E7%94%B5%E5%8A%9B%E7%BA%BF%E8%B5%B0%E5%BB%8A%E7%82%B9%E4%BA%91%E5%88%87%E6%A1%A3/"},{"title":"超算服务器使用记录","text":"​ 课题组提供的GPU实在是不够用，就想着用一下学校的超算，结合之前使用的广东超算中心的经验，这里简单列一下学校服务器的一些常用命令。 ​ 武大超算使用 Slurm 系统，统一管理所有计算资源、统一调度所有用户的计算任务，用户必须通过 Slurm 系统来进行计算 空间管理 查看当前空间使用/bin/myDiskQuota,查看当前空间有多少剩余。 1234name@swarm02 ~]$ /bin/myDiskQuota Dir DiskUsed DiskQuota DiskFree Files FilesQuota home 0M 1024M 1024M 10 10000 project 0G 500G 500G 1 500000 数据上传 直接用FileZilla上传就行。 作业提交 ​ 需要编写一个sbatch的脚本文件，然后调用sbatch xxx.sbatch即可。sbatch脚本如下样例： 123456789101112#!/bin/bash#SBATCH --partition=hpxg#SBATCH --nodes=1#SBATCH --ntasks-per-node=1#SBATCH --time=06:00:00module load anaconda/3.7cd $SLURM_SUBMIT_DIRpython mycode.py","link":"/blogs/2025/02/08/%E8%B6%85%E7%AE%97%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%BD%BF%E7%94%A8/"},{"title":"FFMPEG-Usage","text":"Usage Here, i'm trying to sequeeze a normal video to a n times faster. But, i found that there are many ways to relize this, such as ffmpeg and adjust the speed while roamming, etc. OpenCV requires being complied with ffmpeg, which i didn't have the condition and many video format(.mp4) is not well supported. Installation Under Linux 1sudo apt install ffmpeg Under Windows Directly download the binary executable file from the official page. Move to the bin folder and run the ./ffmpeg in command line. For example the \"ffmpeg-master-latest-win64-gpl-shared\" file. Some common command line arguments From ffmpeg official page. -y: (default) to automatically override the out file without further confirmation. -i: input file. -vf: video filter, e.g. v360 et al. -bufsize: set the buffer size. -c:v libx265: libx265 video encoder. -b:v 40000k: setting code rate of video. --preset: 主要调节编码速度和质量的平衡，有ultrafast（转码速度最快，视频往往也最模糊）、superfast、veryfast、faster、fast、medium、slow、slower、veryslow、placebo，从快到慢. Video speed acceleration Speed or slow down the video, and the example as followings （but the content is not smooth at all）: *** 4 times faster:+1: ffmpeg -i origin.mp4 -vf \"setpts=0.25\\*PTS\" UpTheOrigin.mp4 4 times slower ffmpeg -i origin.mp4 -vf \"setpts=4\\*PTS\" DownTheOrigin.mp4 Change the video format ffmpeg -i origin.ogv -vcodec h264 output.mp4 ffmpeg -i origin.ogv -vcodec mpeg4 output.mp4 ffmpeg -i origin.ogv -vcodec libxvid output.mp4 ffmpeg -i origin.mp4 -vcodec wmv1 output.wmv ffmpeg -i origin.mp4 -vcodec wmv2 output.wmv Compress video into a smaller one. 1ffmpeg -i input.mp4 -vcodec libx265 -crf 28 output.mp4 More resources Please dive the Blog. Attach two images(videos) into one image(video) 1.\\ffmpeg.exe -i D:\\CodeSpace\\fisheye_image\\0000000007-l.png -i D:\\CodeSpace\\fisheye_image\\0000000007-r.png -filter_complex hstack -y ./dual_fisheye_image.png -filter_complex hstack: hstack means images are stacked horizontally, vertically is set to vstack. the raw separate images are here: left image right image the returned joined image (./dual_fisheye_image.png) is as followings: References joint two images into one:+1: Fisheye Image to equirectangular Image For single dual fisheye image to equirectangular image. 1./ffmpeg -i .\\dual_fisheye_image.png -vf v360=dfisheye:e:ih_fov=185:iv_fov=185:yaw=-90 -y ./equirectangle_image.png 185 is the image FOV. References fisheye to equirectangular image (Recommanded:+1::+1::+1:) similar as upper for yaw angle setting demonstration. here is information-less:-1:. Sequence image to video back and forth image to video 1.\\ffmpeg.exe -f image2 -r 1 -i xxx/000000000%d.png -vcodec libx265 -pix_fmt yuv420p -b:v 40000k -bufsize 5000k -preset ultrafast -c:a copy -y -r 1 ./fisheye_rgb.mp4 -f: image2 image type. -r: video frame equal to 1, default by 25, which means extract 1(25) frames/s. Also known as definition how fast the pictures are read in. To note that, the position of the -r argument has different meanings. If we want to change the framerate of the output video, -r should be at the front of the ./fisheye_rgb.mp4 -pix_fmt yuv420p: is required under Windows platform. video to image 1.\\ffmpeg.exe -i .\\fisheye_rgb_l.mp4 -r 1 -q:v 1 -start_number 0 ./%10d.png %10d: rename the out put images with int, e.g 0000000001.png. -start_number 0: means the result image id will start from 0. Also this argument could be used for selecting the specific images for video generation. Deeper operations(e.g. glob, cat and etc) from reference1. References shotstack create a video from images with FFMPEG:+1: Dual fisheye image video to equirectangular video For dual fisheye video to equirectangular video. 1./ffmpeg -y -i $file -vf v360=dfisheye:e:yaw=-90:ih_fov=187.8:iv_fov=185 -c:v libx265 -b:v 40000k -bufsize 5000k -preset ultrafast -c:a copy out.mp4 here we choose the ==v360== filter, v360 basic command as followings: input:output:interp:w:h:in_stereo:out_stereo:yaw(pitch\\roll):rorder:h_filp(v_flip\\d_flip):ih_flip(iv_flip):in_trans:out_trans:h_offset(\\v_offset):alpha_mask:reset_rot and the corresponding parameters as followings: dfisheye = input format is dual fisheye video for input. e = 'Equirectangular projection' for output video format. yaw = rotation along yaw direction for output video. Values in degrees. ih_fov &amp; iv_fov = is output horizontal/vertical/diagonal field of view. Values in degrees. there are no blending operation for the basic command code. References More details at here Basic pipeline from wiki (Recommand:+1::+1::+1:)","link":"/blogs/2020/02/29/%E8%A7%86%E9%A2%91%E5%8A%A0%E9%80%9F%E5%B0%8F%E6%8A%80%E5%B7%A7/"},{"title":"鱼眼图像投影模型及使用","text":"前序 ​ 简单介绍一下目前的相机种类，主要是对相机镜头按照焦距及视角的大小，可分为标准镜头、广角镜头和鱼眼镜头。他们的一些特点如下： 焦距：鱼眼镜头（小于等于16\\(mm\\)）&lt;广角镜头&lt;普通标准镜头（50\\(mm\\)）。 视场角：鱼眼镜头（接近或者大于180°，工程上大于140°的就算）&gt;广角镜头&gt;普通标准镜头。 畸变：鱼眼镜头&gt;广角镜头&gt;普通标准镜头。 普通单目相机 简介 ​ 一般常见的普通小孔成像相机的成像模型如下所示，小孔相机模型采用相似成像的方式（入射角和出射角等大），内参包括焦距\\(f_x,f_y\\)和主点偏差\\(c_x,c_y\\)。如果焦距一定，那么图像传感器像素平面的面积直接决定了相机视场角的大小，超过这个视场角范围的物体不会被镜头获取到。因此基于透镜成像原理的相机，视场角无法做到足够大，水平视场角一般小于140°。在某些时候，比如气象科学空间观测、太阳能辐射研究计算天空视角系数、安防视频监控等实际场景中可能会需要更大视场角的相机，那么这时候广角相机-鱼眼相机就出现了。 透视成像的小孔成像相机模型，图源于这里 投影模型 \\[ r_d=f \\cdot tan \\theta \\] 投影和反投影过程 ​ 不考虑图像畸变的情况下，透视（小孔）成像的相机投影过程（3D-&gt;2D）如下，\\(u,v\\)为图像像素坐标，\\(X,Y,Z\\)为相机坐标系下的坐标。 \\[ \\begin{align} \\label{pinhole_projection} u &amp;= \\frac{f_x X}{Z}+c_x \\\\ v &amp;= \\frac{f_y Y}{Z}+c_y \\end{align} \\] ​ 其对应相机反投影过程（2D-&gt;3D）如下，\\(\\bar{X},\\bar{Y}\\)为归一化坐标（即相机坐标系下的坐标变换到归一化相机坐标系）。 \\[ \\begin{align} \\label{pinhole_inverse_projection} \\bar{X} &amp;= \\frac{u-c_x}{f_x} \\\\ \\bar{Y} &amp;= \\frac{v-c_y}{f_y} \\end{align} \\] 广角相机 ​ 为了获得更大视角，出现了广角相机。根据==Davide Scaramuzza==大神写的“Omnidirectional Camera”一文，有三种镜头聚光方式：第一种通过透镜折射实现；第二种通过使用标准相机加一个面镜实现；第三种通过多个相机共心组装而成（测绘中常见这种，拼接出全景图像）。如下图所示： ​ 传统广角相机的镜头一般由多个镜头组成，如下图所示为几种镜头的结构方式及其参数： 广角镜头示意图，图源于An aquatic-vision-inspired camera based on a monocentric lens and a silicon nanorod photodiode array 鱼眼相机 简介 ​ 广角相机的视场角也没有超过180°，人们为了获得更大的视场角，根据斯内尔（Snell's law）现象发明了鱼眼相机，又因为其镜头和鱼眼非常接近，因此取名鱼眼相机。鱼眼相机拥有更大的球面弧度（超广角），成像平面离透镜更近（短焦距）。为了获得更加的视场角，鱼眼相机只能牺牲一部分精度，引入一些畸变（主要是径向畸变）的同时压缩边缘。 ​ 鱼眼镜头属于一种特殊的超广角镜头。 ​ 鱼眼镜头采用非相似成像（入射角比出射角大）。其镜头组成如下图所示： 鱼眼相机的镜头组成，图源于这里 ​ 鱼眼相机的成像方式可以看成是先将3d点投影到单位球面，单位球上的点在以偏离\\(z\\)轴\\(\\xi(或f)\\)处通过针孔模型进行投影，这样水平入射的光线也能投影到图像的像素区域内。其成像模型如下所示。单位半球面上的点\\(q\\)投影到相机成像平面上的点\\(r_d\\)的过程是一个非线性过程，此时折射角\\(\\theta_d\\)小于入射角\\(\\theta\\)。成像模型也称投影模型。投影模型要表征的就是成像平面的像高\\(r_d\\)和入射角\\(\\theta\\)之间的映射关系。 鱼眼相机的成像模型，图源于这里 ​ 鱼眼相机根据不同的投影方式可以分为以下几种：\\(\\theta\\)为入射光线与鱼眼相机光轴之间的夹角（入射角），\\(f\\)为焦距，\\(r_d\\)为像点至畸变中心的距离。 等距投影 等立体角投影 体视投影 正交投影 畸变量适中，最常用 相等立体角的入射面会产生相等面积的像 保角不变投影 畸变最大，但不会产生透射导致的近大远小 \\(r_d=f \\cdot \\theta\\) \\(r_d=2 \\cdot f \\cdot sin(\\theta/2)\\) \\(r_d=2 \\cdot f \\cdot tan(\\theta/2)\\) \\(r_d=f \\cdot sin(\\theta)\\) 鱼眼相机的成像模型分类，图源于这里 通用相机模型 ​ 鱼眼相机是由多个镜头组成的，上面的投影方式还是过于简单了，理论计算出来的结果和实际差很多，因此出现了一些对鱼眼相机进行建模的方案。常见的有Kannala-Brandt模型、Mei模型、Scaramuzza模型、PolyFisheye模型等。 Kannala-Brandt 模型 ​ Kannala-Brandt 模型发表于TPAMI2006的“A Generic Camera Model and Calibration Method for Conventional, Wide-Angle, and Fish-Eye Lenses”，作者将普通小孔成像、广角、超广角、鱼眼相机模型统一起来。同时统一了畸变的建模方式。通过将不同投影模型的函数，如\\(\\sin,\\tan\\)进行泰勒展开，发现遵循一个相似的多项式方程，因此Kannala-Brandt 模型采用了多项式来近似畸变。原始论文中给出了径向畸变、切向畸变等模型，但是实际中发现只选取多项式的前几项即可得到不错的精度，因此后续的代码库中均存在不同程度的简化和近似。如camodocal和OpenCV中均采用了8参数模型(固定\\(k_0=1\\)，\\(k_1,k_2,k_3,k_4,f_x,f_y,c_x,c_y\\))，如下为OpenCV中实现的通用相机去畸变模型，由于只是兼容鱼眼相机，因此其中充满小孔成像的影子。 \\[ \\begin{align} 世界坐标系X\\rightarrow相机坐标系X_c &amp;:\\left[\\begin{array}{c} X_c \\\\ Y_c \\\\ Z_c \\end{array} \\right] = RX+t \\\\ 归一化相机坐标系p_c &amp;: x_c = \\frac{X_c}{Z_c},\\ y_c=\\frac{Y_c}{Z_c}\\\\ &amp; \\theta = arctan(r),r^2 = x^2_c + y^2_c\\\\ 畸变模型 &amp;: \\theta _d = \\theta(k_0+k_1\\theta^2+k_2\\theta^4+k_3\\theta^6+k_4\\theta^8)\\\\ 去畸变之后的点p_{u} :&amp; x_d=\\frac{\\theta_d}{r}x_c, \\ y_d=\\frac{\\theta_d}{r}y_c\\\\ 归一化相机坐标系\\rightarrow 像素坐标系 &amp;:u=f_xx_d+c_x, \\ v=f_yy_d+c_y \\end{align} \\] ​ but there still are some paper use the following model, and i don't know why... \\[ \\begin{align} r_d &amp; = f \\theta_{distorted} \\\\ k_0\\theta + k_1 \\theta^3 + k_2 \\theta^5 + k_3 \\theta^7 + k_4 \\theta^9 \\end{align} \\] ​ KB模型需要5个参数就能实现畸变校正，\\(k_0,k_1,k_2,k_3,k_4\\)。但KB模型仍遵循针孔成像的基本假设，导致该模型存在奇点（水平入射的光线将被投影到无穷远），因此Mei模型就出现了。 In practice, most systems will characterize Kannala-Brandt distortions purely in terms of the symmetric radial distortion, as that distortion is significantly larger in magnitude and will be the leading kind of distortion in wider-angle lenses. Scaramuzza模型 ​ Scaramuzza大神在IROS 2006的文章“A Toolbox for Easy Calibrating Omnidirectional Cameras”中提出的的鱼眼相机模型。 Mei模型 ​ Mei模型是在ICRA2007中的“Single View Point Omnidirectional Camera Calibration from Planar Grids”一文中专门针对鱼眼相机提出的模型，也称为Unified Camera Model（或者unified omnidirectional camera model），同时被VINS-Fusion、VINS-Mono、鱼眼DSO采用，KITTI360数据集中提供的鱼眼相机也采用了这种模型。这种通用的相机模型可以模拟小孔成像的相机模型，也可以模拟鱼眼相机的成像模型。当\\(\\xi\\)=0时，鱼眼相机模型就退化为了小孔相机模型。优点（源于这里）是它能精确的模拟各种图像设备和畸变的几何图像生成过程，（2）它的反投影是一个闭式解。 ​ 鱼眼相机的投影过程为\\(\\pi_c:\\mathbb{R}^3 \\rightarrow \\Omega\\)： 0.将世界坐标系下的点转到相机坐标系下，需要\\(R,T\\); 1.设原点为\\(C_m\\)的相机坐标系中的一个三维点为\\(\\mathcal{X}(X,Y,Z)\\)，先将其坐标归一化，即将其坐标缩放到单位球面上，得到\\(\\mathcal{X_s}=\\frac{\\mathcal{X}}{|\\mathcal{X}|}=(X_s,Y_s,Z_s)^{T}\\)，\\(|\\mathcal{X}|=\\sqrt{X^2+Y^2+Z^2}\\); 2.随后改变坐标系，设现在坐标系为\\(C_p\\)， \\(C_p\\)相对于坐标系\\(C_m\\)在\\(z\\)轴方向上有一个负方向的平移\\(\\xi\\)，相当于形成一个虚拟的光心（坐标系原点），这样导致\\(\\mathcal{X_s}\\)在新坐标系中的坐标为\\((X_s,Y_s,Z_s+\\xi)^{T}\\)； 3.随后将新的\\(\\mathcal{X_s}\\)投影到归一化平面上，得到三维点\\(\\mathbf{m}_u(x,y,1)\\): \\[ \\begin{align} \\label{fisheye_normalized_point} \\mathbf{m}_u=(\\frac{X_s}{Z_s+\\xi},\\frac{Y_s}{Z_s+\\xi},1)^{T}=(\\frac{X}{Z+\\xi |\\mathcal{X}|},\\frac{Y}{Z+\\xi |\\mathcal{X}|},1)^T=h(\\mathcal{X_s}) \\end{align} \\] 4.引入径向畸变和切向畸变参数（这里采用一般的标准相机、广角相机畸变模型Brown and Conrady 模型，也可以是其他畸变校正模型）后，得到去畸变之后的点坐标\\(\\mathbf{m}_d(x_{distorted},y_{distorted},1)\\)： \\[ \\begin{align} x_{distorted} &amp;= x+k_1\\rho^2+k_2\\rho^4+k_3\\rho^6+2p_1xy+p_2(\\rho^2+2x^2) \\\\ y_{distorted} &amp;= y+k_1\\rho^2+k_2\\rho^4+k_3\\rho^6+p_1(\\rho^2+2y^2)+2p_2xy \\\\ \\mathbf{m}_d &amp;= \\mathbf{m}_u+D(\\mathbf{m}_u,V),\\rho=\\sqrt{x^2+y^2},V=(k_1,k_2,k_3,p_1,p_2) \\end{align} \\] 5.最后将去畸变之后的归一化平面坐标系中的坐标\\(\\mathbf{m}_d\\)用一个类似于针孔相机的内参的\\(K\\)矩阵投影到像素平面上。即最终的像素点\\(\\mathbf{p}(u,v)\\): \\[ \\begin{align} \\mathbf{p}=K\\mathbf{m}_d=\\left[ \\begin{array}{ccc} f_x &amp; \\alpha &amp; u_0 \\\\ 0 &amp; f_y &amp; v_0 \\\\ 0 &amp; 0 &amp; 1 \\end{array} \\right] \\end{align} \\] ​ Mei模型下的鱼眼图像在标定时只需要知道\\(\\xi\\)，内参矩阵\\(K\\)（其中\\(\\alpha\\)为坐标轴倾斜参数，理想情况为0）以及图像畸变参数\\(k_1,k_2,p_1,p_2\\)。但也正因为相比于针孔相机模型，仅仅多了一个参数\\(\\xi\\)，因此一些图像边缘处高畸变的像素的矫正并不是很准。 投影和反投影过程 ​ 不考虑图像畸变的情况下。Mei模型的投影过程（3D-&gt;2D）如下： \\[ \\begin{align} \\label{uocm_projection} \\left[ \\begin{array}{c}u \\\\ v \\end{array} \\right] &amp;= \\left[ \\begin{array}{c}f_x\\frac{X}{\\xi d+Z}+c_x \\\\ f_y\\frac{Y}{\\xi d+Z}+c_y \\end{array} \\right] \\\\ d &amp;= \\sqrt{X^2+Y^2+Z^2} \\end{align} \\] ​ 反投影过程（2D-&gt;3D）：(提供额外深度信息时才能得到实际的三维坐标，否则只能得到归一化平面上的点的三维点坐标) \\[ \\begin{align} \\label{uocm_inverse_projection2} \\left[ \\begin{array}{c}\\tilde{u} \\\\ \\tilde{v} \\end{array} \\right] &amp;= \\left[ \\begin{array}{c}\\frac{(u-c_x)}{f_x} \\\\ \\frac{v-c_y}{f_y} \\end{array} \\right]\\\\ \\pi_u^{-1}(u)&amp;=\\frac{\\xi+\\sqrt{1+(1-\\xi^2)(\\tilde{u}^2+\\tilde{v}^2)}}{\\tilde{u}^2+\\tilde{v}^2+1}\\left[ \\begin{array}{c}\\tilde{u} \\\\ \\tilde{v} \\\\1\\end{array} \\right]-\\left[ \\begin{array}{c}0 \\\\ 0 \\\\ \\xi \\end{array} \\right] \\end{align} \\] ​ 根据上述\\(\\ref{fisheye_normalized_point}\\)中的\\(\\mathbf{m}_u(x,y,1)\\)，对于\\(x,y\\)轴，只需要计算一个\\(\\lambda= \\frac{Z+\\xi |\\mathcal{X}|}{|\\mathcal{X}|}\\)结合内参矩阵\\(K\\)即可实现从像素坐标系坐标\\(\\mathbf{p}(u,v)\\)到归一化平面系坐标\\(\\mathbf{m}_u(x,y,1)\\)向归一化球面系坐标\\(\\mathcal{X_s}\\)的转换；对于\\(z\\)轴，则差了一个\\(\\frac{Z}{|\\mathcal{X}|}=\\lambda-\\xi\\)，因此核心在于找到\\(\\lambda\\)到底应该是多少。转换过程：\\(\\mathbf{m}_u \\rightarrow \\mathcal{X}_{C_p} \\rightarrow \\mathcal{X}_{C_m}\\)，推导过程如下： \\[ \\begin{align} \\label{fisheye_2d_to_3d} \\mathbf{m}_u &amp;= (x,y,1)^T = K^{-1}\\mathbf{p} \\\\ multiply: \\quad \\lambda &amp; \\Downarrow\\\\ \\mathcal{X}_{C_p} &amp;= (\\frac{X}{|\\mathcal{X}|},\\frac{Y}{|\\mathcal{X}|},\\frac{Z}{|\\mathcal{X}|}+\\xi)^{T} \\\\ minus: \\quad \\xi &amp; \\Downarrow \\\\ \\mathcal{X}_{C_m} &amp;= \\frac{\\mathcal{X}}{|\\mathcal{X}|}=(\\frac{X}{|\\mathcal{X}|},\\frac{Y}{|\\mathcal{X}|},\\frac{Z}{|\\mathcal{X}|})^{T} \\end{align} \\] ​ \\(\\lambda\\)的计算方法如下： \\[ \\begin{align} \\label{lambda} \\lambda &amp;= \\frac{Z+\\xi |\\mathcal{X}|}{|\\mathcal{X}|} \\\\ &amp;= \\frac{1}{\\sqrt{(\\frac{X}{Z+\\xi |\\mathcal{X}|})^2+(\\frac{Y}{Z+\\xi |\\mathcal{X}|})^2+(\\frac{Z}{Z+\\xi |\\mathcal{X}|})^2}} \\\\ &amp;= \\frac{1}{\\sqrt{(\\frac{X}{Z+\\xi |\\mathcal{X}|})^2+(\\frac{Y}{Z+\\xi |\\mathcal{X}|})^2+(\\frac{Z+\\xi |\\mathcal{X}|-\\xi |\\mathcal{X}|}{Z+\\xi |\\mathcal{X}|})^2}} \\\\ \\label{lambda_3} &amp;= \\frac{1}{\\sqrt{(\\frac{X}{Z+\\xi |\\mathcal{X}|})^2+(\\frac{Y}{Z+\\xi |\\mathcal{X}|})^2+(1-\\frac{\\xi}{\\lambda})^2}} \\\\ &amp;= \\frac{1}{\\sqrt{x^2+y^2+(1-\\frac{\\xi}{\\lambda})^2}} \\\\ \\end{align} \\] ​ 将上式转成二元一次方程求解\\(\\lambda\\)的解析解如下： \\[ \\begin{align} (x^2+y^2)\\lambda^2+(\\lambda-\\xi)^2 &amp;= 1 \\\\ \\Downarrow &amp; \\\\ (1+x^2+y^2)\\lambda^2-2\\xi \\lambda+(-1+\\xi^2) &amp;= 0 \\\\ \\Downarrow &amp; \\\\ \\lambda &amp;= \\frac{\\xi+\\sqrt{\\xi^2+(1+x^2+y^2)(1-\\xi^2)}}{(1+x^2+y^2)} \\\\ &amp;= \\frac{\\xi+\\sqrt{1+(x^2+y^2)(1-\\xi^2)}}{(1+x^2+y^2)} \\end{align} \\] ​ 2D-&gt;3D的射线变换为：从图像上任意像素为起点，方向朝向空间中的点，此射线上的所有点的归一化平面坐标均为\\(\\mathbf{m}_u(x,y,1)\\)，按照\\(\\ref{fisheye_2d_to_3d}\\)中将归一化平面坐标系下的坐标变换到归一化球面坐标系下坐标有\\(\\ref{fisheye_3d_to_2d}\\)的假设。 \\[ \\begin{align} \\label{fisheye_3d_to_2d} (\\lambda x, \\lambda y,\\lambda - \\xi)^T \\backsimeq (x,y,m)^T \\end{align} \\] ​ 结合\\(\\ref{fisheye_normalized_point}\\)和\\(\\ref{lambda_3}\\)可以得出\\(m=1-\\xi/\\lambda=1-\\xi \\frac{(1+x^2+y^2)}{\\xi+\\sqrt{\\xi^2+(1+x^2+y^2)(1-\\xi^2)}}\\)，即： \\[ \\begin{align} \\label{fisheye_3d_to_2d2} (x,y, 1-\\xi \\frac{(1+x^2+y^2)}{\\xi+\\sqrt{\\xi^2+(1+x^2+y^2)(1-\\xi^2)}})^T \\end{align} \\] PolyFisheye模型 ​ PolyFisheye模型是在IROS2017中的Dual-Fisheye Omnidirectional Stereo中提出的。 ​ 从模型图上看基本和Mei模型一模一样，唯一的不同是，假设空间点\\(\\mathcal{P}^c\\)最终投影得到的像素点为\\(u\\)，他们认为\\(u\\)到光心\\(O_i\\)的距离\\(\\mathcal{R}\\)并不是直接等于沿着\\(\\theta_r\\)方向上投影过来的大小，而是和\\(O^{cl}\\)到\\(u\\)的距离存在一个关于\\(\\theta\\)的七次多项式的多项式倍数关系。这样就相比Mei模型多了七个参数来刻画鱼眼相机，自然就更准了。 \\[ \\begin{align} \\mathcal{R}(\\theta)=[1+\\mathcal{D}(\\theta)] \\mathcal{R}_{ref}(\\theta)=f\\Sigma_{i=0}^N \\eta_i \\theta^i \\end{align} \\] ​ 鱼眼相机的投影模型分为三步：1）\\(\\mathcal{P}^c \\rightarrow \\bar{\\mathcal{P}^c}\\)相机坐标系中的点转换到单位球面上；2）\\(\\bar{\\mathcal{P}}^c \\rightarrow \\overrightarrow{O^{cl}\\mathbf{u}}\\) 单位球面上的点进行光线的折射变换;3）\\(\\overrightarrow{O^{cl}\\mathbf{u}} \\rightarrow \\mathbf{u}\\)将光线投影到像平面空间。其中\\(\\mathcal{R}(\\theta)=\\overrightarrow{O_i\\mathbf{u}}\\)就是实际入射光线折射之后投影到相平面坐标系的长度，存在畸变，而\\(\\mathcal{R}_{ref}\\)就是无畸变的投影向量，具体如下： 1.将相机坐标系中的点归一化到单位球面\\(\\bar{\\mathcal{P}}^c=-\\mathcal{P}^c/||\\mathcal{P}^c||=[\\bar{x}^c,\\bar{y}^c,\\bar{z}^c]^T\\); 2.将单位球面上的点转换到球面坐标系\\(\\cos(\\theta)=\\bar{z}^c,\\tan(\\varphi)=\\bar{y}^c/\\bar{x}^c\\)，\\(\\bar{x}^c=0\\)时\\(\\varphi=0\\)； 3.根据\\(\\theta\\)构建与成像系统无关的镜头光学模型\\(\\mathcal{R}_0(\\theta)=\\Sigma_{i=0}^N \\eta_i \\theta^i\\); 4.通过焦距\\(f\\)将光线投影到像素坐标系\\(\\mathbf{u}=f\\mathcal{R}_0(\\theta)\\left[ \\begin{array}{c} \\cos(\\varphi) \\\\ \\sin(\\varphi) \\end{array} \\right] + \\left[\\begin{array}{c} c_x \\\\ c_y \\end{array} \\right]\\)； 5.综上所示，将焦距\\(f\\)表示成矩阵形式\\(A_f\\),则投影过程为： \\[ \\begin{align} \\label{polyfiseye} \\mathbf{u}=\\Sigma_{i} \\eta_i \\theta^i A_f \\left[ \\begin{array}{c} \\cos(\\varphi) \\\\ \\sin(\\varphi) \\end{array} \\right] + \\left[\\begin{array}{c} c_x \\\\ c_y \\end{array} \\right]，A_f=\\left[ \\begin{array}{cc} A_{11} &amp; A_{12} \\\\ 0 &amp; A_{22} \\end{array} \\right] \\end{align} \\] 同样由于现代工艺的提升，镜头的切向畸变已经很小了，相比于径向畸变，可以忽略不计。出自TPAMI2013的文章“Calibration of ultrawide fisheye lens cameras by eigenvalue minimization”。 相关实现 ​ 主要依赖HKUST航空机器人所开源的一系列代码实现。真强 Kannala-Brandt Scaramuzza模型 Mei模型 PolyFisheye模型 Lionel Heng博士的CamOdoCal 高文良博士的camera_model Lionel Heng博士的CamOdoCal 高文良博士的camera_model OpenCV MATLAB鱼眼图像标定 Kalibr EpsAvlc的小项目 Kalibr yangzhenfei的carema_model OpenCVcv::omnidir::calibrate HKUST的xuhao开源的Vins-fisheye,许久未更新 yangzhenfei的carema_model MultiCol-SLAM yangzhenfei的carema_model 项目，还在维护 高文良博士的camera_model是在Lionel Heng博士的CamOdoCal基础以及yangzhenfei的carema_model优化的基础上改进的。 VINS-Fusion、VINS-Mono、VINS-Fisheye、GVINS等项目都是基于yangzhenfei的carema_model改进的。 VINS-Mono中提供了Mei模型，针孔相机模型，Scaramuzza模型和KB模型。其中的CataCamera就是Mei相机模型。 相比VINS-Mono，VINS-Fusion中的相机模型种类多了一种PinholeFullCamera模型。 高文良博士的camera_model更是多了PolyFisheyeCarema和SplineCamera。因此，如果只用相机模型，选择这个是最佳的。如果想用SLAM系统则选择其他repo。 而GVINS中还是使用了VINS-Mono中的相机模型种类。 OpenCV、Kalibr中关于Mei模型的实现也是基于Lionel Heng博士的CamOdoCal基础上完成的。 鱼眼图像转换 鱼眼图像转普通（框幅式）图像 ​ 一般的V-SLAM或者基于视觉的场景感知任务中使用的都是普通的单目相机，因此需要进行畸变矫正转成框幅式图像。 鱼眼图像转框幅式图像，图源于这里 ​ 转成框幅式图像，首先需要虚拟一个框幅式（小孔成像）相机的内参，然后通过归一化平面作为桥梁，构建鱼眼图像每个像素与框幅式图像每个像素之间的关系。步骤： 1.先确定虚拟相机的内参（\\(f_x,f_y,c_x,c_y\\)）与相对于鱼眼相机的外参。 2.对于虚拟相机的每个像素点\\(p_{pinhole}\\)，将像素点反投影到归一化平面，得到三维点\\(\\mathcal{X}_{s}\\)（z=1）。 3.将三维点根据鱼眼相机模型，投影到鱼眼相机上，得到鱼眼相机上的像素点\\(p_{fisheye}\\)。 4.将鱼眼图像的对应位置像素赋给框幅式图像。 细节补充 虚拟相机的视场角是由虚拟相机内参(\\(f_x,f_y\\))控制的，\\(f_x=width/2\\)时视场角刚好为90°。\\(width\\)为图像的像素宽度。 映射关系可以先算出来做成Lookup table，然后处理鱼眼图像时再直接查表即可。 全景图像转鱼眼图像 ​ 与全景图像转成框幅式图像的原理类似。就是找到鱼眼图像上每个像素与全景图像上的对应映射关系即可，可见。这里简单列一下要点： 1.以下图的全景图像为例，将其转换为右侧的鱼眼图像，鱼眼相机的中心指向天空，那么全景图像的底边宽\\(W_c\\)对应了鱼眼相机圆形视角的周长，而顶边则压缩为了一个中心点，鱼眼图像的半径\\(r_0\\neq H_c\\)； 2.因此鱼眼图像的半径只能通过全景图像的底边\\(W_c\\)来计算，鱼眼图像的中心位置\\(C_x,C_y\\)就知道了； 3.全景与鱼眼图像像素映射关系是从鱼眼图像的坐标开始，找到每一个像素\\(x_f,y_f\\)与全景图像上对应像素之间的关系\\(x_c,y_c\\)，为了不产生空洞，因此是遍历鱼眼图像像素开始，找到对应的全景图像像素，赋值颜色即可。映射关系中有一个\\(\\theta\\)需要根据所处的鱼眼图像坐标象限来判断才能展开到\\(2\\pi\\)空间。 细节补充 ​ 试验了一下发现部分全景图像转换的结果不是很好。尤其是第二章的鱼眼图像边缘不平滑。全景图像本身有问题的话，转出来的鱼眼图像也不好。 全景图像 鱼眼图像 其他 https://stackoverflow.com/questions/56901894/c-algorithm-to-convert-a-fisheye-image-to-an-equirectangular-image-with-opencv?rq=1 [ ] 可视化工具 web端展示，导入全景图像，输出可以360展示的VR视角图像。 相近名词解释 omnidirectional camera： 在一个水平面有360度视野的相机，或视野能覆盖半个球或近似整个球的相机； Panoramic camera：全景相机 spherical camera：球面相机 catadioptric camera：结合了透镜和面镜的相机。广角相机的第二种类型。 fisheye camera：鱼眼相机 wide-angle camera：广角相机 全景相机品牌 GoPro Max、Insta360 （One X2，X3，RS 1-inch，RS Twin）、Ricoh Theta （X，Z1）、Trisio Lite2、Kandao QooCam 8K 360。 参考资料 https://mp.weixin.qq.com/s/0U4_jj1wrggVGY_1uvQXmw https://mp.weixin.qq.com/s/aMJnwTvI87YrBKkmMaGQbQ （其中鱼眼相机2D到3D的变换公式存在错误） https://mp.weixin.qq.com/s/TffJXlFjGwOKC1kIFs3sjQ https://mp.weixin.qq.com/s/GwZ_NaG8u4q2odIS6sORAw https://mp.weixin.qq.com/s/fo3CaWwtAvb6oUR3qt87Tw https://mp.weixin.qq.com/s/zPvvAWFxWJxom6TJW7diIw https://mp.weixin.qq.com/s/efiANlLdrcig6aDCrmeC4w https://mp.weixin.qq.com/s/ygI6BC1JXcSP7QAwKa_Vqg https://zhuanlan.zhihu.com/p/317673040 https://epsavlc.github.io/2019/10/21/fisheye_calib.html https://jiangren.work/2019/09/13/%E9%B1%BC%E7%9C%BC%E9%95%9C%E5%A4%B4%E6%A8%A1%E5%9E%8B/ Mei的主页：https://www.robots.ox.ac.uk/~cmei/Toolbox.html Omnidirectional DSO: Direct Sparse Odometry With Fisheye Cameras","link":"/blogs/2025/02/08/%E9%B1%BC%E7%9C%BC%E5%9B%BE%E5%83%8F/"},{"title":"鱼眼图像转等距投影图像","text":"目的 ​ 单张图像的使用方法见下面的博客。 鱼眼图像的说明见这里。 FFMPEG的使用说明见这里。 批处理 Fisheye image sequences to fisheye video. 将单个鱼眼图像序列转成视频，注意图像的个数和视频的帧数保持一致。 12.\\ffmpeg.exe -f image2 -r 1 -i kitti360imagespath\\image_03\\data_rgb/000000000%d.png -vcodec libx265 -pix_fmt yuv420p -b:v 40000k -bufsize 5000k -preset ultrafast -c:a copy -y -r 1 ./fisheye_rgb_sequence_r.mp4.\\ffmpeg.exe -f image2 -r 1 -i kitti360imagespath\\image_02\\data_rgb/000000000%d.png -vcodec libx265 -pix_fmt yuv420p -b:v 40000k -bufsize 5000k -preset ultrafast -c:a copy -y -r 1 ./fisheye_rgb_sequence_l.mp4 Join to single fisheye video to dual fisheye video. 将两个视频拼接起来。就是两个视频水平放置。 1.\\ffmpeg.exe -i .\\fisheye_rgb_sequence_l.mp4 -i .\\fisheye_rgb_sequence_r.mp4 -filter_complex hstack -y ./dual_fisheye_image.mp4 Dual fisheye video to equirectangular video. 将双鱼眼视频转换为等距投影视频。这里FOV187.8是微调的，为了得到一个比较好的转换结果。 1./ffmpeg.exe -y -i .\\dual_fisheye_image.mp4 -vf v360=dfisheye:e:yaw=-90:ih_fov=187.8:iv_fov=185 -c:v libx265 -b:v 40000k -bufsize 5000k -preset ultrafast -c:a copy equirectangular_image_sequence.mp4 Fisheye video to fisheye image sequences将等距投影视频转换为图像，并按照原始鱼眼图像的命名方式命名。 1.\\ffmpeg.exe -i .\\equirectangular_image_sequence.mp4 -r 1 -q:v 1 -start_number 0 ./%10d.png 这里给一个KITTI-360数据集中鱼眼图像批量转换为等距投影图像的脚本： 1234567891011121314151617181920212223242526272829303132333435363738394041424344#!/bin/bashfile_list=(\"2013_05_28_drive_0000_sync\" \"2013_05_28_drive_0002_sync\" \"2013_05_28_drive_0003_sync\" \"2013_05_28_drive_0004_sync\" \"2013_05_28_drive_0005_sync\" \"2013_05_28_drive_0006_sync\" \"2013_05_28_drive_0007_sync\" \"2013_05_28_drive_0009_sync\" \"2013_05_28_drive_0010_sync\")# create the destiny dirdata_2d_pano=data_2d_panomkdir -p $data_2d_panocd $data_2d_panofor sequence in ${file_list[@]}; do mkdir -p $sequence cd $sequence mkdir -p pano cd pano mkdir -p data_rgb cd ../..donecd ../data_2d_panoecho \"Current dir:\"pwd # #ffmpeg operationfor sequence in ${file_list[@]}; do # create the path and move into cd $sequence # 1. fetch images and merge into videos ffmpeg -f image2 -r 1 -i ../../data_2d_raw/$sequence/image_03/data_rgb/%10d.png -vcodec libx265 -pix_fmt yuv420p -b:v 40000k -bufsize 5000k -preset fast -c:a copy -y -r 1 fisheye_rgb_sequence_r.mp4 ffmpeg -f image2 -r 1 -i ../../data_2d_raw/$sequence/image_02/data_rgb/%10d.png -vcodec libx265 -pix_fmt yuv420p -b:v 40000k -bufsize 5000k -preset fast -c:a copy -y -r 1 fisheye_rgb_sequence_l.mp4 # 2. merge two videos into one video ffmpeg -i fisheye_rgb_sequence_l.mp4 -i fisheye_rgb_sequence_r.mp4 -filter_complex hstack -y dual_fisheye_image.mp4 # 3. transform to equirectangular video ffmpeg -y -i dual_fisheye_image.mp4 -vf v360=dfisheye:e:yaw=-90:ih_fov=187.8:iv_fov=185 -c:v libx265 -b:v 40000k -bufsize 5000k -preset ultrafast -c:a copy equirectangular_image_sequence.mp4 # 4. Equirectangular video to separate images ffmpeg -i equirectangular_image_sequence.mp4 -r 1 -q:v 1 -start_number 0 ./pano/data_rgb/%10d.png cd ..done ​ 这里面图像转视频默认图像的名字是按照数字排序的，而且序号是从0开始的，如果不想从0开始，就要在-f image2后面加-start_number 4613。就可以了。其他位置无效。 当然直接使用FFMPEG得到的等距投影图像中间存在明显的拼接缝，因为FFMPEG并没有经过blend操作。可以手动刺点的方式获取两张鱼眼图像上的同名点，来获得更好的拼接结果，但是比较麻烦，而且需要手动刺点，如果想得到比较好的等距投影图像，应该增加这个步骤。比如使用Fusion2sphere的方式得到拼接较好的结果。 时间比较紧，就先不测试了。 Reference https://www.trekview.org/blog/2022/using-ffmpeg-process-gopro-fusion-fisheye/ (Recommanded:+1::+1::+1:) https://github.com/raboof/dualfisheye2equirectangular https://stackoverflow.com/questions/37796911/is-there-a-fisheye-or-dual-fisheye-to-equirectangular-filter-for-ffmpeg https://github.com/trek-view/Fusion2sphere","link":"/blogs/2025/02/08/%E9%B1%BC%E7%9C%BC%E5%9B%BE%E5%83%8F%E8%BD%AC%E7%AD%89%E8%B7%9D%E6%8A%95%E5%BD%B1%E5%9B%BE%E5%83%8F/"}],"tags":[{"name":"B-Spline","slug":"B-Spline","link":"/blogs/tags/B-Spline/"},{"name":"CloudCompare","slug":"CloudCompare","link":"/blogs/tags/CloudCompare/"},{"name":"Point Cloud","slug":"Point-Cloud","link":"/blogs/tags/Point-Cloud/"},{"name":"Docker","slug":"Docker","link":"/blogs/tags/Docker/"},{"name":"LiDAR_SLAM","slug":"LiDAR-SLAM","link":"/blogs/tags/LiDAR-SLAM/"},{"name":"Hexo","slug":"Hexo","link":"/blogs/tags/Hexo/"},{"name":"IMU","slug":"IMU","link":"/blogs/tags/IMU/"},{"name":"Mathemetics","slug":"Mathemetics","link":"/blogs/tags/Mathemetics/"},{"name":"Linux","slug":"Linux","link":"/blogs/tags/Linux/"},{"name":"MarkDown","slug":"MarkDown","link":"/blogs/tags/MarkDown/"},{"name":"OSG","slug":"OSG","link":"/blogs/tags/OSG/"},{"name":"Geometics","slug":"Geometics","link":"/blogs/tags/Geometics/"},{"name":"Geometry","slug":"Geometry","link":"/blogs/tags/Geometry/"},{"name":"ROS","slug":"ROS","link":"/blogs/tags/ROS/"},{"name":"VS","slug":"VS","link":"/blogs/tags/VS/"},{"name":"PaperReview","slug":"PaperReview","link":"/blogs/tags/PaperReview/"},{"name":"WindowsScript","slug":"WindowsScript","link":"/blogs/tags/WindowsScript/"},{"name":"Windows","slug":"Windows","link":"/blogs/tags/Windows/"},{"name":"Tools","slug":"Tools","link":"/blogs/tags/Tools/"},{"name":"Zotero","slug":"Zotero","link":"/blogs/tags/Zotero/"},{"name":"PCL","slug":"PCL","link":"/blogs/tags/PCL/"},{"name":"Pytorch","slug":"Pytorch","link":"/blogs/tags/Pytorch/"},{"name":"专业应用","slug":"专业应用","link":"/blogs/tags/%E4%B8%93%E4%B8%9A%E5%BA%94%E7%94%A8/"},{"name":"激光雷达","slug":"激光雷达","link":"/blogs/tags/%E6%BF%80%E5%85%89%E9%9B%B7%E8%BE%BE/"},{"name":"服务器","slug":"服务器","link":"/blogs/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8/"},{"name":"FFMPEG","slug":"FFMPEG","link":"/blogs/tags/FFMPEG/"},{"name":"鱼眼图像","slug":"鱼眼图像","link":"/blogs/tags/%E9%B1%BC%E7%9C%BC%E5%9B%BE%E5%83%8F/"}],"categories":[{"name":"MathUtilities","slug":"MathUtilities","link":"/blogs/categories/MathUtilities/"},{"name":"实用工具","slug":"实用工具","link":"/blogs/categories/%E5%AE%9E%E7%94%A8%E5%B7%A5%E5%85%B7/"},{"name":"开源库","slug":"开源库","link":"/blogs/categories/%E5%BC%80%E6%BA%90%E5%BA%93/"},{"name":"算法","slug":"算法","link":"/blogs/categories/%E7%AE%97%E6%B3%95/"},{"name":"写作工具","slug":"写作工具","link":"/blogs/categories/%E5%86%99%E4%BD%9C%E5%B7%A5%E5%85%B7/"},{"name":"传感器","slug":"传感器","link":"/blogs/categories/%E4%BC%A0%E6%84%9F%E5%99%A8/"},{"name":"专业应用","slug":"专业应用","link":"/blogs/categories/%E4%B8%93%E4%B8%9A%E5%BA%94%E7%94%A8/"},{"name":"科研神器","slug":"科研神器","link":"/blogs/categories/%E7%A7%91%E7%A0%94%E7%A5%9E%E5%99%A8/"}]}